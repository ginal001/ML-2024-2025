{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf6611d0-e0e8-4735-ba13-bec4504b1441",
   "metadata": {},
   "source": [
    "# **Last Homework – Finding Odd Shapes**\n",
    "\n",
    "Due to the very sad events that took place on the Krakowskie Przedmieście Campus, the semester schedule has changed for the Monday and Thursday groups. To accommodate these changes, students in all groups receive a **combined homework assignment for both Class 13 and Class 14**.\n",
    "\n",
    "## **RULES**\n",
    "\n",
    "### **Deadline**\n",
    "\n",
    "**The deadline for this homework is July 2nd, 23:59.**\n",
    "\n",
    "### **Grading Criteria**\n",
    "\n",
    "This homework will be graded on a scale from 0 to 4 points - plus a **bonus**.\n",
    "\n",
    "- **4 points** (equivalent to completing two homework assignments worth 2 points each):\n",
    "  - **the solution must attain an RMSE of 5.0 pixels or lower** (on 25,000 samples).\n",
    "  - the sizes of all tensors must be annotated in comments\n",
    "  - training loss curve must be plotted with a clear indication of a 5.0 pixels level\n",
    "  - an in-depth textual description of the solution must be provided\n",
    "  - clear attention diagrams with discussion must be included\n",
    "\n",
    "- **3 points** (equivalent to completing one homework assignment worth 2 points):\n",
    "  - training loss curve must be plotted with a clear indication of a 5.0 pixels level\n",
    "  - the sizes of all tensors must be annotated in comments\n",
    "  - an in-depth textual description of the solution must be provided\n",
    "  - clear attention diagrams with discussion must be included\n",
    "\n",
    "- **2 points** (equivalent to completing one homework assignment worth 2 points):\n",
    "  - missing any one of the following elements:\n",
    "    - training loss curve plot with a clear indication of a 5.0 pixels level\n",
    "    - tensor size annotations in comments\n",
    "    - in-depth textual description of the solution\n",
    "    - attention diagrams with discussion\n",
    "\n",
    "- **1 point** (equivalent to submitting an incomplete homework assignment):\n",
    "  - missing any two of the following elements:\n",
    "    - training loss curve plot with a clear indication of a 5.0 pixels level\n",
    "    - tensor size annotations in comments\n",
    "    - in-depth textual description of the solution\n",
    "    - attention diagrams with discussion\n",
    "\n",
    "- **0 points** (equivalent to not completing the homework assignment):\n",
    "  - missing any three of the following:\n",
    "    - training loss curve plot with a clear indication of a 5.0 pixels level\n",
    "    - tensor size annotations in comments\n",
    "    - in-depth textual description of the solution\n",
    "    - attention diagrams with discussion\n",
    "\n",
    "- **BONUS** – This homework encompasses all key elements from previous classes on deep neural networks.  \n",
    "As a result, any student who obtains an **RMSE of 3.0 pixels or below** (on 25,000 samples), and whose solution would otherwise qualify for 4 points, **will receive the full 14 points** — equivalent to completing all homework assignments related to deep learning — regardless of their previous scores.\n",
    "\n",
    "\n",
    "\n",
    "## **HOMEWORK ASSIGNMENT DESCRIPTION AND INSTRUCTIONS**\n",
    "\n",
    "### **Online Dataset**\n",
    "\n",
    "The code provided below generates an *online* dataset `OddXYDataset`.\n",
    "\n",
    "The term *online* means that the dataset does not have a fixed set of pre-generated examples (like a traditional training set of fixed size). Instead, new samples are generated dynamically each time they are requested.\n",
    "\n",
    "While the number of possible examples is finite in principle, it is so large that — for practical purposes — we can consider it to be effectively infinite.\n",
    "\n",
    "In this setting, there is no need to use a separate validation or test set: the training error itself is a good estimate of the generalization error, since every training sample is new and unseen.\n",
    "\n",
    "Consequently, the notion of an *epoch* becomes a matter of convention. For this assignment, we define one epoch as processing 25,000 training examples.\n",
    "\n",
    "### **Training strategies**\n",
    "\n",
    "Overfitting is not a problem in the *online* setting — but training can still stagnate in local minima or flat regions of the loss landscape.  \n",
    "To address this, you will likely need to try one or more of the following strategies:\n",
    "\n",
    "- **Multiple restarts** with different random seed values;\n",
    "- **Adaptive learning rate** — consider researching training schedulers (this topic was not covered in class);\n",
    "- **Progressive model growth** — start with a simpler architecture and gradually add components during training,\n",
    "  so that the parts already present can learn what to do before the rest is introduced.\n",
    "\n",
    "### **DataLoader**\n",
    "\n",
    "The `show_examples()` function demonstrate how to wrap the dataset into a `torch.utils.data.DataLoader` so it becomes directly usable for the training/testing of a neural network.\n",
    "\n",
    "### **Data Description**\n",
    "\n",
    "By examining the provided code and a few sample images generated from this dataset, you will notice that:\n",
    "\n",
    "1. **Each data sample** is a 64×64 black-and-white image with the following characteristics:\n",
    "  - It contains several shapes of the same type (either circles, triangles, or squares), randomly placed and varying in size;\n",
    "  - It includes one additional shape of a different type — the *odd* shape — also placed at a random location;\n",
    "  \n",
    "  **Note that these shapes may overlap partially or even completely, potentially hiding the odd shape.**\n",
    "\n",
    "2. **The label** associated with each image is a 2D point indicating the coordinates of the center of the odd shape.\n",
    "\n",
    "### **The Homework Objective**\n",
    "\n",
    "Students should design an architecture of an **attention-based neural network** and train it so that it attains an RMSE (Root Mean Square Error, defined as the square root of the MSE) of **5.0 or lower**. Due to the nature of the online dataset, there is no need to test the solution on a separate test set.\n",
    "\n",
    "Students should visualize the attention matrices in the trained network and **discuss what they observe** — not just describe them.  \n",
    "Focus on interpreting the patterns: Where is the model attending? Are there any consistent behaviors across samples? Does attention correlate with the position of the odd shape? What do surprising or unclear patterns tell us?\n",
    "\n",
    "A few technical requirements to observe:\n",
    "\n",
    "- Seed all random number generators so that (1) your results are replicable and (2) I can rerun your solution and obtain the same output — *in case I need to check something*.\n",
    "\n",
    "- Make sure your Colab file contains a **fully trained solution** with:\n",
    "  - printed training output,\n",
    "  - attention diagrams,\n",
    "  - and a plot of the training loss curve.\n",
    "\n",
    "This way, I don’t have to rerun your code unless absolutely necessary.\n",
    "\n",
    "### **Publish on GitHub**\n",
    "- Upload your Colab notebook to your **GitHub repository** for this course.\n",
    "- In your repository’s **README**, include a **link** to the notebook.\n",
    "- In the notebook include **“Open in Colab”** badge so the notebook can be launched directly from GitHub.\n",
    "\n",
    "## **SOLUTION SUGGESTIONS**\n",
    "\n",
    "Students **do not need to follow these suggestions** — these are simply the strategies that worked for me.\n",
    "\n",
    "The goal of the homework is, of course, to find the location of the odd shape. For that reason, it seems worthwhile to consider a *position-aware* variant of the post-processing of attention results. The solution I propose consists of the following components:\n",
    "\n",
    "\n",
    "0. **Input**  \n",
    "   Our input is a black-and-white image with 1 channel, of size 64×64 pixels.\n",
    "\n",
    "1. **Embedding**  \n",
    "  In class, we embedded a sequence of tokens in a multidimensional space, resulting in a sequence of embeddings. We also saw how such sequences are compatible with positional encoding and attention mechanisms used in subsequent stages.\n",
    "\n",
    "  Here, we need to process an image that contains shapes of interest at various spatial locations.  \n",
    "  To do this, I designed a Convolutional Neural Network with:\n",
    "  - 1 input channel,\n",
    "  - an input grid of 64x64 pixels,\n",
    "  - and an output feature map arranged as a 12x12 grid with 16 channels.\n",
    "\n",
    "  I used **no padding**, and each output neuron has a **receptive field of size 20x20** with a **stride of 4x4**.  \n",
    "  This architectural choice yields **144 distinct positions** (12x12), each represented by a 16-dimensional feature vector.\n",
    "\n",
    "  We can treat this as a sequence of 144 embeddings in 16-dimensional space — making it fully compatible with the attention mechanisms used later in the model.\n",
    "\n",
    "\n",
    "2. **Positional Encoding**  \n",
    "  I applied sinusoidal positional encoding, just like in class, using 16 positional dimensions to match the 16 feature dimensions of the image embeddings.  \n",
    "\n",
    "  Positions were encoded based on their indices from 0 to 143.\n",
    "\n",
    "3. **Attention**  \n",
    "   I used full self-attention, where input tokens are linearly projected into Query, Key, and Value vectors using learned matrices.\n",
    "\n",
    "4. **Post-Processing**  \n",
    "   The classifier was implemented as a 2-layer MLP and applied **token-wise**, without averaging over positions.  \n",
    "\n",
    "   This corresponds to the **position-aware** variant of post-processing the attention results, as discussed in class.\n",
    "\n",
    "   As a result, the model produced a **logit for each of the 144 spatial locations**, which was then converted with `softmax` into a **probability distribution** over positions — representing the likelihood of the odd shape being located at each position.\n",
    "\n",
    "\n",
    "5. **Final Prediction**  \n",
    "   We know the exact position (center) of each of the 144 rectangular receptive fields of the embedding network. Since we also have the **probability** of each field being the target location (from the classifier), we can compute the **expected position** as a weighted average of receptive field centers. In what follows I will call it *soft argmax*.\n",
    "\n",
    "   **Example:**\n",
    "\n",
    "   Suppose we had only 4 output rectangles (instead of 144), with centers at:  \n",
    "   $$(16, 16),\\ (16, 48),\\ (48, 16),\\ \\text{and } (48, 48).$$  \n",
    "   and suppose the probabilities from the post-processing stage were:  \n",
    "   $$(0.1,\\ 0.2,\\ 0.69999,\\ 0.00001).$$  \n",
    "   Then the predicted center would be:\n",
    "   $$\n",
    "   \\begin{align*}\n",
    "   x &= 16 \\cdot 0.1 + 16 \\cdot 0.2 + 48 \\cdot 0.69999 + 48 \\cdot 0.00001 \\\\\n",
    "   y &= 16 \\cdot 0.1 + 48 \\cdot 0.2 + 16 \\cdot 0.69999 + 48 \\cdot 0.00001\n",
    "   \\end{align*}\n",
    "   $$\n",
    "\n",
    "   which yields an interpretable, differentiable prediction for the (x, y) location of the odd shape (*soft argmax*).\n",
    "\n",
    "**The above steps bring the RMSE below 4.0 pixels.**  \n",
    "However, the result depends on the network initialization — it is seed-dependent — so it's worth restarting the training a few times with different seeds to find a better-performing run.\n",
    "\n",
    "To improve this result further, though, we'll have to work a bit harder. Here's how:\n",
    "\n",
    "\n",
    "6. **Offset Regressor**\n",
    "\n",
    "  The soft-argmax mechanism in step 5 identifies the **center** of the most probable receptive field, but it cannot fine-tune the prediction within that field. For example, if the odd shape is located in the **lower-left corner** of a receptive field, the best the model can do is predict the **center** of that rectangle — introducing a systematic error.\n",
    "\n",
    "  *One may argue:* the design naturally accounts for a more nuanced case. When the odd shape lies **across the boundary between two receptive fields**, the attention distribution may spread across both regions. In such cases, the soft-argmax prediction becomes a **weighted average** of the centers of the adjacent fields. This behavior is a built-in **feature of the design** that allows the model to predict positions **off-center**, somewhere in between fields.\n",
    "\n",
    "  *To that I would reply:* this is true — but it comes with a trade-off. When attention is distributed across multiple regions, it becomes **less clear which shapes are *regular* and which one is *odd***. This added ambiguity may make it harder for the network to reach a confident decision, especially in the early stages of training.\n",
    "\n",
    "  To address this systematic limitation in a more structured way, I introduced an additional **2-layer MLP regressor**, applied **token-wise** to each of the 144 positions. This regressor takes the same attention output used by the classifier in step 4 and predicts a **local offset** $(\\Delta x, \\Delta y)$ within each receptive field. These offsets are then **aggregated** using the probabilities from step 4, resulting in a **soft average correction vector**.\n",
    "\n",
    "  Note that the attention mechanism must learn to extract — from the original features — both:\n",
    "  - the **probability** that the odd shape is located at a given position, and  \n",
    "  - the **local coordinates** of that shape *within* the respective receptive field.\n",
    "\n",
    "\n",
    "7. **Refined Prediction**\n",
    "\n",
    "  The final predicted position is obtained by summing the **coarse prediction** from step 5 and the **fine-grained correction** from step 6. This allows the model to make accurate, differentiable predictions at **sub-receptive-field resolution**, resulting in significantly improved localization.\n",
    "\n",
    "  **In summary:**\n",
    "\n",
    "  - Step 5: predicts the expected center of the relevant receptive field (via soft-argmax);\n",
    "  - Step 6: estimates a fine-grained, attention-weighted offset within that field;\n",
    "  - Step 7: adds both components to produce the final prediction:\n",
    "\n",
    "$$\n",
    "\\text{final prediction} = \\underbrace{\\sum_i p_i \\cdot C_i}_{\\text{soft argmax}} + \\underbrace{\\sum_i p_i \\cdot (\\Delta x, \\Delta y)_i}_{\\text{fine correction offset}}\n",
    "$$\n",
    "\n",
    "\n",
    "However, I was not able to train this network end-to-end from scratch — it seems that the two heads (the classifier inferring probabilities and the regressor inferring fine-grained corrections) were not able to learn their roles *simultaneously*.  \n",
    "\n",
    "To solve this, I adopted a **progressive model growth** training strategy:\n",
    "\n",
    "- First, I trained a one-headed version of the network (without steps 6 and 7) until the RMSE reached approximately 4.0 — a clear indication that the probability distribution was being inferred correctly.\n",
    "- Then, I copied all weights into a new, complete two-headed network and continued training from that point.\n",
    "\n",
    "**This strategy brought the RMSE down to 2.65 pixels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c44bc518-0e96-415d-a39c-36860205a780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0. Imports & device\n",
    "# ============================================================\n",
    "import torch, random, math, numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Online dataset: 64×64, target = (cx,cy) ∈ [0,63]²  (float32)\n",
    "# ============================================================\n",
    "IMAGE = 64\n",
    "SHAPES = (\"circle\", \"square\", \"triangle\")\n",
    "\n",
    "def draw_shape(drawer, shape_type, center_x, center_y, radius):\n",
    "    if shape_type == \"circle\":\n",
    "        drawer.ellipse([center_x - radius, center_y - radius,\n",
    "                        center_x + radius, center_y + radius], fill=\"black\")\n",
    "    elif shape_type == \"square\":\n",
    "        drawer.rectangle([center_x - radius, center_y - radius,\n",
    "                          center_x + radius, center_y + radius], fill=\"black\")\n",
    "    else:  # triangle\n",
    "        drawer.polygon([\n",
    "            (center_x, center_y - radius),\n",
    "            (center_x - radius, center_y + radius),\n",
    "            (center_x + radius, center_y + radius)\n",
    "        ], fill=\"black\")\n",
    "\n",
    "class OddXYDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generates images on-the-fly:\n",
    "      * several random shapes of the same type\n",
    "      * 1 additional shape of a different type\n",
    "    Returns:\n",
    "      * image (1×64×64 tensor, float32 normalized to [0,1])\n",
    "      * label: float tensor [cx, cy] with center of the odd shape\n",
    "    Arguments:\n",
    "        num_samples             – total number of samples in the dataset\n",
    "        same_shape_count_range – tuple (min, max), number of identical shapes\n",
    "        shape_radius_range      – tuple (min_radius, max_radius) for shape size\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_samples,\n",
    "                 same_shape_count_range=(3, 6),\n",
    "                 shape_radius_range=(4, 10)):\n",
    "        self.num_samples = num_samples\n",
    "        self.same_shape_count_range = same_shape_count_range\n",
    "        self.radius_min, self.radius_max = shape_radius_range\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        base_shape = random.choice(SHAPES)\n",
    "        odd_shape = random.choice([s for s in SHAPES if s != base_shape])\n",
    "\n",
    "        img = Image.new(\"L\", (IMAGE, IMAGE), \"white\")\n",
    "        drawer = ImageDraw.Draw(img)\n",
    "\n",
    "        # draw identical shapes\n",
    "        for _ in range(random.randint(*self.same_shape_count_range)):\n",
    "            radius = random.randint(self.radius_min, self.radius_max)\n",
    "            cx = random.randint(radius, IMAGE - radius - 1)\n",
    "            cy = random.randint(radius, IMAGE - radius - 1)\n",
    "            draw_shape(drawer, base_shape, cx, cy, radius)\n",
    "\n",
    "        # draw the odd shape (with known center)\n",
    "        radius = random.randint(self.radius_min, self.radius_max)\n",
    "        cx = random.randint(radius, IMAGE - radius - 1)\n",
    "        cy = random.randint(radius, IMAGE - radius - 1)\n",
    "        draw_shape(drawer, odd_shape, cx, cy, radius)\n",
    "\n",
    "        img_tensor = torch.tensor(np.array(img), dtype=torch.float32).unsqueeze(0) / 255.\n",
    "        label_tensor = torch.tensor([float(cx), float(cy)], dtype=torch.float32)\n",
    "        return img_tensor, label_tensor\n",
    "\n",
    "def show_examples(num_examples=10):\n",
    "    \"\"\"\n",
    "    Displays a grid of image samples from OddXYDataset using a DataLoader with batch_size=1.\n",
    "\n",
    "    Args:\n",
    "        num_examples (int): Number of examples to display.\n",
    "    \"\"\"\n",
    "    dataset = OddXYDataset(num_samples=num_examples)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    num_columns = 5\n",
    "    num_rows = math.ceil(num_examples / num_columns)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(num_columns * 2, num_rows * 2))\n",
    "\n",
    "    for i, (image, label) in enumerate(dataloader):\n",
    "        if i >= num_examples:\n",
    "            break\n",
    "        image_np = image.squeeze(0).squeeze(0).numpy()  # B=1,C=1,H,W --> H,W\n",
    "        cx, cy = label.squeeze(0)                       # B=1,2       --> 2\n",
    "        axes.flat[i].imshow(image_np, cmap=\"gray\")\n",
    "        axes.flat[i].set_title(f\"({cx:.0f},{cy:.0f})\")\n",
    "        axes.flat[i].axis(\"off\")\n",
    "        axes.flat[i].scatter(cx, cy) # added\n",
    "\n",
    "    for j in range(i + 1, num_rows * num_columns):\n",
    "        axes.flat[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "show_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a784e4d-523b-4f53-a0ae-618d468c45f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OddXYDataset(25_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae8d072-f836-4276-ac3f-046bc65c3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1024,          #bylo256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43bc618-a76b-4eba-9ae7-951ea6ea968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedCNN(nn.Module):\n",
    "    def __init__(self, in_ch=1, out_ch=16, kernel=20, stride=4):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):              # x: [B, 1, 64, 64]\n",
    "        x = self.conv(x)               # -> [B, 16, 12, 12]\n",
    "        x = x.flatten(2).transpose(1, 2)   # -> [B, 144, 16]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4418a7b0-e93d-4615-a91c-fa04af016ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model=16, max_len=144):\n",
    "        super().__init__()\n",
    "\n",
    "        # pre-allocate the PE matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "\n",
    "        # positions 0 … max_len-1\n",
    "        pos = torch.arange(max_len).float().unsqueeze(1)          # [L, 1]\n",
    "\n",
    "        # denominator from “Attention Is All You Need”\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000) / d_model)\n",
    "        )                                                         # [d_model // 2]\n",
    "\n",
    "        # sin on even channels, cos on odd channels\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "\n",
    "        self.pe = pe\n",
    "\n",
    "    def forward(self, x):          # x: [B, L, d_model]\n",
    "        L = x.size(1)              # actual sequence length\n",
    "        return x + self.pe[:L].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aef97b36-8fbd-4a06-bb76-87b144b1bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(torch.nn.Module):\n",
    "    def __init__(self, input_dim = 16, output_dim = 16, k = 8):\n",
    "        super().__init__()\n",
    "        self.Q = torch.nn.Linear(input_dim, k)        # query projection d x k\n",
    "        self.K = torch.nn.Linear(input_dim, k)        # key projection d x k\n",
    "        self.V = torch.nn.Linear(input_dim, output_dim)      # value projection d x d_v\n",
    "        self.k = k\n",
    "        self.attention = None  # will store softmaxed attention weights for inspection later\n",
    "\n",
    "    def forward(self, features):                        # size: batch, words, d\n",
    "        queries = self.Q(features)                      # size: batch, words, k\n",
    "        keys = self.K(features)                         # size: batch, words, k\n",
    "        values = self.V(features)                       # size: batch, words, d_v\n",
    "\n",
    "        # Compute energy scores:\n",
    "        energies = queries @ keys.transpose(-2, -1)     # size: batch, words, words\n",
    "        energies = energies / (self.k ** 0.5)                # it is an additional rescale helping the stability\n",
    "\n",
    "        # Normalize energies into attention weights\n",
    "        self.attention = F.softmax(energies, dim=-1)         # size: batch, words, words\n",
    "\n",
    "        # Apply attention weights to values:\n",
    "        output = self.attention @ values                     # size: batch, words, d_v\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca702ac5-ca79-4918-8bff-6abbb317d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=16, hidden=32):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, 1)         # logit per token\n",
    "        )\n",
    "\n",
    "    def forward(self, x):                # [B, L, 16]\n",
    "        logits = self.mlp(x).squeeze(-1) # [B, L]\n",
    "        probs  = F.softmax(logits, dim=-1)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f3d2f5-73dc-471d-a3a9-72e90ba87b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftArgmax(nn.Module):\n",
    "    def __init__(self, kernel=20, stride=4, grid=12):\n",
    "        super().__init__()\n",
    "\n",
    "        # centers of 20×20 windows, sampled every 4 px\n",
    "        xx, yy = torch.meshgrid(\n",
    "            torch.arange(grid), torch.arange(grid), indexing=\"xy\"\n",
    "        )                                           # [G, G]\n",
    "        centers = torch.stack([xx, yy], -1).float() \\\n",
    "                  * stride + (kernel - 1) / 2       # [G, G, 2]\n",
    "\n",
    "        # plain tensor; no need for register_buffer in a quick demo\n",
    "        self.centers = centers.reshape(-1, 2)       # [144, 2]\n",
    "\n",
    "    def forward(self, probs):       # probs: [B, 144] (rows sum to 1)\n",
    "        return probs @ self.centers.to(probs.device)  # [B, 2]  → (y, x)\n",
    "\n",
    "\n",
    "class OddShapeDetector(nn.Module):\n",
    "    def __init__(self, output_attention=16, k=16, hidden=64):  #output attention 16, k = 8, hidden = 32, rezultat 47 po 5500 iteracjach a najlepsze to 16,16,32, batch 256, lr 0.001\n",
    "        super().__init__()\n",
    "        self.patch = PatchEmbedCNN()\n",
    "        self.pos   = PositionalEncoding()\n",
    "        self.attn  = SelfAttention(output_dim = output_attention, k = k)\n",
    "        self.cls   = TokenClassifier(input_dim = output_attention, hidden = hidden)\n",
    "        self.sarg  = SoftArgmax()\n",
    "\n",
    "    def forward(self, img):            # [B, 1, 64, 64]\n",
    "        x = self.patch(img)            # [B, 144, 16]\n",
    "        x = self.pos(x)\n",
    "        x = self.attn(x)\n",
    "        probs = self.cls(x)    # [B, 144]\n",
    "        coords = self.sarg(probs)      # [B, 2] (y, x w px)\n",
    "        return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91dfcb77-aba8-4992-82fa-fe2b44d61396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1  loss 202.9669  lr 1.000e-03\n",
      "epoch  2  loss 181.6908  lr 1.000e-03\n",
      "epoch  3  loss 180.8033  lr 1.000e-03\n",
      "epoch  4  loss 178.3418  lr 1.000e-03\n",
      "epoch  5  loss 177.2589  lr 1.000e-03\n",
      "epoch  6  loss 175.7717  lr 1.000e-03\n",
      "epoch  7  loss 176.7622  lr 1.000e-03\n",
      "epoch  8  loss 173.0113  lr 1.000e-03\n",
      "epoch  9  loss 166.1737  lr 1.000e-03\n",
      "epoch 10  loss 164.0312  lr 1.000e-03\n",
      "epoch 11  loss 160.1873  lr 1.000e-03\n",
      "epoch 12  loss 155.5335  lr 1.000e-03\n",
      "epoch 13  loss 151.2679  lr 1.000e-03\n",
      "epoch 14  loss 144.1045  lr 1.000e-03\n",
      "epoch 15  loss 139.5591  lr 1.000e-03\n",
      "epoch 16  loss 133.9767  lr 1.000e-03\n",
      "epoch 17  loss 131.1870  lr 1.000e-03\n",
      "epoch 18  loss 126.8404  lr 1.000e-03\n",
      "epoch 19  loss 123.7170  lr 1.000e-03\n",
      "epoch 20  loss 121.9011  lr 1.000e-03\n",
      "epoch 21  loss 119.8590  lr 1.000e-03\n",
      "epoch 22  loss 119.1634  lr 1.000e-03\n",
      "epoch 23  loss 118.1150  lr 1.000e-03\n",
      "epoch 24  loss 116.8937  lr 1.000e-03\n",
      "epoch 25  loss 115.3382  lr 1.000e-03\n",
      "epoch 26  loss 116.0156  lr 1.000e-03\n",
      "epoch 27  loss 116.0142  lr 1.000e-03\n",
      "epoch 28  loss 111.6967  lr 1.000e-03\n",
      "epoch 29  loss 111.7996  lr 1.000e-03\n",
      "epoch 30  loss 110.0251  lr 1.000e-03\n",
      "epoch 31  loss 108.7948  lr 1.000e-03\n",
      "epoch 32  loss 110.2319  lr 1.000e-03\n",
      "epoch 33  loss 107.1223  lr 1.000e-03\n",
      "epoch 34  loss 108.5473  lr 1.000e-03\n",
      "epoch 35  loss 106.0891  lr 1.000e-03\n",
      "epoch 36  loss 106.9072  lr 1.000e-03\n",
      "epoch 37  loss 106.3873  lr 1.000e-03\n",
      "epoch 38  loss 105.1589  lr 1.000e-03\n",
      "epoch 39  loss 101.2482  lr 1.000e-03\n",
      "epoch 40  loss 101.5936  lr 1.000e-03\n",
      "epoch 41  loss 103.6463  lr 1.000e-03\n",
      "epoch 42  loss 101.3480  lr 1.000e-03\n",
      "epoch 43  loss 101.4055  lr 1.000e-03\n",
      "epoch 44  loss 100.3219  lr 1.000e-03\n",
      "epoch 45  loss 100.2071  lr 1.000e-03\n",
      "epoch 46  loss 97.7505  lr 1.000e-03\n",
      "epoch 47  loss 97.6241  lr 1.000e-03\n",
      "epoch 48  loss 96.1646  lr 1.000e-03\n",
      "epoch 49  loss 94.6429  lr 1.000e-03\n",
      "epoch 50  loss 96.2892  lr 1.000e-03\n",
      "epoch 51  loss 93.1993  lr 1.000e-03\n",
      "epoch 52  loss 93.4625  lr 1.000e-03\n",
      "epoch 53  loss 93.6039  lr 1.000e-03\n",
      "epoch 54  loss 92.1407  lr 1.000e-03\n",
      "epoch 55  loss 91.2189  lr 1.000e-03\n",
      "epoch 56  loss 94.8873  lr 1.000e-03\n",
      "epoch 57  loss 92.3182  lr 1.000e-03\n",
      "epoch 58  loss 90.1978  lr 1.000e-03\n",
      "epoch 59  loss 92.8833  lr 1.000e-03\n",
      "epoch 60  loss 93.4373  lr 1.000e-03\n",
      "epoch 61  loss 89.9015  lr 1.000e-03\n",
      "epoch 62  loss 89.8690  lr 1.000e-03\n",
      "epoch 63  loss 88.1094  lr 1.000e-03\n",
      "epoch 64  loss 89.3001  lr 1.000e-03\n",
      "epoch 65  loss 85.9138  lr 1.000e-03\n",
      "epoch 66  loss 87.7260  lr 1.000e-03\n",
      "epoch 67  loss 87.1213  lr 1.000e-03\n",
      "epoch 68  loss 85.9900  lr 1.000e-03\n",
      "epoch 69  loss 86.9618  lr 1.000e-03\n",
      "epoch 70  loss 84.0424  lr 1.000e-03\n",
      "epoch 71  loss 85.5803  lr 1.000e-03\n",
      "epoch 72  loss 83.9265  lr 1.000e-03\n",
      "epoch 73  loss 83.0524  lr 1.000e-03\n",
      "epoch 74  loss 81.9385  lr 1.000e-03\n",
      "epoch 75  loss 81.4242  lr 1.000e-03\n",
      "epoch 76  loss 81.2567  lr 1.000e-03\n",
      "epoch 77  loss 83.8005  lr 1.000e-03\n",
      "epoch 78  loss 85.4175  lr 1.000e-03\n",
      "epoch 79  loss 82.5623  lr 1.000e-03\n",
      "epoch 80  loss 81.4166  lr 1.000e-03\n",
      "epoch 81  loss 79.3465  lr 1.000e-03\n",
      "epoch 82  loss 79.9901  lr 1.000e-03\n",
      "epoch 83  loss 81.2420  lr 1.000e-03\n",
      "epoch 84  loss 80.1619  lr 1.000e-03\n",
      "epoch 85  loss 79.8630  lr 1.000e-03\n",
      "epoch 86  loss 79.4512  lr 1.000e-03\n",
      "epoch 87  loss 80.7808  lr 1.000e-03\n",
      "epoch 88  loss 78.1355  lr 1.000e-03\n",
      "epoch 89  loss 80.2406  lr 1.000e-03\n",
      "epoch 90  loss 81.9214  lr 1.000e-03\n",
      "epoch 91  loss 80.4235  lr 1.000e-03\n",
      "epoch 92  loss 77.3857  lr 1.000e-03\n",
      "epoch 93  loss 81.1315  lr 1.000e-03\n",
      "epoch 94  loss 81.4335  lr 1.000e-03\n",
      "epoch 95  loss 76.8677  lr 1.000e-03\n",
      "epoch 96  loss 80.5692  lr 1.000e-03\n",
      "epoch 97  loss 76.4409  lr 1.000e-03\n",
      "epoch 98  loss 79.7289  lr 1.000e-03\n",
      "epoch 99  loss 76.5127  lr 1.000e-03\n",
      "epoch 100  loss 77.7463  lr 1.000e-03\n",
      "epoch 101  loss 77.9997  lr 1.000e-03\n",
      "epoch 102  loss 76.9018  lr 1.000e-03\n",
      "epoch 103  loss 75.9630  lr 1.000e-03\n",
      "epoch 104  loss 78.0639  lr 1.000e-03\n",
      "epoch 105  loss 75.9788  lr 1.000e-03\n",
      "epoch 106  loss 81.8291  lr 1.000e-03\n",
      "epoch 107  loss 76.5566  lr 1.000e-03\n",
      "epoch 108  loss 75.9763  lr 1.000e-03\n",
      "epoch 109  loss 76.1235  lr 1.000e-03\n",
      "epoch 110  loss 74.9887  lr 1.000e-03\n",
      "epoch 111  loss 74.6598  lr 1.000e-03\n",
      "epoch 112  loss 76.8800  lr 1.000e-03\n",
      "epoch 113  loss 74.7919  lr 1.000e-03\n",
      "epoch 114  loss 73.3460  lr 1.000e-03\n",
      "epoch 115  loss 74.2348  lr 1.000e-03\n",
      "epoch 116  loss 74.6175  lr 1.000e-03\n",
      "epoch 117  loss 75.4250  lr 1.000e-03\n",
      "epoch 118  loss 75.5143  lr 1.000e-03\n",
      "epoch 119  loss 77.1995  lr 1.000e-03\n",
      "epoch 120  loss 75.8082  lr 1.000e-03\n",
      "epoch 121  loss 73.4866  lr 1.000e-03\n",
      "epoch 122  loss 74.4511  lr 1.000e-03\n",
      "epoch 123  loss 73.2627  lr 1.000e-03\n",
      "epoch 124  loss 73.5873  lr 1.000e-03\n",
      "epoch 125  loss 70.1689  lr 1.000e-03\n",
      "epoch 126  loss 74.0346  lr 1.000e-03\n",
      "epoch 127  loss 74.0130  lr 1.000e-03\n",
      "epoch 128  loss 72.0463  lr 1.000e-03\n",
      "epoch 129  loss 73.6966  lr 1.000e-03\n",
      "epoch 130  loss 71.8364  lr 1.000e-03\n",
      "epoch 131  loss 74.8725  lr 1.000e-03\n",
      "epoch 132  loss 71.6339  lr 1.000e-03\n",
      "epoch 133  loss 73.1851  lr 1.000e-03\n",
      "epoch 134  loss 70.9885  lr 1.000e-03\n",
      "epoch 135  loss 74.4570  lr 1.000e-03\n",
      "epoch 136  loss 73.1853  lr 1.000e-03\n",
      "epoch 137  loss 74.1215  lr 1.000e-03\n",
      "epoch 138  loss 70.0962  lr 1.000e-03\n",
      "epoch 139  loss 72.3871  lr 1.000e-03\n",
      "epoch 140  loss 71.5892  lr 1.000e-03\n",
      "epoch 141  loss 71.5714  lr 1.000e-03\n",
      "epoch 142  loss 72.2209  lr 1.000e-03\n",
      "epoch 143  loss 72.2390  lr 1.000e-03\n",
      "epoch 144  loss 71.0247  lr 1.000e-03\n",
      "epoch 145  loss 72.4145  lr 1.000e-03\n",
      "epoch 146  loss 72.5573  lr 1.000e-03\n",
      "epoch 147  loss 70.9535  lr 1.000e-03\n",
      "epoch 148  loss 72.2362  lr 1.000e-03\n",
      "epoch 149  loss 71.0012  lr 1.000e-03\n",
      "epoch 150  loss 69.8540  lr 1.000e-03\n",
      "epoch 151  loss 71.9030  lr 1.000e-03\n",
      "epoch 152  loss 71.6813  lr 1.000e-03\n",
      "epoch 153  loss 70.8863  lr 1.000e-03\n",
      "epoch 154  loss 70.8383  lr 1.000e-03\n",
      "epoch 155  loss 71.4046  lr 1.000e-03\n",
      "epoch 156  loss 70.4907  lr 1.000e-03\n",
      "epoch 157  loss 70.4110  lr 1.000e-03\n",
      "epoch 158  loss 70.5294  lr 1.000e-03\n",
      "epoch 159  loss 70.2209  lr 1.000e-03\n",
      "epoch 160  loss 70.8673  lr 1.000e-03\n",
      "epoch 161  loss 70.7184  lr 1.000e-03\n",
      "epoch 162  loss 70.4515  lr 1.000e-03\n",
      "epoch 163  loss 68.1581  lr 1.000e-03\n",
      "epoch 164  loss 68.2278  lr 1.000e-03\n",
      "epoch 165  loss 70.4425  lr 1.000e-03\n",
      "epoch 166  loss 72.4783  lr 1.000e-03\n",
      "epoch 167  loss 68.9864  lr 1.000e-03\n",
      "epoch 168  loss 71.3956  lr 1.000e-03\n",
      "epoch 169  loss 68.9859  lr 1.000e-03\n",
      "epoch 170  loss 68.3536  lr 1.000e-03\n",
      "epoch 171  loss 70.1112  lr 1.000e-03\n",
      "epoch 172  loss 70.4170  lr 1.000e-03\n",
      "epoch 173  loss 68.0480  lr 1.000e-03\n",
      "epoch 174  loss 68.2339  lr 1.000e-03\n",
      "epoch 175  loss 68.3764  lr 1.000e-03\n",
      "epoch 176  loss 69.9259  lr 1.000e-03\n",
      "epoch 177  loss 67.3501  lr 1.000e-03\n",
      "epoch 178  loss 70.4888  lr 1.000e-03\n",
      "epoch 179  loss 67.7009  lr 1.000e-03\n",
      "epoch 180  loss 70.0600  lr 1.000e-03\n",
      "epoch 181  loss 69.2565  lr 1.000e-03\n",
      "epoch 182  loss 70.7741  lr 1.000e-03\n",
      "epoch 183  loss 70.6072  lr 1.000e-03\n",
      "epoch 184  loss 67.0916  lr 1.000e-03\n",
      "epoch 185  loss 69.5911  lr 1.000e-03\n",
      "epoch 186  loss 69.8718  lr 1.000e-03\n",
      "epoch 187  loss 69.6732  lr 1.000e-03\n",
      "epoch 188  loss 68.5776  lr 1.000e-03\n",
      "epoch 189  loss 68.4627  lr 1.000e-03\n",
      "epoch 190  loss 68.9491  lr 1.000e-03\n",
      "epoch 191  loss 68.2991  lr 1.000e-03\n",
      "epoch 192  loss 69.3202  lr 1.000e-03\n",
      "epoch 193  loss 68.6898  lr 1.000e-03\n",
      "epoch 194  loss 67.4107  lr 1.000e-03\n",
      "epoch 195  loss 68.6123  lr 1.000e-03\n",
      "epoch 196  loss 65.9999  lr 1.000e-03\n",
      "epoch 197  loss 66.2410  lr 1.000e-03\n",
      "epoch 198  loss 69.0134  lr 1.000e-03\n",
      "epoch 199  loss 68.2719  lr 1.000e-03\n",
      "epoch 200  loss 67.9586  lr 1.000e-03\n",
      "epoch 201  loss 68.3808  lr 1.000e-03\n",
      "epoch 202  loss 67.5604  lr 1.000e-03\n",
      "epoch 203  loss 66.8729  lr 1.000e-03\n",
      "epoch 204  loss 66.4723  lr 1.000e-03\n",
      "epoch 205  loss 69.9343  lr 1.000e-03\n",
      "epoch 206  loss 66.6777  lr 1.000e-03\n",
      "epoch 207  loss 66.7224  lr 1.000e-03\n",
      "epoch 208  loss 66.4124  lr 1.000e-03\n",
      "epoch 209  loss 70.6214  lr 1.000e-03\n",
      "epoch 210  loss 68.8981  lr 1.000e-03\n",
      "epoch 211  loss 68.4491  lr 1.000e-03\n",
      "epoch 212  loss 66.0602  lr 1.000e-03\n",
      "epoch 213  loss 66.9368  lr 1.000e-03\n",
      "epoch 214  loss 67.6129  lr 1.000e-03\n",
      "epoch 215  loss 66.3313  lr 1.000e-03\n",
      "epoch 216  loss 67.9236  lr 1.000e-03\n",
      "epoch 217  loss 68.1230  lr 1.000e-03\n",
      "epoch 218  loss 67.6825  lr 1.000e-03\n",
      "epoch 219  loss 69.1917  lr 1.000e-03\n",
      "epoch 220  loss 66.7258  lr 1.000e-03\n",
      "epoch 221  loss 67.5573  lr 1.000e-03\n",
      "epoch 222  loss 67.3502  lr 1.000e-03\n",
      "epoch 223  loss 68.3478  lr 1.000e-03\n",
      "epoch 224  loss 67.1347  lr 1.000e-03\n",
      "epoch 225  loss 68.1320  lr 1.000e-03\n",
      "epoch 226  loss 67.3554  lr 1.000e-03\n",
      "epoch 227  loss 67.6262  lr 1.000e-03\n",
      "epoch 228  loss 65.3853  lr 1.000e-03\n",
      "epoch 229  loss 65.6834  lr 1.000e-03\n",
      "epoch 230  loss 67.0915  lr 1.000e-03\n",
      "epoch 231  loss 65.4895  lr 1.000e-03\n",
      "epoch 232  loss 67.0808  lr 1.000e-03\n",
      "epoch 233  loss 64.7290  lr 1.000e-03\n",
      "epoch 234  loss 68.6602  lr 1.000e-03\n",
      "epoch 235  loss 67.0240  lr 1.000e-03\n",
      "epoch 236  loss 65.7255  lr 1.000e-03\n",
      "epoch 237  loss 64.7913  lr 1.000e-03\n",
      "epoch 238  loss 64.7257  lr 1.000e-03\n",
      "epoch 239  loss 65.3355  lr 1.000e-03\n",
      "epoch 240  loss 65.3013  lr 1.000e-03\n",
      "epoch 241  loss 65.8885  lr 1.000e-03\n",
      "epoch 242  loss 65.7244  lr 1.000e-03\n",
      "epoch 243  loss 68.0487  lr 1.000e-03\n",
      "epoch 244  loss 65.1072  lr 1.000e-03\n",
      "epoch 245  loss 66.3618  lr 1.000e-03\n",
      "epoch 246  loss 67.1795  lr 1.000e-03\n",
      "epoch 247  loss 65.2734  lr 1.000e-03\n",
      "epoch 248  loss 65.9022  lr 1.000e-03\n",
      "epoch 249  loss 66.7039  lr 1.000e-03\n",
      "epoch 250  loss 65.3256  lr 1.000e-03\n",
      "epoch 251  loss 64.6831  lr 1.000e-03\n",
      "epoch 252  loss 65.1207  lr 1.000e-03\n",
      "epoch 253  loss 66.9340  lr 1.000e-03\n",
      "epoch 254  loss 64.9740  lr 1.000e-03\n",
      "epoch 255  loss 64.6692  lr 1.000e-03\n",
      "epoch 256  loss 65.8659  lr 1.000e-03\n",
      "epoch 257  loss 61.9428  lr 1.000e-03\n",
      "epoch 258  loss 64.0924  lr 1.000e-03\n",
      "epoch 259  loss 65.7875  lr 1.000e-03\n",
      "epoch 260  loss 68.0733  lr 1.000e-03\n",
      "epoch 261  loss 63.4026  lr 1.000e-03\n",
      "epoch 262  loss 64.5724  lr 1.000e-03\n",
      "epoch 263  loss 64.8061  lr 1.000e-03\n",
      "epoch 264  loss 65.8875  lr 1.000e-03\n",
      "epoch 265  loss 64.4892  lr 1.000e-03\n",
      "epoch 266  loss 64.4217  lr 1.000e-03\n",
      "epoch 267  loss 64.2464  lr 1.000e-03\n",
      "epoch 268  loss 66.1372  lr 1.000e-03\n",
      "epoch 269  loss 64.0443  lr 1.000e-03\n",
      "epoch 270  loss 63.8368  lr 1.000e-03\n",
      "epoch 271  loss 66.3503  lr 1.000e-03\n",
      "epoch 272  loss 65.7516  lr 1.000e-03\n",
      "epoch 273  loss 63.8595  lr 1.000e-03\n",
      "epoch 274  loss 62.8436  lr 1.000e-03\n",
      "epoch 275  loss 63.1927  lr 1.000e-03\n",
      "epoch 276  loss 63.8416  lr 1.000e-03\n",
      "epoch 277  loss 65.9467  lr 1.000e-03\n",
      "epoch 278  loss 62.9337  lr 1.000e-03\n",
      "epoch 279  loss 64.6469  lr 1.000e-03\n",
      "epoch 280  loss 64.1490  lr 1.000e-03\n",
      "epoch 281  loss 63.9422  lr 1.000e-03\n",
      "epoch 282  loss 63.4259  lr 1.000e-03\n",
      "epoch 283  loss 62.6041  lr 1.000e-03\n",
      "epoch 284  loss 62.6174  lr 1.000e-03\n",
      "epoch 285  loss 65.3596  lr 1.000e-03\n",
      "epoch 286  loss 64.1597  lr 1.000e-03\n",
      "epoch 287  loss 62.8127  lr 1.000e-03\n",
      "epoch 288  loss 63.4105  lr 1.000e-03\n",
      "epoch 289  loss 63.9126  lr 1.000e-03\n",
      "epoch 290  loss 64.3234  lr 1.000e-03\n",
      "epoch 291  loss 63.3579  lr 1.000e-03\n",
      "epoch 292  loss 61.1609  lr 1.000e-03\n",
      "epoch 293  loss 63.9519  lr 1.000e-03\n",
      "epoch 294  loss 61.6124  lr 1.000e-03\n",
      "epoch 295  loss 61.5594  lr 1.000e-03\n",
      "epoch 296  loss 64.1290  lr 1.000e-03\n",
      "epoch 297  loss 62.5578  lr 1.000e-03\n",
      "epoch 298  loss 63.4171  lr 1.000e-03\n",
      "epoch 299  loss 63.5269  lr 1.000e-03\n",
      "epoch 300  loss 63.8073  lr 1.000e-03\n",
      "epoch 301  loss 63.9037  lr 1.000e-03\n",
      "epoch 302  loss 65.9650  lr 1.000e-03\n",
      "epoch 303  loss 64.0647  lr 1.000e-03\n",
      "epoch 304  loss 62.4739  lr 1.000e-03\n",
      "epoch 305  loss 62.5158  lr 1.000e-03\n",
      "epoch 306  loss 62.9549  lr 1.000e-03\n",
      "epoch 307  loss 63.5411  lr 1.000e-03\n",
      "epoch 308  loss 62.8643  lr 1.000e-03\n",
      "epoch 309  loss 61.1778  lr 1.000e-03\n",
      "epoch 310  loss 63.8421  lr 1.000e-03\n",
      "epoch 311  loss 61.0867  lr 1.000e-03\n",
      "epoch 312  loss 62.9468  lr 1.000e-03\n",
      "epoch 313  loss 62.8123  lr 1.000e-03\n",
      "epoch 314  loss 63.5190  lr 1.000e-03\n",
      "epoch 315  loss 64.6312  lr 1.000e-03\n",
      "epoch 316  loss 61.9183  lr 1.000e-03\n",
      "epoch 317  loss 62.3823  lr 1.000e-03\n",
      "epoch 318  loss 62.7401  lr 1.000e-03\n",
      "epoch 319  loss 63.0771  lr 1.000e-03\n",
      "epoch 320  loss 60.4626  lr 1.000e-03\n",
      "epoch 321  loss 62.8145  lr 1.000e-03\n",
      "epoch 322  loss 63.6798  lr 1.000e-03\n",
      "epoch 323  loss 63.9668  lr 1.000e-03\n",
      "epoch 324  loss 63.7689  lr 1.000e-03\n",
      "epoch 325  loss 59.8382  lr 1.000e-03\n",
      "epoch 326  loss 61.5574  lr 1.000e-03\n",
      "epoch 327  loss 63.8614  lr 1.000e-03\n",
      "epoch 328  loss 60.3579  lr 1.000e-03\n",
      "epoch 329  loss 62.1658  lr 1.000e-03\n",
      "epoch 330  loss 63.4856  lr 1.000e-03\n",
      "epoch 331  loss 64.1751  lr 1.000e-03\n",
      "epoch 332  loss 62.5163  lr 1.000e-03\n",
      "epoch 333  loss 63.3058  lr 1.000e-03\n",
      "epoch 334  loss 61.6254  lr 1.000e-03\n",
      "epoch 335  loss 62.1392  lr 1.000e-03\n",
      "epoch 336  loss 63.3404  lr 1.000e-03\n",
      "epoch 337  loss 61.7761  lr 1.000e-03\n",
      "epoch 338  loss 58.5736  lr 1.000e-03\n",
      "epoch 339  loss 61.3939  lr 1.000e-03\n",
      "epoch 340  loss 63.3015  lr 1.000e-03\n",
      "epoch 341  loss 62.0890  lr 1.000e-03\n",
      "epoch 342  loss 62.6688  lr 1.000e-03\n",
      "epoch 343  loss 62.6325  lr 1.000e-03\n",
      "epoch 344  loss 61.2804  lr 1.000e-03\n",
      "epoch 345  loss 61.5756  lr 1.000e-03\n",
      "epoch 346  loss 64.0113  lr 1.000e-03\n",
      "epoch 347  loss 60.7701  lr 1.000e-03\n",
      "epoch 348  loss 62.4940  lr 1.000e-03\n",
      "epoch 349  loss 61.6613  lr 1.000e-03\n",
      "epoch 350  loss 61.8259  lr 1.000e-03\n",
      "epoch 351  loss 60.7986  lr 1.000e-03\n",
      "epoch 352  loss 60.3162  lr 1.000e-03\n",
      "epoch 353  loss 60.8781  lr 1.000e-03\n",
      "epoch 354  loss 61.6602  lr 1.000e-03\n",
      "epoch 355  loss 63.1910  lr 1.000e-03\n",
      "epoch 356  loss 62.7705  lr 1.000e-03\n",
      "epoch 357  loss 62.3356  lr 1.000e-03\n",
      "epoch 358  loss 59.7045  lr 1.000e-03\n",
      "epoch 359  loss 60.6366  lr 1.000e-03\n",
      "epoch 360  loss 61.0920  lr 1.000e-03\n",
      "epoch 361  loss 62.7202  lr 1.000e-03\n",
      "epoch 362  loss 60.9920  lr 1.000e-03\n",
      "epoch 363  loss 61.1720  lr 1.000e-03\n",
      "epoch 364  loss 63.3035  lr 1.000e-03\n",
      "epoch 365  loss 60.7068  lr 1.000e-03\n",
      "epoch 366  loss 61.3546  lr 1.000e-03\n",
      "epoch 367  loss 61.2795  lr 1.000e-03\n",
      "epoch 368  loss 61.5236  lr 1.000e-03\n",
      "epoch 369  loss 61.1938  lr 1.000e-03\n",
      "epoch 370  loss 59.5840  lr 1.000e-03\n",
      "epoch 371  loss 60.9054  lr 1.000e-03\n",
      "epoch 372  loss 64.2988  lr 1.000e-03\n",
      "epoch 373  loss 61.6041  lr 1.000e-03\n",
      "epoch 374  loss 62.1981  lr 1.000e-03\n",
      "epoch 375  loss 61.6771  lr 1.000e-03\n",
      "epoch 376  loss 62.3781  lr 1.000e-03\n",
      "epoch 377  loss 62.5937  lr 1.000e-03\n",
      "epoch 378  loss 60.3124  lr 1.000e-03\n",
      "epoch 379  loss 60.3846  lr 1.000e-03\n",
      "epoch 380  loss 62.4891  lr 1.000e-03\n",
      "epoch 381  loss 60.3416  lr 1.000e-03\n",
      "epoch 382  loss 62.2323  lr 1.000e-03\n",
      "epoch 383  loss 62.4200  lr 1.000e-03\n",
      "epoch 384  loss 62.3864  lr 1.000e-03\n",
      "epoch 385  loss 59.8136  lr 1.000e-03\n",
      "epoch 386  loss 60.0410  lr 1.000e-03\n",
      "epoch 387  loss 62.1710  lr 1.000e-03\n",
      "epoch 388  loss 61.9960  lr 1.000e-03\n",
      "epoch 389  loss 61.7416  lr 1.000e-03\n",
      "epoch 390  loss 59.6390  lr 1.000e-03\n",
      "epoch 391  loss 57.7302  lr 1.000e-03\n",
      "epoch 392  loss 59.6372  lr 1.000e-03\n",
      "epoch 393  loss 61.1157  lr 1.000e-03\n",
      "epoch 394  loss 60.6636  lr 1.000e-03\n",
      "epoch 395  loss 60.4409  lr 1.000e-03\n",
      "epoch 396  loss 59.8012  lr 1.000e-03\n",
      "epoch 397  loss 59.3986  lr 1.000e-03\n",
      "epoch 398  loss 60.5765  lr 1.000e-03\n",
      "epoch 399  loss 60.9213  lr 1.000e-03\n",
      "epoch 400  loss 61.4755  lr 1.000e-03\n",
      "epoch 401  loss 60.2375  lr 1.000e-03\n",
      "epoch 402  loss 60.4212  lr 1.000e-03\n",
      "epoch 403  loss 62.0235  lr 1.000e-03\n",
      "epoch 404  loss 61.5110  lr 1.000e-03\n",
      "epoch 405  loss 60.8700  lr 1.000e-03\n",
      "epoch 406  loss 59.9504  lr 1.000e-03\n",
      "epoch 407  loss 60.3260  lr 1.000e-03\n",
      "epoch 408  loss 60.8551  lr 1.000e-03\n",
      "epoch 409  loss 58.8329  lr 1.000e-03\n",
      "epoch 410  loss 57.4552  lr 1.000e-03\n",
      "epoch 411  loss 60.9602  lr 1.000e-03\n",
      "epoch 412  loss 60.6690  lr 1.000e-03\n",
      "epoch 413  loss 61.7532  lr 1.000e-03\n",
      "epoch 414  loss 60.3225  lr 1.000e-03\n",
      "epoch 415  loss 60.1427  lr 1.000e-03\n",
      "epoch 416  loss 59.6064  lr 1.000e-03\n",
      "epoch 417  loss 60.6514  lr 1.000e-03\n",
      "epoch 418  loss 58.6605  lr 1.000e-03\n",
      "epoch 419  loss 59.6631  lr 1.000e-03\n",
      "epoch 420  loss 58.8512  lr 1.000e-03\n",
      "epoch 421  loss 58.7851  lr 1.000e-03\n",
      "epoch 422  loss 60.3034  lr 1.000e-03\n",
      "epoch 423  loss 60.5585  lr 1.000e-03\n",
      "epoch 424  loss 60.3383  lr 1.000e-03\n",
      "epoch 425  loss 60.7871  lr 1.000e-03\n",
      "epoch 426  loss 61.3742  lr 1.000e-03\n",
      "epoch 427  loss 60.7118  lr 1.000e-03\n",
      "epoch 428  loss 60.7237  lr 1.000e-03\n",
      "epoch 429  loss 58.2761  lr 1.000e-03\n",
      "epoch 430  loss 59.0079  lr 1.000e-03\n",
      "epoch 431  loss 59.7647  lr 1.000e-03\n",
      "epoch 432  loss 59.9156  lr 1.000e-03\n",
      "epoch 433  loss 58.6553  lr 1.000e-03\n",
      "epoch 434  loss 60.3296  lr 1.000e-03\n",
      "epoch 435  loss 58.5269  lr 1.000e-03\n",
      "epoch 436  loss 60.8267  lr 1.000e-03\n",
      "epoch 437  loss 58.6243  lr 1.000e-03\n",
      "epoch 438  loss 58.2586  lr 1.000e-03\n",
      "epoch 439  loss 58.7200  lr 1.000e-03\n",
      "epoch 440  loss 57.8320  lr 1.000e-03\n",
      "epoch 441  loss 59.2597  lr 1.000e-03\n",
      "epoch 442  loss 61.4988  lr 1.000e-03\n",
      "epoch 443  loss 60.4649  lr 1.000e-03\n",
      "epoch 444  loss 59.0285  lr 1.000e-03\n",
      "epoch 445  loss 60.3533  lr 1.000e-03\n",
      "epoch 446  loss 60.2937  lr 1.000e-03\n",
      "epoch 447  loss 60.5722  lr 1.000e-03\n",
      "epoch 448  loss 59.0908  lr 1.000e-03\n",
      "epoch 449  loss 59.0263  lr 1.000e-03\n",
      "epoch 450  loss 59.6756  lr 1.000e-03\n",
      "epoch 451  loss 58.1682  lr 1.000e-03\n",
      "epoch 452  loss 60.4808  lr 1.000e-03\n",
      "epoch 453  loss 60.5006  lr 1.000e-03\n",
      "epoch 454  loss 59.7219  lr 1.000e-03\n",
      "epoch 455  loss 59.2720  lr 1.000e-03\n",
      "epoch 456  loss 59.2894  lr 1.000e-03\n",
      "epoch 457  loss 59.3751  lr 1.000e-03\n",
      "epoch 458  loss 59.6682  lr 1.000e-03\n",
      "epoch 459  loss 59.9048  lr 1.000e-03\n",
      "epoch 460  loss 60.0059  lr 1.000e-03\n",
      "epoch 461  loss 59.8765  lr 1.000e-03\n",
      "epoch 462  loss 58.3179  lr 1.000e-03\n",
      "epoch 463  loss 60.9096  lr 1.000e-03\n",
      "epoch 464  loss 59.0363  lr 1.000e-03\n",
      "epoch 465  loss 59.1443  lr 1.000e-03\n",
      "epoch 466  loss 58.7019  lr 1.000e-03\n",
      "epoch 467  loss 58.6091  lr 1.000e-03\n",
      "epoch 468  loss 58.0968  lr 1.000e-03\n",
      "epoch 469  loss 58.3126  lr 1.000e-03\n",
      "epoch 470  loss 56.8077  lr 1.000e-03\n",
      "epoch 471  loss 60.4352  lr 1.000e-03\n",
      "epoch 472  loss 60.2448  lr 1.000e-03\n",
      "epoch 473  loss 56.7237  lr 1.000e-03\n",
      "epoch 474  loss 58.1976  lr 1.000e-03\n",
      "epoch 475  loss 59.2867  lr 1.000e-03\n",
      "epoch 476  loss 59.5489  lr 1.000e-03\n",
      "epoch 477  loss 61.4882  lr 1.000e-03\n",
      "epoch 478  loss 61.4762  lr 1.000e-03\n",
      "epoch 479  loss 58.1672  lr 1.000e-03\n",
      "epoch 480  loss 59.1014  lr 1.000e-03\n",
      "epoch 481  loss 59.1442  lr 1.000e-03\n",
      "epoch 482  loss 59.0516  lr 1.000e-03\n",
      "epoch 483  loss 59.6708  lr 1.000e-03\n",
      "epoch 484  loss 59.5159  lr 1.000e-03\n",
      "epoch 485  loss 59.0792  lr 1.000e-03\n",
      "epoch 486  loss 60.0126  lr 1.000e-03\n",
      "epoch 487  loss 57.6287  lr 1.000e-03\n",
      "epoch 488  loss 58.1279  lr 1.000e-03\n",
      "epoch 489  loss 58.7049  lr 1.000e-03\n",
      "epoch 490  loss 59.5657  lr 1.000e-03\n",
      "epoch 491  loss 58.0010  lr 1.000e-03\n",
      "epoch 492  loss 57.3403  lr 1.000e-03\n",
      "epoch 493  loss 57.4608  lr 1.000e-03\n",
      "epoch 494  loss 58.9073  lr 1.000e-03\n",
      "epoch 495  loss 58.9347  lr 1.000e-03\n",
      "epoch 496  loss 57.3401  lr 1.000e-03\n",
      "epoch 497  loss 58.9050  lr 1.000e-03\n",
      "epoch 498  loss 58.5286  lr 1.000e-03\n",
      "epoch 499  loss 58.1452  lr 1.000e-03\n",
      "epoch 500  loss 57.8972  lr 1.000e-03\n",
      "epoch 501  loss 59.1319  lr 1.000e-03\n",
      "epoch 502  loss 59.3684  lr 1.000e-03\n",
      "epoch 503  loss 60.6558  lr 1.000e-03\n",
      "epoch 504  loss 58.7966  lr 1.000e-03\n",
      "epoch 505  loss 59.1191  lr 1.000e-03\n",
      "epoch 506  loss 57.2179  lr 1.000e-03\n",
      "epoch 507  loss 58.0492  lr 1.000e-03\n",
      "epoch 508  loss 58.1093  lr 1.000e-03\n",
      "epoch 509  loss 59.4905  lr 1.000e-03\n",
      "epoch 510  loss 59.7329  lr 1.000e-03\n",
      "epoch 511  loss 58.6983  lr 1.000e-03\n",
      "epoch 512  loss 56.8969  lr 1.000e-03\n",
      "epoch 513  loss 58.3825  lr 1.000e-03\n",
      "epoch 514  loss 58.2630  lr 1.000e-03\n",
      "epoch 515  loss 55.8156  lr 1.000e-03\n",
      "epoch 516  loss 59.6407  lr 1.000e-03\n",
      "epoch 517  loss 57.3395  lr 1.000e-03\n",
      "epoch 518  loss 58.8054  lr 1.000e-03\n",
      "epoch 519  loss 58.4787  lr 1.000e-03\n",
      "epoch 520  loss 57.7271  lr 1.000e-03\n",
      "epoch 521  loss 56.3320  lr 1.000e-03\n",
      "epoch 522  loss 58.1202  lr 1.000e-03\n",
      "epoch 523  loss 58.5529  lr 1.000e-03\n",
      "epoch 524  loss 58.1646  lr 1.000e-03\n",
      "epoch 525  loss 59.9971  lr 1.000e-03\n",
      "epoch 526  loss 58.0366  lr 1.000e-03\n",
      "epoch 527  loss 58.2669  lr 1.000e-03\n",
      "epoch 528  loss 56.7645  lr 1.000e-03\n",
      "epoch 529  loss 58.2983  lr 1.000e-03\n",
      "epoch 530  loss 58.3660  lr 1.000e-03\n",
      "epoch 531  loss 59.2167  lr 1.000e-03\n",
      "epoch 532  loss 57.4726  lr 1.000e-03\n",
      "epoch 533  loss 57.0318  lr 1.000e-03\n",
      "epoch 534  loss 57.3284  lr 1.000e-03\n",
      "epoch 535  loss 59.5338  lr 1.000e-03\n",
      "epoch 536  loss 58.1265  lr 1.000e-03\n",
      "epoch 537  loss 57.6011  lr 1.000e-03\n",
      "epoch 538  loss 56.4704  lr 1.000e-03\n",
      "epoch 539  loss 58.9664  lr 1.000e-03\n",
      "epoch 540  loss 57.8781  lr 1.000e-03\n",
      "epoch 541  loss 56.7878  lr 1.000e-03\n",
      "epoch 542  loss 57.8954  lr 1.000e-03\n",
      "epoch 543  loss 57.0299  lr 1.000e-03\n",
      "epoch 544  loss 59.3385  lr 1.000e-03\n",
      "epoch 545  loss 59.3444  lr 1.000e-03\n",
      "epoch 546  loss 59.6970  lr 1.000e-03\n",
      "epoch 547  loss 58.5945  lr 1.000e-03\n",
      "epoch 548  loss 57.8141  lr 1.000e-03\n",
      "epoch 549  loss 57.7968  lr 1.000e-03\n",
      "epoch 550  loss 56.6852  lr 1.000e-03\n",
      "epoch 551  loss 57.9681  lr 1.000e-03\n",
      "epoch 552  loss 57.1104  lr 1.000e-03\n",
      "epoch 553  loss 58.5633  lr 1.000e-03\n",
      "epoch 554  loss 55.8477  lr 1.000e-03\n",
      "epoch 555  loss 58.2592  lr 1.000e-03\n",
      "epoch 556  loss 57.9698  lr 1.000e-03\n",
      "epoch 557  loss 57.2739  lr 1.000e-03\n",
      "epoch 558  loss 56.8536  lr 1.000e-03\n",
      "epoch 559  loss 57.1571  lr 1.000e-03\n",
      "epoch 560  loss 56.0664  lr 1.000e-03\n",
      "epoch 561  loss 59.2135  lr 1.000e-03\n",
      "epoch 562  loss 58.7816  lr 1.000e-03\n",
      "epoch 563  loss 59.9327  lr 1.000e-03\n",
      "epoch 564  loss 56.8973  lr 1.000e-03\n",
      "epoch 565  loss 57.6514  lr 1.000e-03\n",
      "epoch 566  loss 58.5622  lr 1.000e-03\n",
      "epoch 567  loss 57.8310  lr 1.000e-03\n",
      "epoch 568  loss 58.6385  lr 1.000e-03\n",
      "epoch 569  loss 56.3287  lr 1.000e-03\n",
      "epoch 570  loss 58.7935  lr 1.000e-03\n",
      "epoch 571  loss 56.4906  lr 1.000e-03\n",
      "epoch 572  loss 57.1627  lr 1.000e-03\n",
      "epoch 573  loss 57.4683  lr 1.000e-03\n",
      "epoch 574  loss 56.4690  lr 1.000e-03\n",
      "epoch 575  loss 56.9338  lr 1.000e-03\n",
      "epoch 576  loss 56.2156  lr 1.000e-03\n",
      "epoch 577  loss 58.2811  lr 1.000e-03\n",
      "epoch 578  loss 57.8550  lr 1.000e-03\n",
      "epoch 579  loss 59.3052  lr 1.000e-03\n",
      "epoch 580  loss 56.4579  lr 1.000e-03\n",
      "epoch 581  loss 56.1145  lr 1.000e-03\n",
      "epoch 582  loss 56.4149  lr 1.000e-03\n",
      "epoch 583  loss 57.3298  lr 1.000e-03\n",
      "epoch 584  loss 58.0100  lr 1.000e-03\n",
      "epoch 585  loss 57.1035  lr 1.000e-03\n",
      "epoch 586  loss 58.3756  lr 1.000e-03\n",
      "epoch 587  loss 58.2943  lr 1.000e-03\n",
      "epoch 588  loss 57.8174  lr 1.000e-03\n",
      "epoch 589  loss 58.6494  lr 1.000e-03\n",
      "epoch 590  loss 57.5928  lr 1.000e-03\n",
      "epoch 591  loss 59.0939  lr 1.000e-03\n",
      "epoch 592  loss 56.9247  lr 1.000e-03\n",
      "epoch 593  loss 59.1049  lr 1.000e-03\n",
      "epoch 594  loss 57.3729  lr 1.000e-03\n",
      "epoch 595  loss 57.4012  lr 1.000e-03\n",
      "epoch 596  loss 60.6345  lr 1.000e-03\n",
      "epoch 597  loss 57.0269  lr 1.000e-03\n",
      "epoch 598  loss 56.3104  lr 1.000e-03\n",
      "epoch 599  loss 57.6549  lr 1.000e-03\n",
      "epoch 600  loss 56.1441  lr 1.000e-03\n",
      "epoch 601  loss 55.2190  lr 1.000e-03\n",
      "epoch 602  loss 58.3942  lr 1.000e-03\n",
      "epoch 603  loss 57.0094  lr 1.000e-03\n",
      "epoch 604  loss 57.0332  lr 1.000e-03\n",
      "epoch 605  loss 57.2933  lr 1.000e-03\n",
      "epoch 606  loss 58.4655  lr 1.000e-03\n",
      "epoch 607  loss 58.4095  lr 1.000e-03\n",
      "epoch 608  loss 56.1167  lr 1.000e-03\n",
      "epoch 609  loss 58.1791  lr 1.000e-03\n",
      "epoch 610  loss 57.8395  lr 1.000e-03\n",
      "epoch 611  loss 56.2585  lr 1.000e-03\n",
      "epoch 612  loss 57.2012  lr 1.000e-03\n",
      "epoch 613  loss 56.2916  lr 1.000e-03\n",
      "epoch 614  loss 56.8600  lr 1.000e-03\n",
      "epoch 615  loss 57.1660  lr 1.000e-03\n",
      "epoch 616  loss 58.7832  lr 1.000e-03\n",
      "epoch 617  loss 56.0645  lr 1.000e-03\n",
      "epoch 618  loss 57.6147  lr 1.000e-03\n",
      "epoch 619  loss 57.0539  lr 1.000e-03\n",
      "epoch 620  loss 57.9279  lr 1.000e-03\n",
      "epoch 621  loss 56.5662  lr 1.000e-03\n",
      "epoch 622  loss 58.9039  lr 1.000e-03\n",
      "epoch 623  loss 57.5496  lr 1.000e-03\n",
      "epoch 624  loss 57.5525  lr 1.000e-03\n",
      "epoch 625  loss 55.7132  lr 1.000e-03\n",
      "epoch 626  loss 56.5619  lr 1.000e-03\n",
      "epoch 627  loss 57.5735  lr 1.000e-03\n",
      "epoch 628  loss 57.3267  lr 1.000e-03\n",
      "epoch 629  loss 56.8701  lr 1.000e-03\n",
      "epoch 630  loss 55.8028  lr 1.000e-03\n",
      "epoch 631  loss 56.4411  lr 1.000e-03\n",
      "epoch 632  loss 56.4339  lr 1.000e-03\n",
      "epoch 633  loss 56.1086  lr 1.000e-03\n",
      "epoch 634  loss 56.2338  lr 1.000e-03\n",
      "epoch 635  loss 57.0013  lr 1.000e-03\n",
      "epoch 636  loss 56.5658  lr 1.000e-03\n",
      "epoch 637  loss 57.0748  lr 1.000e-03\n",
      "epoch 638  loss 55.7718  lr 1.000e-03\n",
      "epoch 639  loss 55.9006  lr 1.000e-03\n",
      "epoch 640  loss 57.8213  lr 1.000e-03\n",
      "epoch 641  loss 55.8670  lr 1.000e-03\n",
      "epoch 642  loss 54.1122  lr 1.000e-03\n",
      "epoch 643  loss 55.8907  lr 1.000e-03\n",
      "epoch 644  loss 55.2739  lr 1.000e-03\n",
      "epoch 645  loss 58.4587  lr 1.000e-03\n",
      "epoch 646  loss 59.5989  lr 1.000e-03\n",
      "epoch 647  loss 58.1772  lr 1.000e-03\n",
      "epoch 648  loss 55.9311  lr 1.000e-03\n",
      "epoch 649  loss 58.3381  lr 1.000e-03\n",
      "epoch 650  loss 58.3813  lr 1.000e-03\n",
      "epoch 651  loss 57.6629  lr 1.000e-03\n",
      "epoch 652  loss 54.8610  lr 1.000e-03\n",
      "epoch 653  loss 55.1027  lr 1.000e-03\n",
      "epoch 654  loss 56.6065  lr 1.000e-03\n",
      "epoch 655  loss 55.0667  lr 1.000e-03\n",
      "epoch 656  loss 56.2694  lr 1.000e-03\n",
      "epoch 657  loss 55.9795  lr 1.000e-03\n",
      "epoch 658  loss 57.0861  lr 1.000e-03\n",
      "epoch 659  loss 56.6469  lr 1.000e-03\n",
      "epoch 660  loss 56.5961  lr 1.000e-03\n",
      "epoch 661  loss 54.5226  lr 1.000e-03\n",
      "epoch 662  loss 57.3488  lr 1.000e-03\n",
      "epoch 663  loss 56.9082  lr 1.000e-03\n",
      "epoch 664  loss 58.6902  lr 1.000e-03\n",
      "epoch 665  loss 54.8236  lr 1.000e-03\n",
      "epoch 666  loss 57.2648  lr 1.000e-03\n",
      "epoch 667  loss 58.0374  lr 1.000e-03\n",
      "epoch 668  loss 57.0851  lr 1.000e-03\n",
      "epoch 669  loss 55.3665  lr 1.000e-03\n",
      "epoch 670  loss 56.9734  lr 1.000e-03\n",
      "epoch 671  loss 55.5482  lr 1.000e-03\n",
      "epoch 672  loss 56.2707  lr 1.000e-03\n",
      "epoch 673  loss 57.2053  lr 1.000e-03\n",
      "epoch 674  loss 57.5056  lr 1.000e-03\n",
      "epoch 675  loss 54.1502  lr 1.000e-03\n",
      "epoch 676  loss 57.6097  lr 1.000e-03\n",
      "epoch 677  loss 55.2930  lr 1.000e-03\n",
      "epoch 678  loss 57.7486  lr 1.000e-03\n",
      "epoch 679  loss 56.7009  lr 1.000e-03\n",
      "epoch 680  loss 55.3142  lr 1.000e-03\n",
      "epoch 681  loss 55.5350  lr 1.000e-03\n",
      "epoch 682  loss 55.2904  lr 1.000e-03\n",
      "epoch 683  loss 54.9389  lr 1.000e-03\n",
      "epoch 684  loss 55.8437  lr 1.000e-03\n",
      "epoch 685  loss 54.3938  lr 1.000e-03\n",
      "epoch 686  loss 56.5115  lr 1.000e-03\n",
      "epoch 687  loss 55.3503  lr 1.000e-03\n",
      "epoch 688  loss 55.7091  lr 1.000e-03\n",
      "epoch 689  loss 56.6843  lr 1.000e-03\n",
      "epoch 690  loss 54.9800  lr 1.000e-03\n",
      "epoch 691  loss 56.0499  lr 1.000e-03\n",
      "epoch 692  loss 58.0824  lr 1.000e-03\n",
      "epoch 693  loss 58.0410  lr 1.000e-03\n",
      "epoch 694  loss 56.3107  lr 1.000e-03\n",
      "epoch 695  loss 56.1158  lr 1.000e-03\n",
      "epoch 696  loss 56.1442  lr 1.000e-03\n",
      "epoch 697  loss 56.0676  lr 1.000e-03\n",
      "epoch 698  loss 57.2286  lr 1.000e-03\n",
      "epoch 699  loss 56.6039  lr 1.000e-03\n",
      "epoch 700  loss 56.6684  lr 1.000e-03\n",
      "epoch 701  loss 55.5584  lr 1.000e-03\n",
      "epoch 702  loss 56.0297  lr 1.000e-03\n",
      "epoch 703  loss 53.9482  lr 1.000e-03\n",
      "epoch 704  loss 55.4243  lr 1.000e-03\n",
      "epoch 705  loss 56.0222  lr 1.000e-03\n",
      "epoch 706  loss 56.0430  lr 1.000e-03\n",
      "epoch 707  loss 54.1765  lr 1.000e-03\n",
      "epoch 708  loss 56.0134  lr 1.000e-03\n",
      "epoch 709  loss 56.4062  lr 1.000e-03\n",
      "epoch 710  loss 58.3071  lr 1.000e-03\n",
      "epoch 711  loss 56.3190  lr 1.000e-03\n",
      "epoch 712  loss 54.4926  lr 1.000e-03\n",
      "epoch 713  loss 56.8304  lr 1.000e-03\n",
      "epoch 714  loss 56.3096  lr 1.000e-03\n",
      "epoch 715  loss 52.7704  lr 1.000e-03\n",
      "epoch 716  loss 55.5077  lr 1.000e-03\n",
      "epoch 717  loss 55.0531  lr 1.000e-03\n",
      "epoch 718  loss 55.7382  lr 1.000e-03\n",
      "epoch 719  loss 57.5386  lr 1.000e-03\n",
      "epoch 720  loss 57.1516  lr 1.000e-03\n",
      "epoch 721  loss 56.8453  lr 1.000e-03\n",
      "epoch 722  loss 56.8917  lr 1.000e-03\n",
      "epoch 723  loss 55.6437  lr 1.000e-03\n",
      "epoch 724  loss 55.5786  lr 1.000e-03\n",
      "epoch 725  loss 55.7097  lr 1.000e-03\n",
      "epoch 726  loss 55.7690  lr 1.000e-03\n",
      "epoch 727  loss 53.6705  lr 1.000e-03\n",
      "epoch 728  loss 55.2672  lr 1.000e-03\n",
      "epoch 729  loss 53.4284  lr 1.000e-03\n",
      "epoch 730  loss 55.8784  lr 1.000e-03\n",
      "epoch 731  loss 54.5141  lr 1.000e-03\n",
      "epoch 732  loss 55.6722  lr 1.000e-03\n",
      "epoch 733  loss 55.0770  lr 1.000e-03\n",
      "epoch 734  loss 57.0380  lr 1.000e-03\n",
      "epoch 735  loss 57.3470  lr 1.000e-03\n",
      "epoch 736  loss 54.9999  lr 1.000e-03\n",
      "epoch 737  loss 55.7298  lr 1.000e-03\n",
      "epoch 738  loss 56.6698  lr 1.000e-03\n",
      "epoch 739  loss 59.7495  lr 1.000e-03\n",
      "epoch 740  loss 55.3480  lr 1.000e-03\n",
      "epoch 741  loss 54.7787  lr 1.000e-03\n",
      "epoch 742  loss 56.8172  lr 1.000e-03\n",
      "epoch 743  loss 55.6333  lr 1.000e-03\n",
      "epoch 744  loss 55.4417  lr 1.000e-03\n",
      "epoch 745  loss 56.0735  lr 1.000e-03\n",
      "epoch 746  loss 56.4607  lr 1.000e-03\n",
      "epoch 747  loss 53.5579  lr 1.000e-03\n",
      "epoch 748  loss 55.6035  lr 1.000e-03\n",
      "epoch 749  loss 55.6563  lr 1.000e-03\n",
      "epoch 750  loss 56.1605  lr 1.000e-03\n",
      "epoch 751  loss 55.7175  lr 1.000e-03\n",
      "epoch 752  loss 57.8309  lr 1.000e-03\n",
      "epoch 753  loss 54.3801  lr 1.000e-03\n",
      "epoch 754  loss 55.2025  lr 1.000e-03\n",
      "epoch 755  loss 54.8123  lr 1.000e-03\n",
      "epoch 756  loss 55.0241  lr 1.000e-03\n",
      "epoch 757  loss 57.5406  lr 1.000e-03\n",
      "epoch 758  loss 57.5582  lr 1.000e-03\n",
      "epoch 759  loss 55.2483  lr 1.000e-03\n",
      "epoch 760  loss 55.6154  lr 1.000e-03\n",
      "epoch 761  loss 55.2938  lr 1.000e-03\n",
      "epoch 762  loss 55.2148  lr 1.000e-03\n",
      "epoch 763  loss 54.3476  lr 1.000e-03\n",
      "epoch 764  loss 53.3870  lr 1.000e-03\n",
      "epoch 765  loss 56.1091  lr 1.000e-03\n",
      "epoch 766  loss 57.8480  lr 1.000e-03\n",
      "epoch 767  loss 57.7250  lr 1.000e-03\n",
      "epoch 768  loss 56.5267  lr 1.000e-03\n",
      "epoch 769  loss 56.0346  lr 1.000e-03\n",
      "epoch 770  loss 56.7909  lr 1.000e-03\n",
      "epoch 771  loss 54.6596  lr 1.000e-03\n",
      "epoch 772  loss 55.6843  lr 1.000e-03\n",
      "epoch 773  loss 56.4954  lr 1.000e-03\n",
      "epoch 774  loss 55.7189  lr 1.000e-03\n",
      "epoch 775  loss 55.0346  lr 1.000e-03\n",
      "epoch 776  loss 54.2472  lr 1.000e-03\n",
      "epoch 777  loss 55.4286  lr 1.000e-03\n",
      "epoch 778  loss 54.7107  lr 1.000e-03\n",
      "epoch 779  loss 56.1792  lr 1.000e-03\n",
      "epoch 780  loss 55.8285  lr 1.000e-03\n",
      "epoch 781  loss 54.4473  lr 1.000e-03\n",
      "epoch 782  loss 55.9374  lr 1.000e-03\n",
      "epoch 783  loss 56.5010  lr 1.000e-03\n",
      "epoch 784  loss 54.2566  lr 1.000e-03\n",
      "epoch 785  loss 54.9312  lr 1.000e-03\n",
      "epoch 786  loss 54.8580  lr 1.000e-03\n",
      "epoch 787  loss 54.4099  lr 1.000e-03\n",
      "epoch 788  loss 54.4525  lr 1.000e-03\n",
      "epoch 789  loss 55.7521  lr 1.000e-03\n",
      "epoch 790  loss 54.2595  lr 1.000e-03\n",
      "epoch 791  loss 53.4993  lr 1.000e-03\n",
      "epoch 792  loss 56.7408  lr 1.000e-03\n",
      "epoch 793  loss 55.0199  lr 1.000e-03\n",
      "epoch 794  loss 54.0044  lr 1.000e-03\n",
      "epoch 795  loss 54.6802  lr 1.000e-03\n",
      "epoch 796  loss 55.5954  lr 1.000e-03\n",
      "epoch 797  loss 53.7588  lr 1.000e-03\n",
      "epoch 798  loss 54.9746  lr 1.000e-03\n",
      "epoch 799  loss 54.1911  lr 1.000e-03\n",
      "epoch 800  loss 56.1039  lr 1.000e-03\n",
      "epoch 801  loss 57.1266  lr 1.000e-03\n",
      "epoch 802  loss 55.3665  lr 1.000e-03\n",
      "epoch 803  loss 54.8032  lr 1.000e-03\n",
      "epoch 804  loss 56.5098  lr 1.000e-03\n",
      "epoch 805  loss 56.2998  lr 1.000e-03\n",
      "epoch 806  loss 54.5381  lr 1.000e-03\n",
      "epoch 807  loss 54.8650  lr 1.000e-03\n",
      "epoch 808  loss 54.0255  lr 1.000e-03\n",
      "epoch 809  loss 53.9161  lr 1.000e-03\n",
      "epoch 810  loss 55.0283  lr 1.000e-03\n",
      "epoch 811  loss 55.3156  lr 1.000e-03\n",
      "epoch 812  loss 53.9004  lr 1.000e-03\n",
      "epoch 813  loss 54.5441  lr 1.000e-03\n",
      "epoch 814  loss 56.4379  lr 1.000e-03\n",
      "epoch 815  loss 54.4992  lr 1.000e-03\n",
      "epoch 816  loss 55.2897  lr 1.000e-03\n",
      "epoch 817  loss 54.2516  lr 1.000e-03\n",
      "epoch 818  loss 56.0780  lr 1.000e-03\n",
      "epoch 819  loss 56.1244  lr 1.000e-03\n",
      "epoch 820  loss 53.1419  lr 1.000e-03\n",
      "epoch 821  loss 53.8245  lr 1.000e-03\n",
      "epoch 822  loss 55.5935  lr 1.000e-03\n",
      "epoch 823  loss 55.0895  lr 1.000e-03\n",
      "epoch 824  loss 55.7864  lr 1.000e-03\n",
      "epoch 825  loss 54.8386  lr 1.000e-03\n",
      "epoch 826  loss 53.8074  lr 1.000e-03\n",
      "epoch 827  loss 53.9057  lr 1.000e-03\n",
      "epoch 828  loss 55.1169  lr 1.000e-03\n",
      "epoch 829  loss 52.9289  lr 1.000e-03\n",
      "epoch 830  loss 55.8053  lr 1.000e-03\n",
      "epoch 831  loss 56.0181  lr 1.000e-03\n",
      "epoch 832  loss 55.5745  lr 1.000e-03\n",
      "epoch 833  loss 54.5819  lr 1.000e-03\n",
      "epoch 834  loss 53.4484  lr 1.000e-03\n",
      "epoch 835  loss 54.0986  lr 1.000e-03\n",
      "epoch 836  loss 54.5076  lr 1.000e-03\n",
      "epoch 837  loss 54.8416  lr 1.000e-03\n",
      "epoch 838  loss 55.6390  lr 1.000e-03\n",
      "epoch 839  loss 55.0905  lr 1.000e-03\n",
      "epoch 840  loss 55.6591  lr 1.000e-03\n",
      "epoch 841  loss 54.7904  lr 1.000e-03\n",
      "epoch 842  loss 55.2352  lr 1.000e-03\n",
      "epoch 843  loss 55.1880  lr 1.000e-03\n",
      "epoch 844  loss 56.0377  lr 1.000e-03\n",
      "epoch 845  loss 54.0467  lr 1.000e-03\n",
      "epoch 846  loss 52.8672  lr 1.000e-03\n",
      "epoch 847  loss 54.6838  lr 1.000e-03\n",
      "epoch 848  loss 52.5146  lr 1.000e-03\n",
      "epoch 849  loss 55.0640  lr 1.000e-03\n",
      "epoch 850  loss 54.8153  lr 1.000e-03\n",
      "epoch 851  loss 54.1230  lr 1.000e-03\n",
      "epoch 852  loss 52.7705  lr 1.000e-03\n",
      "epoch 853  loss 54.0288  lr 1.000e-03\n",
      "epoch 854  loss 55.5134  lr 1.000e-03\n",
      "epoch 855  loss 53.8326  lr 1.000e-03\n",
      "epoch 856  loss 53.6739  lr 1.000e-03\n",
      "epoch 857  loss 55.6798  lr 1.000e-03\n",
      "epoch 858  loss 53.5694  lr 1.000e-03\n",
      "epoch 859  loss 53.8002  lr 1.000e-03\n",
      "epoch 860  loss 53.6557  lr 1.000e-03\n",
      "epoch 861  loss 54.8328  lr 1.000e-03\n",
      "epoch 862  loss 54.9603  lr 1.000e-03\n",
      "epoch 863  loss 54.5525  lr 1.000e-03\n",
      "epoch 864  loss 55.5661  lr 1.000e-03\n",
      "epoch 865  loss 53.9073  lr 1.000e-03\n",
      "epoch 866  loss 54.7419  lr 1.000e-03\n",
      "epoch 867  loss 54.6606  lr 1.000e-03\n",
      "epoch 868  loss 54.7730  lr 1.000e-03\n",
      "epoch 869  loss 55.1220  lr 1.000e-03\n",
      "epoch 870  loss 54.1236  lr 1.000e-03\n",
      "epoch 871  loss 54.8663  lr 1.000e-03\n",
      "epoch 872  loss 54.8347  lr 1.000e-03\n",
      "epoch 873  loss 58.0824  lr 1.000e-03\n",
      "epoch 874  loss 55.7693  lr 1.000e-03\n",
      "epoch 875  loss 53.4395  lr 1.000e-03\n",
      "epoch 876  loss 55.3514  lr 1.000e-03\n",
      "epoch 877  loss 54.6012  lr 1.000e-03\n",
      "epoch 878  loss 55.1964  lr 1.000e-03\n",
      "epoch 879  loss 54.2463  lr 1.000e-03\n",
      "epoch 880  loss 54.0304  lr 1.000e-03\n",
      "epoch 881  loss 53.6813  lr 1.000e-03\n",
      "epoch 882  loss 55.8453  lr 1.000e-03\n",
      "epoch 883  loss 55.8733  lr 1.000e-03\n",
      "epoch 884  loss 56.6297  lr 1.000e-03\n",
      "epoch 885  loss 53.4948  lr 1.000e-03\n",
      "epoch 886  loss 53.1314  lr 1.000e-03\n",
      "epoch 887  loss 54.1603  lr 1.000e-03\n",
      "epoch 888  loss 53.3085  lr 1.000e-03\n",
      "epoch 889  loss 52.8375  lr 1.000e-03\n",
      "epoch 890  loss 55.1385  lr 1.000e-03\n",
      "epoch 891  loss 56.3288  lr 1.000e-03\n",
      "epoch 892  loss 53.4823  lr 1.000e-03\n",
      "epoch 893  loss 53.9288  lr 1.000e-03\n",
      "epoch 894  loss 52.1439  lr 1.000e-03\n",
      "epoch 895  loss 56.3683  lr 1.000e-03\n",
      "epoch 896  loss 53.8051  lr 1.000e-03\n",
      "epoch 897  loss 53.3882  lr 1.000e-03\n",
      "epoch 898  loss 54.4067  lr 1.000e-03\n",
      "epoch 899  loss 53.6195  lr 1.000e-03\n",
      "epoch 900  loss 53.2900  lr 1.000e-03\n",
      "epoch 901  loss 56.7542  lr 1.000e-03\n",
      "epoch 902  loss 56.2079  lr 1.000e-03\n",
      "epoch 903  loss 54.8908  lr 1.000e-03\n",
      "epoch 904  loss 52.0056  lr 1.000e-03\n",
      "epoch 905  loss 54.9965  lr 1.000e-03\n",
      "epoch 906  loss 54.0707  lr 1.000e-03\n",
      "epoch 907  loss 57.3627  lr 1.000e-03\n",
      "epoch 908  loss 53.5161  lr 1.000e-03\n",
      "epoch 909  loss 53.6796  lr 1.000e-03\n",
      "epoch 910  loss 53.9252  lr 1.000e-03\n",
      "epoch 911  loss 53.3040  lr 1.000e-03\n",
      "epoch 912  loss 53.6529  lr 1.000e-03\n",
      "epoch 913  loss 52.5393  lr 1.000e-03\n",
      "epoch 914  loss 52.5805  lr 1.000e-03\n",
      "epoch 915  loss 52.9463  lr 1.000e-03\n",
      "epoch 916  loss 53.2387  lr 1.000e-03\n",
      "epoch 917  loss 53.9893  lr 1.000e-03\n",
      "epoch 918  loss 55.2205  lr 1.000e-03\n",
      "epoch 919  loss 54.2264  lr 1.000e-03\n",
      "epoch 920  loss 53.8840  lr 1.000e-03\n",
      "epoch 921  loss 53.8659  lr 1.000e-03\n",
      "epoch 922  loss 55.6175  lr 1.000e-03\n",
      "epoch 923  loss 54.2106  lr 1.000e-03\n",
      "epoch 924  loss 53.9733  lr 1.000e-03\n",
      "epoch 925  loss 54.9900  lr 1.000e-03\n",
      "epoch 926  loss 54.6036  lr 1.000e-03\n",
      "epoch 927  loss 55.1048  lr 1.000e-03\n",
      "epoch 928  loss 53.9344  lr 1.000e-03\n",
      "epoch 929  loss 51.6609  lr 1.000e-03\n",
      "epoch 930  loss 55.0947  lr 1.000e-03\n",
      "epoch 931  loss 53.4405  lr 1.000e-03\n",
      "epoch 932  loss 55.0351  lr 1.000e-03\n",
      "epoch 933  loss 54.9188  lr 1.000e-03\n",
      "epoch 934  loss 54.8201  lr 1.000e-03\n",
      "epoch 935  loss 54.9416  lr 1.000e-03\n",
      "epoch 936  loss 56.4665  lr 1.000e-03\n",
      "epoch 937  loss 56.4807  lr 1.000e-03\n",
      "epoch 938  loss 55.8863  lr 1.000e-03\n",
      "epoch 939  loss 52.1301  lr 1.000e-03\n",
      "epoch 940  loss 53.5483  lr 1.000e-03\n",
      "epoch 941  loss 54.0221  lr 1.000e-03\n",
      "epoch 942  loss 53.8680  lr 1.000e-03\n",
      "epoch 943  loss 52.7898  lr 1.000e-03\n",
      "epoch 944  loss 52.6347  lr 1.000e-03\n",
      "epoch 945  loss 54.7861  lr 1.000e-03\n",
      "epoch 946  loss 53.7307  lr 1.000e-03\n",
      "epoch 947  loss 53.7684  lr 1.000e-03\n",
      "epoch 948  loss 55.1567  lr 1.000e-03\n",
      "epoch 949  loss 55.0424  lr 1.000e-03\n",
      "epoch 950  loss 54.2560  lr 1.000e-03\n",
      "epoch 951  loss 54.6003  lr 1.000e-03\n",
      "epoch 952  loss 55.6167  lr 1.000e-03\n",
      "epoch 953  loss 55.2573  lr 1.000e-03\n",
      "epoch 954  loss 53.7721  lr 1.000e-03\n",
      "epoch 955  loss 55.4903  lr 1.000e-03\n",
      "epoch 956  loss 52.5540  lr 1.000e-03\n",
      "epoch 957  loss 54.2621  lr 1.000e-03\n",
      "epoch 958  loss 53.5045  lr 1.000e-03\n",
      "epoch 959  loss 52.3450  lr 1.000e-03\n",
      "epoch 960  loss 52.9443  lr 1.000e-03\n",
      "epoch 961  loss 54.3475  lr 1.000e-03\n",
      "epoch 962  loss 53.0676  lr 1.000e-03\n",
      "epoch 963  loss 53.6505  lr 1.000e-03\n",
      "epoch 964  loss 54.7589  lr 1.000e-03\n",
      "epoch 965  loss 53.9612  lr 1.000e-03\n",
      "epoch 966  loss 55.5905  lr 1.000e-03\n",
      "epoch 967  loss 53.0247  lr 1.000e-03\n",
      "epoch 968  loss 54.8171  lr 1.000e-03\n",
      "epoch 969  loss 53.6357  lr 1.000e-03\n",
      "epoch 970  loss 54.6710  lr 1.000e-03\n",
      "epoch 971  loss 54.3526  lr 1.000e-03\n",
      "epoch 972  loss 54.6229  lr 1.000e-03\n",
      "epoch 973  loss 54.3530  lr 1.000e-03\n",
      "epoch 974  loss 53.1350  lr 1.000e-03\n",
      "epoch 975  loss 54.4805  lr 1.000e-03\n",
      "epoch 976  loss 54.1998  lr 1.000e-03\n",
      "epoch 977  loss 52.6224  lr 1.000e-03\n",
      "epoch 978  loss 53.8428  lr 1.000e-03\n",
      "epoch 979  loss 53.2042  lr 1.000e-03\n",
      "epoch 980  loss 52.6359  lr 1.000e-03\n",
      "epoch 981  loss 51.7588  lr 1.000e-03\n",
      "epoch 982  loss 53.4686  lr 1.000e-03\n",
      "epoch 983  loss 54.7503  lr 1.000e-03\n",
      "epoch 984  loss 53.3079  lr 1.000e-03\n",
      "epoch 985  loss 53.4350  lr 1.000e-03\n",
      "epoch 986  loss 51.7787  lr 1.000e-03\n",
      "epoch 987  loss 52.8921  lr 1.000e-03\n",
      "epoch 988  loss 54.3398  lr 1.000e-03\n",
      "epoch 989  loss 52.4580  lr 1.000e-03\n",
      "epoch 990  loss 53.7465  lr 1.000e-03\n",
      "epoch 991  loss 52.4132  lr 1.000e-03\n",
      "epoch 992  loss 51.6151  lr 1.000e-03\n",
      "epoch 993  loss 52.8445  lr 1.000e-03\n",
      "epoch 994  loss 53.7485  lr 1.000e-03\n",
      "epoch 995  loss 52.7936  lr 1.000e-03\n",
      "epoch 996  loss 54.0743  lr 1.000e-03\n",
      "epoch 997  loss 52.7953  lr 1.000e-03\n",
      "epoch 998  loss 53.3742  lr 1.000e-03\n",
      "epoch 999  loss 52.4105  lr 1.000e-03\n",
      "epoch 1000  loss 52.8510  lr 1.000e-03\n",
      "epoch 1001  loss 52.6157  lr 1.000e-03\n",
      "epoch 1002  loss 54.1427  lr 1.000e-03\n",
      "epoch 1003  loss 54.2725  lr 1.000e-03\n",
      "epoch 1004  loss 52.9177  lr 1.000e-03\n",
      "epoch 1005  loss 54.1032  lr 1.000e-03\n",
      "epoch 1006  loss 51.9510  lr 1.000e-03\n",
      "epoch 1007  loss 53.1803  lr 1.000e-03\n",
      "epoch 1008  loss 53.7504  lr 1.000e-03\n",
      "epoch 1009  loss 54.1747  lr 1.000e-03\n",
      "epoch 1010  loss 53.6944  lr 1.000e-03\n",
      "epoch 1011  loss 54.1086  lr 1.000e-03\n",
      "epoch 1012  loss 54.7284  lr 1.000e-03\n",
      "epoch 1013  loss 52.9949  lr 1.000e-03\n",
      "epoch 1014  loss 53.4258  lr 1.000e-03\n",
      "epoch 1015  loss 52.5127  lr 1.000e-03\n",
      "epoch 1016  loss 52.8926  lr 1.000e-03\n",
      "epoch 1017  loss 53.0696  lr 1.000e-03\n",
      "epoch 1018  loss 52.4295  lr 1.000e-03\n",
      "epoch 1019  loss 53.6590  lr 1.000e-03\n",
      "epoch 1020  loss 52.3438  lr 1.000e-03\n",
      "epoch 1021  loss 50.9934  lr 1.000e-03\n",
      "epoch 1022  loss 51.4422  lr 1.000e-03\n",
      "epoch 1023  loss 52.6167  lr 1.000e-03\n",
      "epoch 1024  loss 54.5561  lr 1.000e-03\n",
      "epoch 1025  loss 52.2966  lr 1.000e-03\n",
      "epoch 1026  loss 53.4728  lr 1.000e-03\n",
      "epoch 1027  loss 52.1478  lr 1.000e-03\n",
      "epoch 1028  loss 51.9817  lr 1.000e-03\n",
      "epoch 1029  loss 52.0759  lr 1.000e-03\n",
      "epoch 1030  loss 53.2735  lr 1.000e-03\n",
      "epoch 1031  loss 53.4167  lr 1.000e-03\n",
      "epoch 1032  loss 53.1554  lr 1.000e-03\n",
      "epoch 1033  loss 52.3158  lr 1.000e-03\n",
      "epoch 1034  loss 54.9207  lr 1.000e-03\n",
      "epoch 1035  loss 52.1327  lr 1.000e-03\n",
      "epoch 1036  loss 53.2033  lr 1.000e-03\n",
      "epoch 1037  loss 52.7720  lr 1.000e-03\n",
      "epoch 1038  loss 53.6182  lr 1.000e-03\n",
      "epoch 1039  loss 53.5360  lr 1.000e-03\n",
      "epoch 1040  loss 53.5770  lr 1.000e-03\n",
      "epoch 1041  loss 54.6029  lr 1.000e-03\n",
      "epoch 1042  loss 54.3511  lr 1.000e-03\n",
      "epoch 1043  loss 55.5010  lr 1.000e-03\n",
      "epoch 1044  loss 53.7151  lr 1.000e-03\n",
      "epoch 1045  loss 53.1539  lr 1.000e-03\n",
      "epoch 1046  loss 52.9049  lr 1.000e-03\n",
      "epoch 1047  loss 52.8448  lr 1.000e-03\n",
      "epoch 1048  loss 53.0251  lr 1.000e-03\n",
      "epoch 1049  loss 54.2497  lr 1.000e-03\n",
      "epoch 1050  loss 51.8830  lr 1.000e-03\n",
      "epoch 1051  loss 53.8859  lr 1.000e-03\n",
      "epoch 1052  loss 52.6372  lr 1.000e-03\n",
      "epoch 1053  loss 54.8055  lr 1.000e-03\n",
      "epoch 1054  loss 52.0155  lr 1.000e-03\n",
      "epoch 1055  loss 52.5413  lr 1.000e-03\n",
      "epoch 1056  loss 52.4253  lr 1.000e-03\n",
      "epoch 1057  loss 53.9042  lr 1.000e-03\n",
      "epoch 1058  loss 54.3496  lr 1.000e-03\n",
      "epoch 1059  loss 53.2497  lr 1.000e-03\n",
      "epoch 1060  loss 52.6022  lr 1.000e-03\n",
      "epoch 1061  loss 54.2136  lr 1.000e-03\n",
      "epoch 1062  loss 52.5950  lr 1.000e-03\n",
      "epoch 1063  loss 51.1144  lr 1.000e-03\n",
      "epoch 1064  loss 51.7551  lr 1.000e-03\n",
      "epoch 1065  loss 51.0514  lr 1.000e-03\n",
      "epoch 1066  loss 54.2793  lr 1.000e-03\n",
      "epoch 1067  loss 52.5458  lr 1.000e-03\n",
      "epoch 1068  loss 51.2634  lr 1.000e-03\n",
      "epoch 1069  loss 52.0439  lr 1.000e-03\n",
      "epoch 1070  loss 52.1820  lr 1.000e-03\n",
      "epoch 1071  loss 52.4262  lr 1.000e-03\n",
      "epoch 1072  loss 53.0125  lr 1.000e-03\n",
      "epoch 1073  loss 54.8175  lr 1.000e-03\n",
      "epoch 1074  loss 52.5879  lr 1.000e-03\n",
      "epoch 1075  loss 52.6793  lr 1.000e-03\n",
      "epoch 1076  loss 52.2791  lr 1.000e-03\n",
      "epoch 1077  loss 53.8348  lr 1.000e-03\n",
      "epoch 1078  loss 52.5003  lr 1.000e-03\n",
      "epoch 1079  loss 53.5129  lr 1.000e-03\n",
      "epoch 1080  loss 54.0871  lr 1.000e-03\n",
      "epoch 1081  loss 53.2608  lr 1.000e-03\n",
      "epoch 1082  loss 51.8690  lr 1.000e-03\n",
      "epoch 1083  loss 53.0180  lr 1.000e-03\n",
      "epoch 1084  loss 53.7056  lr 1.000e-03\n",
      "epoch 1085  loss 54.3253  lr 1.000e-03\n",
      "epoch 1086  loss 51.5599  lr 1.000e-03\n",
      "epoch 1087  loss 52.6868  lr 1.000e-03\n",
      "epoch 1088  loss 53.0688  lr 1.000e-03\n",
      "epoch 1089  loss 52.7557  lr 1.000e-03\n",
      "epoch 1090  loss 52.5797  lr 1.000e-03\n",
      "epoch 1091  loss 53.3008  lr 1.000e-03\n",
      "epoch 1092  loss 52.1821  lr 1.000e-03\n",
      "epoch 1093  loss 51.5865  lr 1.000e-03\n",
      "epoch 1094  loss 52.6053  lr 1.000e-03\n",
      "epoch 1095  loss 52.3537  lr 1.000e-03\n",
      "epoch 1096  loss 52.0042  lr 1.000e-03\n",
      "epoch 1097  loss 51.9471  lr 1.000e-03\n",
      "epoch 1098  loss 52.7556  lr 1.000e-03\n",
      "epoch 1099  loss 53.0457  lr 1.000e-03\n",
      "epoch 1100  loss 54.2057  lr 1.000e-03\n",
      "epoch 1101  loss 54.3347  lr 1.000e-03\n",
      "epoch 1102  loss 55.0853  lr 1.000e-03\n",
      "epoch 1103  loss 51.9188  lr 1.000e-03\n",
      "epoch 1104  loss 51.8204  lr 1.000e-03\n",
      "epoch 1105  loss 53.5362  lr 1.000e-03\n",
      "epoch 1106  loss 51.4873  lr 1.000e-03\n",
      "epoch 1107  loss 53.3373  lr 1.000e-03\n",
      "epoch 1108  loss 52.9990  lr 1.000e-03\n",
      "epoch 1109  loss 52.5893  lr 1.000e-03\n",
      "epoch 1110  loss 53.2538  lr 1.000e-03\n",
      "epoch 1111  loss 52.2070  lr 1.000e-03\n",
      "epoch 1112  loss 52.1752  lr 1.000e-03\n",
      "epoch 1113  loss 52.6825  lr 1.000e-03\n",
      "epoch 1114  loss 52.1165  lr 1.000e-03\n",
      "epoch 1115  loss 52.7029  lr 1.000e-03\n",
      "epoch 1116  loss 53.2934  lr 1.000e-03\n",
      "epoch 1117  loss 51.9545  lr 1.000e-03\n",
      "epoch 1118  loss 51.2526  lr 1.000e-03\n",
      "epoch 1119  loss 52.7568  lr 1.000e-03\n",
      "epoch 1120  loss 52.2778  lr 1.000e-03\n",
      "epoch 1121  loss 51.3971  lr 1.000e-03\n",
      "epoch 1122  loss 51.6922  lr 1.000e-03\n",
      "epoch 1123  loss 52.4343  lr 1.000e-03\n",
      "epoch 1124  loss 52.4882  lr 1.000e-03\n",
      "epoch 1125  loss 51.8986  lr 1.000e-03\n",
      "epoch 1126  loss 53.5580  lr 1.000e-03\n",
      "epoch 1127  loss 53.3937  lr 1.000e-03\n",
      "epoch 1128  loss 52.2849  lr 1.000e-03\n",
      "epoch 1129  loss 52.5862  lr 1.000e-03\n",
      "epoch 1130  loss 55.4218  lr 1.000e-03\n",
      "epoch 1131  loss 52.2108  lr 1.000e-03\n",
      "epoch 1132  loss 53.4295  lr 1.000e-03\n",
      "epoch 1133  loss 52.7100  lr 1.000e-03\n",
      "epoch 1134  loss 51.3203  lr 1.000e-03\n",
      "epoch 1135  loss 51.5064  lr 1.000e-03\n",
      "epoch 1136  loss 52.7873  lr 1.000e-03\n",
      "epoch 1137  loss 53.3893  lr 1.000e-03\n",
      "epoch 1138  loss 51.9057  lr 1.000e-03\n",
      "epoch 1139  loss 51.3902  lr 1.000e-03\n",
      "epoch 1140  loss 52.5314  lr 1.000e-03\n",
      "epoch 1141  loss 52.9745  lr 1.000e-03\n",
      "epoch 1142  loss 52.0199  lr 1.000e-03\n",
      "epoch 1143  loss 52.7036  lr 1.000e-03\n",
      "epoch 1144  loss 51.3364  lr 1.000e-03\n",
      "epoch 1145  loss 52.8664  lr 1.000e-03\n",
      "epoch 1146  loss 54.0741  lr 1.000e-03\n",
      "epoch 1147  loss 52.9665  lr 1.000e-03\n",
      "epoch 1148  loss 50.3949  lr 1.000e-03\n",
      "epoch 1149  loss 52.7225  lr 1.000e-03\n",
      "epoch 1150  loss 51.7851  lr 1.000e-03\n",
      "epoch 1151  loss 53.3240  lr 1.000e-03\n",
      "epoch 1152  loss 52.5306  lr 1.000e-03\n",
      "epoch 1153  loss 52.3491  lr 1.000e-03\n",
      "epoch 1154  loss 54.1405  lr 1.000e-03\n",
      "epoch 1155  loss 52.2338  lr 1.000e-03\n",
      "epoch 1156  loss 50.8849  lr 1.000e-03\n",
      "epoch 1157  loss 52.5733  lr 1.000e-03\n",
      "epoch 1158  loss 52.2481  lr 1.000e-03\n",
      "epoch 1159  loss 53.4993  lr 1.000e-03\n",
      "epoch 1160  loss 53.6293  lr 1.000e-03\n",
      "epoch 1161  loss 52.0018  lr 1.000e-03\n",
      "epoch 1162  loss 52.1147  lr 1.000e-03\n",
      "epoch 1163  loss 54.3776  lr 1.000e-03\n",
      "epoch 1164  loss 52.6969  lr 1.000e-03\n",
      "epoch 1165  loss 51.9052  lr 1.000e-03\n",
      "epoch 1166  loss 50.5154  lr 1.000e-03\n",
      "epoch 1167  loss 51.8248  lr 1.000e-03\n",
      "epoch 1168  loss 50.5968  lr 1.000e-03\n",
      "epoch 1169  loss 52.3472  lr 1.000e-03\n",
      "epoch 1170  loss 50.9706  lr 1.000e-03\n",
      "epoch 1171  loss 51.7543  lr 1.000e-03\n",
      "epoch 1172  loss 52.1590  lr 1.000e-03\n",
      "epoch 1173  loss 51.0891  lr 1.000e-03\n",
      "epoch 1174  loss 52.8139  lr 1.000e-03\n",
      "epoch 1175  loss 51.3745  lr 1.000e-03\n",
      "epoch 1176  loss 52.3960  lr 1.000e-03\n",
      "epoch 1177  loss 51.1472  lr 1.000e-03\n",
      "epoch 1178  loss 51.7100  lr 1.000e-03\n",
      "epoch 1179  loss 52.0953  lr 1.000e-03\n",
      "epoch 1180  loss 52.3619  lr 1.000e-03\n",
      "epoch 1181  loss 51.7777  lr 1.000e-03\n",
      "epoch 1182  loss 49.7495  lr 1.000e-03\n",
      "epoch 1183  loss 50.7091  lr 1.000e-03\n",
      "epoch 1184  loss 51.9004  lr 1.000e-03\n",
      "epoch 1185  loss 52.2318  lr 1.000e-03\n",
      "epoch 1186  loss 52.2487  lr 1.000e-03\n",
      "epoch 1187  loss 51.6207  lr 1.000e-03\n",
      "epoch 1188  loss 52.9315  lr 1.000e-03\n",
      "epoch 1189  loss 52.0202  lr 1.000e-03\n",
      "epoch 1190  loss 52.8447  lr 1.000e-03\n",
      "epoch 1191  loss 49.5602  lr 1.000e-03\n",
      "epoch 1192  loss 51.5173  lr 1.000e-03\n",
      "epoch 1193  loss 52.3272  lr 1.000e-03\n",
      "epoch 1194  loss 54.0641  lr 1.000e-03\n",
      "epoch 1195  loss 52.6560  lr 1.000e-03\n",
      "epoch 1196  loss 51.6253  lr 1.000e-03\n",
      "epoch 1197  loss 53.4698  lr 1.000e-03\n",
      "epoch 1198  loss 51.8103  lr 1.000e-03\n",
      "epoch 1199  loss 52.3785  lr 1.000e-03\n",
      "epoch 1200  loss 53.5219  lr 1.000e-03\n",
      "epoch 1201  loss 51.3171  lr 1.000e-03\n",
      "epoch 1202  loss 52.7228  lr 1.000e-03\n",
      "epoch 1203  loss 49.6122  lr 1.000e-03\n",
      "epoch 1204  loss 51.5292  lr 1.000e-03\n",
      "epoch 1205  loss 49.9562  lr 1.000e-03\n",
      "epoch 1206  loss 51.0721  lr 1.000e-03\n",
      "epoch 1207  loss 52.3271  lr 1.000e-03\n",
      "epoch 1208  loss 52.3558  lr 1.000e-03\n",
      "epoch 1209  loss 51.8402  lr 1.000e-03\n",
      "epoch 1210  loss 51.7527  lr 1.000e-03\n",
      "epoch 1211  loss 51.8101  lr 1.000e-03\n",
      "epoch 1212  loss 51.0431  lr 1.000e-03\n",
      "epoch 1213  loss 51.1177  lr 1.000e-03\n",
      "epoch 1214  loss 52.1622  lr 1.000e-03\n",
      "epoch 1215  loss 50.6503  lr 1.000e-03\n",
      "epoch 1216  loss 50.9662  lr 1.000e-03\n",
      "epoch 1217  loss 53.1233  lr 1.000e-03\n",
      "epoch 1218  loss 51.5998  lr 1.000e-03\n",
      "epoch 1219  loss 51.1347  lr 1.000e-03\n",
      "epoch 1220  loss 55.0200  lr 1.000e-03\n",
      "epoch 1221  loss 53.2436  lr 1.000e-03\n",
      "epoch 1222  loss 52.1516  lr 1.000e-03\n",
      "epoch 1223  loss 51.6374  lr 1.000e-03\n",
      "epoch 1224  loss 51.5441  lr 1.000e-03\n",
      "epoch 1225  loss 51.7322  lr 1.000e-03\n",
      "epoch 1226  loss 53.0174  lr 1.000e-03\n",
      "epoch 1227  loss 53.4368  lr 1.000e-03\n",
      "epoch 1228  loss 51.1978  lr 1.000e-03\n",
      "epoch 1229  loss 50.8286  lr 1.000e-03\n",
      "epoch 1230  loss 50.4166  lr 1.000e-03\n",
      "epoch 1231  loss 52.6148  lr 1.000e-03\n",
      "epoch 1232  loss 52.7557  lr 1.000e-03\n",
      "epoch 1233  loss 53.3751  lr 1.000e-03\n",
      "epoch 1234  loss 51.4271  lr 1.000e-03\n",
      "epoch 1235  loss 51.9866  lr 1.000e-03\n",
      "epoch 1236  loss 52.3501  lr 1.000e-03\n",
      "epoch 1237  loss 50.9120  lr 1.000e-03\n",
      "epoch 1238  loss 52.0301  lr 1.000e-03\n",
      "epoch 1239  loss 51.0041  lr 1.000e-03\n",
      "epoch 1240  loss 52.4248  lr 1.000e-03\n",
      "epoch 1241  loss 48.5001  lr 1.000e-03\n",
      "epoch 1242  loss 50.4586  lr 1.000e-03\n",
      "epoch 1243  loss 51.2565  lr 1.000e-03\n",
      "epoch 1244  loss 51.3813  lr 1.000e-03\n",
      "epoch 1245  loss 52.6911  lr 1.000e-03\n",
      "epoch 1246  loss 51.4972  lr 1.000e-03\n",
      "epoch 1247  loss 52.1838  lr 1.000e-03\n",
      "epoch 1248  loss 51.4854  lr 1.000e-03\n",
      "epoch 1249  loss 51.5118  lr 1.000e-03\n",
      "epoch 1250  loss 52.6540  lr 1.000e-03\n",
      "epoch 1251  loss 50.8998  lr 1.000e-03\n",
      "epoch 1252  loss 52.8298  lr 1.000e-03\n",
      "epoch 1253  loss 52.6230  lr 1.000e-03\n",
      "epoch 1254  loss 52.5563  lr 1.000e-03\n",
      "epoch 1255  loss 52.2754  lr 1.000e-03\n",
      "epoch 1256  loss 51.2473  lr 1.000e-03\n",
      "epoch 1257  loss 50.8135  lr 1.000e-03\n",
      "epoch 1258  loss 52.7923  lr 1.000e-03\n",
      "epoch 1259  loss 53.2030  lr 1.000e-03\n",
      "epoch 1260  loss 51.9680  lr 1.000e-03\n",
      "epoch 1261  loss 53.0167  lr 1.000e-03\n",
      "epoch 1262  loss 50.9909  lr 1.000e-03\n",
      "epoch 1263  loss 51.7123  lr 1.000e-03\n",
      "epoch 1264  loss 52.3822  lr 1.000e-03\n",
      "epoch 1265  loss 51.4385  lr 1.000e-03\n",
      "epoch 1266  loss 52.1696  lr 1.000e-03\n",
      "epoch 1267  loss 51.6273  lr 1.000e-03\n",
      "epoch 1268  loss 51.6755  lr 1.000e-03\n",
      "epoch 1269  loss 50.9219  lr 1.000e-03\n",
      "epoch 1270  loss 50.9125  lr 1.000e-03\n",
      "epoch 1271  loss 49.9420  lr 1.000e-03\n",
      "epoch 1272  loss 51.8068  lr 1.000e-03\n",
      "epoch 1273  loss 51.9818  lr 1.000e-03\n",
      "epoch 1274  loss 49.7191  lr 1.000e-03\n",
      "epoch 1275  loss 51.1912  lr 1.000e-03\n",
      "epoch 1276  loss 52.7291  lr 1.000e-03\n",
      "epoch 1277  loss 52.5117  lr 1.000e-03\n",
      "epoch 1278  loss 52.2010  lr 1.000e-03\n",
      "epoch 1279  loss 52.3760  lr 1.000e-03\n",
      "epoch 1280  loss 51.3197  lr 1.000e-03\n",
      "epoch 1281  loss 52.5111  lr 1.000e-03\n",
      "epoch 1282  loss 51.4135  lr 1.000e-03\n",
      "epoch 1283  loss 50.9967  lr 1.000e-03\n",
      "epoch 1284  loss 50.3609  lr 1.000e-03\n",
      "epoch 1285  loss 53.2255  lr 1.000e-03\n",
      "epoch 1286  loss 52.1534  lr 1.000e-03\n",
      "epoch 1287  loss 51.1136  lr 1.000e-03\n",
      "epoch 1288  loss 54.5231  lr 1.000e-03\n",
      "epoch 1289  loss 52.6062  lr 1.000e-03\n",
      "epoch 1290  loss 52.3393  lr 1.000e-03\n",
      "epoch 1291  loss 50.3170  lr 1.000e-03\n",
      "epoch 1292  loss 51.7427  lr 1.000e-03\n",
      "epoch 1293  loss 49.9703  lr 1.000e-03\n",
      "epoch 1294  loss 52.3608  lr 1.000e-03\n",
      "epoch 1295  loss 51.2053  lr 1.000e-03\n",
      "epoch 1296  loss 51.3777  lr 1.000e-03\n",
      "epoch 1297  loss 51.5110  lr 1.000e-03\n",
      "epoch 1298  loss 50.6749  lr 1.000e-03\n",
      "epoch 1299  loss 52.1306  lr 1.000e-03\n",
      "epoch 1300  loss 52.4376  lr 1.000e-03\n",
      "epoch 1301  loss 53.7009  lr 1.000e-03\n",
      "epoch 1302  loss 51.7817  lr 1.000e-03\n",
      "epoch 1303  loss 49.4735  lr 1.000e-03\n",
      "epoch 1304  loss 50.1564  lr 1.000e-03\n",
      "epoch 1305  loss 51.3907  lr 1.000e-03\n",
      "epoch 1306  loss 51.9648  lr 1.000e-03\n",
      "epoch 1307  loss 50.7979  lr 1.000e-03\n",
      "epoch 1308  loss 50.7623  lr 1.000e-03\n",
      "epoch 1309  loss 52.3303  lr 1.000e-03\n",
      "epoch 1310  loss 49.0803  lr 1.000e-03\n",
      "epoch 1311  loss 52.2772  lr 1.000e-03\n",
      "epoch 1312  loss 51.4055  lr 1.000e-03\n",
      "epoch 1313  loss 51.4101  lr 1.000e-03\n",
      "epoch 1314  loss 50.9785  lr 1.000e-03\n",
      "epoch 1315  loss 49.9924  lr 1.000e-03\n",
      "epoch 1316  loss 50.7495  lr 1.000e-03\n",
      "epoch 1317  loss 52.4023  lr 1.000e-03\n",
      "epoch 1318  loss 51.8479  lr 1.000e-03\n",
      "epoch 1319  loss 49.4917  lr 1.000e-03\n",
      "epoch 1320  loss 50.5225  lr 1.000e-03\n",
      "epoch 1321  loss 51.1334  lr 1.000e-03\n",
      "epoch 1322  loss 50.3807  lr 1.000e-03\n",
      "epoch 1323  loss 50.5840  lr 1.000e-03\n",
      "epoch 1324  loss 51.3678  lr 1.000e-03\n",
      "epoch 1325  loss 50.0481  lr 1.000e-03\n",
      "epoch 1326  loss 49.8903  lr 1.000e-03\n",
      "epoch 1327  loss 51.2598  lr 1.000e-03\n",
      "epoch 1328  loss 51.7074  lr 1.000e-03\n",
      "epoch 1329  loss 52.6166  lr 1.000e-03\n",
      "epoch 1330  loss 50.0684  lr 1.000e-03\n",
      "epoch 1331  loss 50.5764  lr 1.000e-03\n",
      "epoch 1332  loss 49.8263  lr 1.000e-03\n",
      "epoch 1333  loss 51.2622  lr 1.000e-03\n",
      "epoch 1334  loss 50.3639  lr 1.000e-03\n",
      "epoch 1335  loss 51.6877  lr 1.000e-03\n",
      "epoch 1336  loss 51.0594  lr 1.000e-03\n",
      "epoch 1337  loss 50.1554  lr 1.000e-03\n",
      "epoch 1338  loss 50.6779  lr 1.000e-03\n",
      "epoch 1339  loss 51.4696  lr 1.000e-03\n",
      "epoch 1340  loss 51.5345  lr 1.000e-03\n",
      "epoch 1341  loss 52.9550  lr 1.000e-03\n",
      "epoch 1342  loss 51.8730  lr 1.000e-03\n",
      "epoch 1343  loss 51.2060  lr 1.000e-03\n",
      "epoch 1344  loss 49.7881  lr 1.000e-03\n",
      "epoch 1345  loss 49.8420  lr 1.000e-03\n",
      "epoch 1346  loss 49.8276  lr 1.000e-03\n",
      "epoch 1347  loss 50.1448  lr 1.000e-03\n",
      "epoch 1348  loss 52.5702  lr 1.000e-03\n",
      "epoch 1349  loss 49.8637  lr 1.000e-03\n",
      "epoch 1350  loss 49.4173  lr 1.000e-03\n",
      "epoch 1351  loss 52.6212  lr 1.000e-03\n",
      "epoch 1352  loss 51.1315  lr 1.000e-03\n",
      "epoch 1353  loss 49.7249  lr 1.000e-03\n",
      "epoch 1354  loss 51.2015  lr 1.000e-03\n",
      "epoch 1355  loss 51.3694  lr 1.000e-03\n",
      "epoch 1356  loss 50.7476  lr 1.000e-03\n",
      "epoch 1357  loss 51.2197  lr 1.000e-03\n",
      "epoch 1358  loss 52.6354  lr 1.000e-03\n",
      "epoch 1359  loss 48.6306  lr 1.000e-03\n",
      "epoch 1360  loss 50.6438  lr 1.000e-03\n",
      "epoch 1361  loss 51.3159  lr 1.000e-03\n",
      "epoch 1362  loss 50.8575  lr 1.000e-03\n",
      "epoch 1363  loss 51.9310  lr 1.000e-03\n",
      "epoch 1364  loss 50.8552  lr 1.000e-03\n",
      "epoch 1365  loss 50.9737  lr 1.000e-03\n",
      "epoch 1366  loss 50.1685  lr 1.000e-03\n",
      "epoch 1367  loss 49.1622  lr 1.000e-03\n",
      "epoch 1368  loss 51.8302  lr 1.000e-03\n",
      "epoch 1369  loss 51.3629  lr 1.000e-03\n",
      "epoch 1370  loss 50.0859  lr 1.000e-03\n",
      "epoch 1371  loss 51.3329  lr 1.000e-03\n",
      "epoch 1372  loss 50.7779  lr 1.000e-03\n",
      "epoch 1373  loss 49.3540  lr 1.000e-03\n",
      "epoch 1374  loss 50.8724  lr 1.000e-03\n",
      "epoch 1375  loss 52.4804  lr 1.000e-03\n",
      "epoch 1376  loss 52.4455  lr 1.000e-03\n",
      "epoch 1377  loss 50.9457  lr 1.000e-03\n",
      "epoch 1378  loss 49.8868  lr 1.000e-03\n",
      "epoch 1379  loss 52.2199  lr 1.000e-03\n",
      "epoch 1380  loss 50.0466  lr 1.000e-03\n",
      "epoch 1381  loss 52.1495  lr 1.000e-03\n",
      "epoch 1382  loss 49.8150  lr 1.000e-03\n",
      "epoch 1383  loss 51.2806  lr 1.000e-03\n",
      "epoch 1384  loss 49.1319  lr 1.000e-03\n",
      "epoch 1385  loss 50.5744  lr 1.000e-03\n",
      "epoch 1386  loss 49.8873  lr 1.000e-03\n",
      "epoch 1387  loss 50.6657  lr 1.000e-03\n",
      "epoch 1388  loss 50.6594  lr 1.000e-03\n",
      "epoch 1389  loss 51.6696  lr 1.000e-03\n",
      "epoch 1390  loss 52.1379  lr 1.000e-03\n",
      "epoch 1391  loss 49.9877  lr 1.000e-03\n",
      "epoch 1392  loss 51.1804  lr 1.000e-03\n",
      "epoch 1393  loss 50.4035  lr 1.000e-03\n",
      "epoch 1394  loss 50.2561  lr 1.000e-03\n",
      "epoch 1395  loss 50.2529  lr 1.000e-03\n",
      "epoch 1396  loss 49.8268  lr 1.000e-03\n",
      "epoch 1397  loss 51.9062  lr 1.000e-03\n",
      "epoch 1398  loss 53.6486  lr 1.000e-03\n",
      "epoch 1399  loss 51.0616  lr 1.000e-03\n",
      "epoch 1400  loss 50.1812  lr 1.000e-03\n",
      "epoch 1401  loss 50.5061  lr 1.000e-03\n",
      "epoch 1402  loss 50.1920  lr 1.000e-03\n",
      "epoch 1403  loss 50.6201  lr 1.000e-03\n",
      "epoch 1404  loss 50.4546  lr 1.000e-03\n",
      "epoch 1405  loss 50.0408  lr 1.000e-03\n",
      "epoch 1406  loss 52.7290  lr 1.000e-03\n",
      "epoch 1407  loss 50.9191  lr 1.000e-03\n",
      "epoch 1408  loss 50.0405  lr 1.000e-03\n",
      "epoch 1409  loss 51.3832  lr 1.000e-03\n",
      "epoch 1410  loss 50.9180  lr 1.000e-03\n",
      "epoch 1411  loss 49.6031  lr 1.000e-03\n",
      "epoch 1412  loss 50.0062  lr 1.000e-03\n",
      "epoch 1413  loss 51.0455  lr 1.000e-03\n",
      "epoch 1414  loss 50.7059  lr 1.000e-03\n",
      "epoch 1415  loss 51.6664  lr 1.000e-03\n",
      "epoch 1416  loss 50.6535  lr 1.000e-03\n",
      "epoch 1417  loss 49.6791  lr 1.000e-03\n",
      "epoch 1418  loss 51.4791  lr 1.000e-03\n",
      "epoch 1419  loss 50.8384  lr 1.000e-03\n",
      "epoch 1420  loss 52.2702  lr 1.000e-03\n",
      "epoch 1421  loss 51.6191  lr 1.000e-03\n",
      "epoch 1422  loss 51.4350  lr 1.000e-03\n",
      "epoch 1423  loss 51.3083  lr 1.000e-03\n",
      "epoch 1424  loss 51.2729  lr 1.000e-03\n",
      "epoch 1425  loss 51.6063  lr 1.000e-03\n",
      "epoch 1426  loss 49.8139  lr 1.000e-03\n",
      "epoch 1427  loss 48.0778  lr 1.000e-03\n",
      "epoch 1428  loss 53.8847  lr 1.000e-03\n",
      "epoch 1429  loss 52.6308  lr 1.000e-03\n",
      "epoch 1430  loss 50.7997  lr 1.000e-03\n",
      "epoch 1431  loss 51.7042  lr 1.000e-03\n",
      "epoch 1432  loss 49.2909  lr 1.000e-03\n",
      "epoch 1433  loss 50.5382  lr 1.000e-03\n",
      "epoch 1434  loss 50.1246  lr 1.000e-03\n",
      "epoch 1435  loss 50.1278  lr 1.000e-03\n",
      "epoch 1436  loss 48.3198  lr 1.000e-03\n",
      "epoch 1437  loss 53.2683  lr 1.000e-03\n",
      "epoch 1438  loss 50.3187  lr 1.000e-03\n",
      "epoch 1439  loss 50.7775  lr 1.000e-03\n",
      "epoch 1440  loss 49.8298  lr 1.000e-03\n",
      "epoch 1441  loss 50.3536  lr 1.000e-03\n",
      "epoch 1442  loss 51.6069  lr 1.000e-03\n",
      "epoch 1443  loss 51.3739  lr 1.000e-03\n",
      "epoch 1444  loss 50.5130  lr 1.000e-03\n",
      "epoch 1445  loss 50.3298  lr 1.000e-03\n",
      "epoch 1446  loss 48.9739  lr 1.000e-03\n",
      "epoch 1447  loss 47.6495  lr 1.000e-03\n",
      "epoch 1448  loss 49.4696  lr 1.000e-03\n",
      "epoch 1449  loss 50.0919  lr 1.000e-03\n",
      "epoch 1450  loss 52.4305  lr 1.000e-03\n",
      "epoch 1451  loss 50.4948  lr 1.000e-03\n",
      "epoch 1452  loss 49.2761  lr 1.000e-03\n",
      "epoch 1453  loss 50.8076  lr 1.000e-03\n",
      "epoch 1454  loss 51.0996  lr 1.000e-03\n",
      "epoch 1455  loss 50.3984  lr 1.000e-03\n",
      "epoch 1456  loss 52.1453  lr 1.000e-03\n",
      "epoch 1457  loss 50.6613  lr 1.000e-03\n",
      "epoch 1458  loss 50.3508  lr 1.000e-03\n",
      "epoch 1459  loss 51.7400  lr 1.000e-03\n",
      "epoch 1460  loss 50.3104  lr 1.000e-03\n",
      "epoch 1461  loss 50.8032  lr 1.000e-03\n",
      "epoch 1462  loss 49.7644  lr 1.000e-03\n",
      "epoch 1463  loss 49.0153  lr 1.000e-03\n",
      "epoch 1464  loss 51.7842  lr 1.000e-03\n",
      "epoch 1465  loss 49.3588  lr 1.000e-03\n",
      "epoch 1466  loss 49.2366  lr 1.000e-03\n",
      "epoch 1467  loss 51.5695  lr 1.000e-03\n",
      "epoch 1468  loss 50.5002  lr 1.000e-03\n",
      "epoch 1469  loss 48.7626  lr 1.000e-03\n",
      "epoch 1470  loss 48.9595  lr 1.000e-03\n",
      "epoch 1471  loss 51.1063  lr 1.000e-03\n",
      "epoch 1472  loss 50.0852  lr 1.000e-03\n",
      "epoch 1473  loss 50.7396  lr 1.000e-03\n",
      "epoch 1474  loss 48.8665  lr 1.000e-03\n",
      "epoch 1475  loss 48.2458  lr 1.000e-03\n",
      "epoch 1476  loss 49.0464  lr 1.000e-03\n",
      "epoch 1477  loss 50.6727  lr 1.000e-03\n",
      "epoch 1478  loss 49.3588  lr 1.000e-03\n",
      "epoch 1479  loss 51.7127  lr 1.000e-03\n",
      "epoch 1480  loss 51.9728  lr 1.000e-03\n",
      "epoch 1481  loss 50.2849  lr 1.000e-03\n",
      "epoch 1482  loss 52.3776  lr 1.000e-03\n",
      "epoch 1483  loss 49.9509  lr 1.000e-03\n",
      "epoch 1484  loss 50.6304  lr 1.000e-03\n",
      "epoch 1485  loss 50.4220  lr 1.000e-03\n",
      "epoch 1486  loss 50.0905  lr 1.000e-03\n",
      "epoch 1487  loss 50.9183  lr 1.000e-03\n",
      "epoch 1488  loss 50.2333  lr 1.000e-03\n",
      "epoch 1489  loss 49.8371  lr 1.000e-03\n",
      "epoch 1490  loss 50.0939  lr 1.000e-03\n",
      "epoch 1491  loss 51.1872  lr 1.000e-03\n",
      "epoch 1492  loss 49.8655  lr 1.000e-03\n",
      "epoch 1493  loss 48.8225  lr 1.000e-03\n",
      "epoch 1494  loss 50.3772  lr 1.000e-03\n",
      "epoch 1495  loss 48.7328  lr 1.000e-03\n",
      "epoch 1496  loss 51.4403  lr 1.000e-03\n",
      "epoch 1497  loss 51.0119  lr 1.000e-03\n",
      "epoch 1498  loss 49.1229  lr 1.000e-03\n",
      "epoch 1499  loss 49.1013  lr 1.000e-03\n",
      "epoch 1500  loss 49.4508  lr 1.000e-03\n",
      "epoch 1501  loss 50.2647  lr 1.000e-03\n",
      "epoch 1502  loss 50.3370  lr 1.000e-03\n",
      "epoch 1503  loss 50.3593  lr 1.000e-03\n",
      "epoch 1504  loss 50.3009  lr 1.000e-03\n",
      "epoch 1505  loss 49.3971  lr 1.000e-03\n",
      "epoch 1506  loss 52.0755  lr 1.000e-03\n",
      "epoch 1507  loss 49.8501  lr 1.000e-03\n",
      "epoch 1508  loss 49.0036  lr 1.000e-03\n",
      "epoch 1509  loss 50.6777  lr 1.000e-03\n",
      "epoch 1510  loss 50.0883  lr 1.000e-03\n",
      "epoch 1511  loss 50.9607  lr 1.000e-03\n",
      "epoch 1512  loss 48.3943  lr 1.000e-03\n",
      "epoch 1513  loss 50.5966  lr 1.000e-03\n",
      "epoch 1514  loss 50.8415  lr 1.000e-03\n",
      "epoch 1515  loss 49.6795  lr 1.000e-03\n",
      "epoch 1516  loss 50.1524  lr 1.000e-03\n",
      "epoch 1517  loss 51.5768  lr 1.000e-03\n",
      "epoch 1518  loss 51.5381  lr 1.000e-03\n",
      "epoch 1519  loss 51.3655  lr 1.000e-03\n",
      "epoch 1520  loss 49.3006  lr 1.000e-03\n",
      "epoch 1521  loss 50.6338  lr 1.000e-03\n",
      "epoch 1522  loss 51.2270  lr 1.000e-03\n",
      "epoch 1523  loss 48.5787  lr 1.000e-03\n",
      "epoch 1524  loss 50.1926  lr 1.000e-03\n",
      "epoch 1525  loss 51.6157  lr 1.000e-03\n",
      "epoch 1526  loss 51.5950  lr 1.000e-03\n",
      "epoch 1527  loss 48.5728  lr 1.000e-03\n",
      "epoch 1528  loss 50.3076  lr 1.000e-03\n",
      "epoch 1529  loss 50.0826  lr 1.000e-03\n",
      "epoch 1530  loss 49.1466  lr 1.000e-03\n",
      "epoch 1531  loss 51.7431  lr 1.000e-03\n",
      "epoch 1532  loss 51.0388  lr 1.000e-03\n",
      "epoch 1533  loss 49.2468  lr 1.000e-03\n",
      "epoch 1534  loss 48.0576  lr 1.000e-03\n",
      "epoch 1535  loss 48.0986  lr 1.000e-03\n",
      "epoch 1536  loss 49.4407  lr 1.000e-03\n",
      "epoch 1537  loss 49.4235  lr 1.000e-03\n",
      "epoch 1538  loss 49.3476  lr 1.000e-03\n",
      "epoch 1539  loss 48.9696  lr 1.000e-03\n",
      "epoch 1540  loss 52.1362  lr 1.000e-03\n",
      "epoch 1541  loss 50.1760  lr 1.000e-03\n",
      "epoch 1542  loss 47.8390  lr 1.000e-03\n",
      "epoch 1543  loss 48.8933  lr 1.000e-03\n",
      "epoch 1544  loss 49.9640  lr 1.000e-03\n",
      "epoch 1545  loss 49.5435  lr 1.000e-03\n",
      "epoch 1546  loss 51.1200  lr 1.000e-03\n",
      "epoch 1547  loss 50.6972  lr 1.000e-03\n",
      "epoch 1548  loss 49.9875  lr 1.000e-03\n",
      "epoch 1549  loss 49.2925  lr 1.000e-03\n",
      "epoch 1550  loss 47.6930  lr 1.000e-03\n",
      "epoch 1551  loss 51.0946  lr 1.000e-03\n",
      "epoch 1552  loss 49.3640  lr 1.000e-03\n",
      "epoch 1553  loss 49.3982  lr 1.000e-03\n",
      "epoch 1554  loss 50.2988  lr 1.000e-03\n",
      "epoch 1555  loss 50.0157  lr 1.000e-03\n",
      "epoch 1556  loss 48.9998  lr 1.000e-03\n",
      "epoch 1557  loss 49.9347  lr 1.000e-03\n",
      "epoch 1558  loss 50.3005  lr 1.000e-03\n",
      "epoch 1559  loss 50.2699  lr 1.000e-03\n",
      "epoch 1560  loss 48.6623  lr 1.000e-03\n",
      "epoch 1561  loss 50.0377  lr 1.000e-03\n",
      "epoch 1562  loss 50.1459  lr 1.000e-03\n",
      "epoch 1563  loss 50.2471  lr 1.000e-03\n",
      "epoch 1564  loss 49.4174  lr 1.000e-03\n",
      "epoch 1565  loss 49.7199  lr 1.000e-03\n",
      "epoch 1566  loss 50.7951  lr 1.000e-03\n",
      "epoch 1567  loss 50.4562  lr 1.000e-03\n",
      "epoch 1568  loss 51.5531  lr 1.000e-03\n",
      "epoch 1569  loss 48.9969  lr 1.000e-03\n",
      "epoch 1570  loss 50.6809  lr 1.000e-03\n",
      "epoch 1571  loss 47.7344  lr 1.000e-03\n",
      "epoch 1572  loss 48.9044  lr 1.000e-03\n",
      "epoch 1573  loss 51.1650  lr 1.000e-03\n",
      "epoch 1574  loss 49.9261  lr 1.000e-03\n",
      "epoch 1575  loss 49.1700  lr 1.000e-03\n",
      "epoch 1576  loss 49.0837  lr 1.000e-03\n",
      "epoch 1577  loss 50.9067  lr 1.000e-03\n",
      "epoch 1578  loss 50.4609  lr 1.000e-03\n",
      "epoch 1579  loss 50.8924  lr 1.000e-03\n",
      "epoch 1580  loss 50.6318  lr 1.000e-03\n",
      "epoch 1581  loss 51.8576  lr 1.000e-03\n",
      "epoch 1582  loss 48.4157  lr 1.000e-03\n",
      "epoch 1583  loss 47.5715  lr 1.000e-03\n",
      "epoch 1584  loss 49.7057  lr 1.000e-03\n",
      "epoch 1585  loss 49.6785  lr 1.000e-03\n",
      "epoch 1586  loss 51.5868  lr 1.000e-03\n",
      "epoch 1587  loss 51.6593  lr 1.000e-03\n",
      "epoch 1588  loss 50.0440  lr 1.000e-03\n",
      "epoch 1589  loss 49.5167  lr 1.000e-03\n",
      "epoch 1590  loss 50.6226  lr 1.000e-03\n",
      "epoch 1591  loss 50.6516  lr 1.000e-03\n",
      "epoch 1592  loss 48.8826  lr 1.000e-03\n",
      "epoch 1593  loss 49.3992  lr 1.000e-03\n",
      "epoch 1594  loss 48.8720  lr 1.000e-03\n",
      "epoch 1595  loss 51.1334  lr 1.000e-03\n",
      "epoch 1596  loss 48.4061  lr 1.000e-03\n",
      "epoch 1597  loss 50.1230  lr 1.000e-03\n",
      "epoch 1598  loss 49.0816  lr 1.000e-03\n",
      "epoch 1599  loss 49.9447  lr 1.000e-03\n",
      "epoch 1600  loss 49.4324  lr 1.000e-03\n",
      "epoch 1601  loss 50.0208  lr 1.000e-03\n",
      "epoch 1602  loss 49.1954  lr 1.000e-03\n",
      "epoch 1603  loss 48.8417  lr 1.000e-03\n",
      "epoch 1604  loss 50.3403  lr 1.000e-03\n",
      "epoch 1605  loss 50.6399  lr 1.000e-03\n",
      "epoch 1606  loss 50.2557  lr 1.000e-03\n",
      "epoch 1607  loss 50.5099  lr 1.000e-03\n",
      "epoch 1608  loss 49.0438  lr 1.000e-03\n",
      "epoch 1609  loss 49.9916  lr 1.000e-03\n",
      "epoch 1610  loss 51.1970  lr 1.000e-03\n",
      "epoch 1611  loss 50.0393  lr 1.000e-03\n",
      "epoch 1612  loss 49.8952  lr 1.000e-03\n",
      "epoch 1613  loss 49.2845  lr 1.000e-03\n",
      "epoch 1614  loss 50.2127  lr 1.000e-03\n",
      "epoch 1615  loss 49.7548  lr 1.000e-03\n",
      "epoch 1616  loss 49.7687  lr 1.000e-03\n",
      "epoch 1617  loss 50.0640  lr 1.000e-03\n",
      "epoch 1618  loss 48.8629  lr 1.000e-03\n",
      "epoch 1619  loss 50.3042  lr 1.000e-03\n",
      "epoch 1620  loss 51.3478  lr 1.000e-03\n",
      "epoch 1621  loss 49.0153  lr 1.000e-03\n",
      "epoch 1622  loss 49.0945  lr 1.000e-03\n",
      "epoch 1623  loss 49.8715  lr 1.000e-03\n",
      "epoch 1624  loss 47.6137  lr 1.000e-03\n",
      "epoch 1625  loss 49.5174  lr 1.000e-03\n",
      "epoch 1626  loss 49.2101  lr 1.000e-03\n",
      "epoch 1627  loss 51.1333  lr 1.000e-03\n",
      "epoch 1628  loss 51.4167  lr 1.000e-03\n",
      "epoch 1629  loss 48.8127  lr 1.000e-03\n",
      "epoch 1630  loss 50.1413  lr 1.000e-03\n",
      "epoch 1631  loss 50.1612  lr 1.000e-03\n",
      "epoch 1632  loss 48.1541  lr 1.000e-03\n",
      "epoch 1633  loss 49.5744  lr 1.000e-03\n",
      "epoch 1634  loss 49.2833  lr 1.000e-03\n",
      "epoch 1635  loss 48.9547  lr 1.000e-03\n",
      "epoch 1636  loss 48.4728  lr 1.000e-03\n",
      "epoch 1637  loss 50.2573  lr 1.000e-03\n",
      "epoch 1638  loss 49.1297  lr 1.000e-03\n",
      "epoch 1639  loss 48.8185  lr 1.000e-03\n",
      "epoch 1640  loss 50.5444  lr 1.000e-03\n",
      "epoch 1641  loss 49.5070  lr 1.000e-03\n",
      "epoch 1642  loss 51.2486  lr 1.000e-03\n",
      "epoch 1643  loss 50.5622  lr 1.000e-03\n",
      "epoch 1644  loss 49.7555  lr 1.000e-03\n",
      "epoch 1645  loss 49.8439  lr 1.000e-03\n",
      "epoch 1646  loss 48.8018  lr 1.000e-03\n",
      "epoch 1647  loss 47.5783  lr 1.000e-03\n",
      "epoch 1648  loss 48.7872  lr 1.000e-03\n",
      "epoch 1649  loss 50.7941  lr 1.000e-03\n",
      "epoch 1650  loss 49.1333  lr 1.000e-03\n",
      "epoch 1651  loss 48.4604  lr 1.000e-03\n",
      "epoch 1652  loss 48.4023  lr 1.000e-03\n",
      "epoch 1653  loss 49.5414  lr 1.000e-03\n",
      "epoch 1654  loss 49.9978  lr 1.000e-03\n",
      "epoch 1655  loss 49.5914  lr 1.000e-03\n",
      "epoch 1656  loss 49.2760  lr 1.000e-03\n",
      "epoch 1657  loss 52.4121  lr 1.000e-03\n",
      "epoch 1658  loss 49.7930  lr 1.000e-03\n",
      "epoch 1659  loss 49.9059  lr 1.000e-03\n",
      "epoch 1660  loss 49.6829  lr 1.000e-03\n",
      "epoch 1661  loss 50.0769  lr 1.000e-03\n",
      "epoch 1662  loss 50.1358  lr 1.000e-03\n",
      "epoch 1663  loss 49.0182  lr 1.000e-03\n",
      "epoch 1664  loss 48.9423  lr 1.000e-03\n",
      "epoch 1665  loss 51.0742  lr 1.000e-03\n",
      "epoch 1666  loss 50.3155  lr 1.000e-03\n",
      "epoch 1667  loss 50.8687  lr 1.000e-03\n",
      "epoch 1668  loss 49.8841  lr 1.000e-03\n",
      "epoch 1669  loss 51.6658  lr 1.000e-03\n",
      "epoch 1670  loss 48.6558  lr 1.000e-03\n",
      "epoch 1671  loss 49.9697  lr 1.000e-03\n",
      "epoch 1672  loss 48.5658  lr 1.000e-03\n",
      "epoch 1673  loss 51.1428  lr 1.000e-03\n",
      "epoch 1674  loss 47.8150  lr 1.000e-03\n",
      "epoch 1675  loss 48.8167  lr 1.000e-03\n",
      "epoch 1676  loss 48.8832  lr 1.000e-03\n",
      "epoch 1677  loss 49.4714  lr 1.000e-03\n",
      "epoch 1678  loss 48.4539  lr 1.000e-03\n",
      "epoch 1679  loss 47.6249  lr 1.000e-03\n",
      "epoch 1680  loss 50.9804  lr 1.000e-03\n",
      "epoch 1681  loss 48.6434  lr 1.000e-03\n",
      "epoch 1682  loss 49.3839  lr 1.000e-03\n",
      "epoch 1683  loss 49.7468  lr 1.000e-03\n",
      "epoch 1684  loss 49.9558  lr 1.000e-03\n",
      "epoch 1685  loss 49.2700  lr 1.000e-03\n",
      "epoch 1686  loss 47.9007  lr 1.000e-03\n",
      "epoch 1687  loss 49.0066  lr 1.000e-03\n",
      "epoch 1688  loss 49.1544  lr 1.000e-03\n",
      "epoch 1689  loss 48.9672  lr 1.000e-03\n",
      "epoch 1690  loss 48.4324  lr 1.000e-03\n",
      "epoch 1691  loss 48.9336  lr 1.000e-03\n",
      "epoch 1692  loss 49.6233  lr 1.000e-03\n",
      "epoch 1693  loss 47.6566  lr 1.000e-03\n",
      "epoch 1694  loss 50.0881  lr 1.000e-03\n",
      "epoch 1695  loss 48.5131  lr 1.000e-03\n",
      "epoch 1696  loss 51.0247  lr 1.000e-03\n",
      "epoch 1697  loss 47.6412  lr 1.000e-03\n",
      "epoch 1698  loss 49.3498  lr 1.000e-03\n",
      "epoch 1699  loss 49.2826  lr 1.000e-03\n",
      "epoch 1700  loss 48.0222  lr 1.000e-03\n",
      "epoch 1701  loss 49.5570  lr 1.000e-03\n",
      "epoch 1702  loss 47.9385  lr 1.000e-03\n",
      "epoch 1703  loss 48.1489  lr 1.000e-03\n",
      "epoch 1704  loss 50.0605  lr 1.000e-03\n",
      "epoch 1705  loss 48.6099  lr 1.000e-03\n",
      "epoch 1706  loss 50.1155  lr 1.000e-03\n",
      "epoch 1707  loss 47.9415  lr 1.000e-03\n",
      "epoch 1708  loss 48.3399  lr 1.000e-03\n",
      "epoch 1709  loss 50.4457  lr 1.000e-03\n",
      "epoch 1710  loss 50.4019  lr 1.000e-03\n",
      "epoch 1711  loss 49.1175  lr 1.000e-03\n",
      "epoch 1712  loss 47.7170  lr 1.000e-03\n",
      "epoch 1713  loss 49.8657  lr 1.000e-03\n",
      "epoch 1714  loss 50.3704  lr 1.000e-03\n",
      "epoch 1715  loss 50.0803  lr 1.000e-03\n",
      "epoch 1716  loss 50.1740  lr 1.000e-03\n",
      "epoch 1717  loss 49.9365  lr 1.000e-03\n",
      "epoch 1718  loss 50.8548  lr 1.000e-03\n",
      "epoch 1719  loss 47.6642  lr 1.000e-03\n",
      "epoch 1720  loss 48.3417  lr 1.000e-03\n",
      "epoch 1721  loss 48.7140  lr 1.000e-03\n",
      "epoch 1722  loss 47.9891  lr 1.000e-03\n",
      "epoch 1723  loss 50.4869  lr 1.000e-03\n",
      "epoch 1724  loss 48.0693  lr 1.000e-03\n",
      "epoch 1725  loss 48.9781  lr 1.000e-03\n",
      "epoch 1726  loss 48.7409  lr 1.000e-03\n",
      "epoch 1727  loss 48.7124  lr 1.000e-03\n",
      "epoch 1728  loss 47.4266  lr 1.000e-03\n",
      "epoch 1729  loss 48.9576  lr 1.000e-03\n",
      "epoch 1730  loss 48.8047  lr 1.000e-03\n",
      "epoch 1731  loss 48.2922  lr 1.000e-03\n",
      "epoch 1732  loss 50.2598  lr 1.000e-03\n",
      "epoch 1733  loss 49.7582  lr 1.000e-03\n",
      "epoch 1734  loss 48.5836  lr 1.000e-03\n",
      "epoch 1735  loss 48.5884  lr 1.000e-03\n",
      "epoch 1736  loss 49.0516  lr 1.000e-03\n",
      "epoch 1737  loss 48.8239  lr 1.000e-03\n",
      "epoch 1738  loss 49.7527  lr 1.000e-03\n",
      "epoch 1739  loss 47.6097  lr 1.000e-03\n",
      "epoch 1740  loss 51.2546  lr 1.000e-03\n",
      "epoch 1741  loss 49.9985  lr 1.000e-03\n",
      "epoch 1742  loss 50.0730  lr 1.000e-03\n",
      "epoch 1743  loss 50.1008  lr 1.000e-03\n",
      "epoch 1744  loss 48.4903  lr 1.000e-03\n",
      "epoch 1745  loss 48.3984  lr 1.000e-03\n",
      "epoch 1746  loss 50.7675  lr 1.000e-03\n",
      "epoch 1747  loss 50.2482  lr 1.000e-03\n",
      "epoch 1748  loss 49.1062  lr 1.000e-03\n",
      "epoch 1749  loss 49.0648  lr 1.000e-03\n",
      "epoch 1750  loss 50.1354  lr 1.000e-03\n",
      "epoch 1751  loss 49.8831  lr 1.000e-03\n",
      "epoch 1752  loss 47.7357  lr 1.000e-03\n",
      "epoch 1753  loss 50.5171  lr 1.000e-03\n",
      "epoch 1754  loss 49.8681  lr 1.000e-03\n",
      "epoch 1755  loss 48.8380  lr 1.000e-03\n",
      "epoch 1756  loss 48.0709  lr 1.000e-03\n",
      "epoch 1757  loss 47.7915  lr 1.000e-03\n",
      "epoch 1758  loss 48.3107  lr 1.000e-03\n",
      "epoch 1759  loss 48.2876  lr 1.000e-03\n",
      "epoch 1760  loss 48.4100  lr 1.000e-03\n",
      "epoch 1761  loss 49.4624  lr 1.000e-03\n",
      "epoch 1762  loss 48.6386  lr 1.000e-03\n",
      "epoch 1763  loss 48.2934  lr 1.000e-03\n",
      "epoch 1764  loss 48.8004  lr 1.000e-03\n",
      "epoch 1765  loss 48.0163  lr 1.000e-03\n",
      "epoch 1766  loss 50.3176  lr 1.000e-03\n",
      "epoch 1767  loss 49.0406  lr 1.000e-03\n",
      "epoch 1768  loss 48.1541  lr 1.000e-03\n",
      "epoch 1769  loss 47.2336  lr 1.000e-03\n",
      "epoch 1770  loss 49.7534  lr 1.000e-03\n",
      "epoch 1771  loss 49.7317  lr 1.000e-03\n",
      "epoch 1772  loss 48.5430  lr 1.000e-03\n",
      "epoch 1773  loss 48.7824  lr 1.000e-03\n",
      "epoch 1774  loss 49.9615  lr 1.000e-03\n",
      "epoch 1775  loss 49.0632  lr 1.000e-03\n",
      "epoch 1776  loss 49.9162  lr 1.000e-03\n",
      "epoch 1777  loss 49.2748  lr 1.000e-03\n",
      "epoch 1778  loss 48.8353  lr 1.000e-03\n",
      "epoch 1779  loss 49.1532  lr 1.000e-03\n",
      "epoch 1780  loss 48.5512  lr 1.000e-03\n",
      "epoch 1781  loss 51.2378  lr 1.000e-03\n",
      "epoch 1782  loss 48.5673  lr 1.000e-03\n",
      "epoch 1783  loss 49.7795  lr 1.000e-03\n",
      "epoch 1784  loss 49.7854  lr 1.000e-03\n",
      "epoch 1785  loss 48.2694  lr 1.000e-03\n",
      "epoch 1786  loss 50.0008  lr 1.000e-03\n",
      "epoch 1787  loss 49.5401  lr 1.000e-03\n",
      "epoch 1788  loss 48.0230  lr 1.000e-03\n",
      "epoch 1789  loss 48.0679  lr 1.000e-03\n",
      "epoch 1790  loss 50.2894  lr 1.000e-03\n",
      "epoch 1791  loss 48.4387  lr 1.000e-03\n",
      "epoch 1792  loss 47.3430  lr 1.000e-03\n",
      "epoch 1793  loss 47.8990  lr 1.000e-03\n",
      "epoch 1794  loss 50.3910  lr 1.000e-03\n",
      "epoch 1795  loss 50.4472  lr 1.000e-03\n",
      "epoch 1796  loss 50.2745  lr 1.000e-03\n",
      "epoch 1797  loss 48.4983  lr 1.000e-03\n",
      "epoch 1798  loss 48.4019  lr 1.000e-03\n",
      "epoch 1799  loss 49.4311  lr 1.000e-03\n",
      "epoch 1800  loss 47.8070  lr 1.000e-03\n",
      "epoch 1801  loss 48.3318  lr 1.000e-03\n",
      "epoch 1802  loss 48.4848  lr 1.000e-03\n",
      "epoch 1803  loss 47.9857  lr 1.000e-03\n",
      "epoch 1804  loss 49.2617  lr 1.000e-03\n",
      "epoch 1805  loss 48.6120  lr 1.000e-03\n",
      "epoch 1806  loss 46.3063  lr 1.000e-03\n",
      "epoch 1807  loss 47.4980  lr 1.000e-03\n",
      "epoch 1808  loss 50.7830  lr 1.000e-03\n",
      "epoch 1809  loss 50.0211  lr 1.000e-03\n",
      "epoch 1810  loss 50.6704  lr 1.000e-03\n",
      "epoch 1811  loss 48.7260  lr 1.000e-03\n",
      "epoch 1812  loss 48.3297  lr 1.000e-03\n",
      "epoch 1813  loss 47.6294  lr 1.000e-03\n",
      "epoch 1814  loss 48.4646  lr 1.000e-03\n",
      "epoch 1815  loss 49.6210  lr 1.000e-03\n",
      "epoch 1816  loss 49.6750  lr 1.000e-03\n",
      "epoch 1817  loss 48.2189  lr 1.000e-03\n",
      "epoch 1818  loss 49.0192  lr 1.000e-03\n",
      "epoch 1819  loss 48.8417  lr 1.000e-03\n",
      "epoch 1820  loss 48.3297  lr 1.000e-03\n",
      "epoch 1821  loss 47.8271  lr 1.000e-03\n",
      "epoch 1822  loss 47.7427  lr 1.000e-03\n",
      "epoch 1823  loss 48.2972  lr 1.000e-03\n",
      "epoch 1824  loss 50.0073  lr 1.000e-03\n",
      "epoch 1825  loss 48.6344  lr 1.000e-03\n",
      "epoch 1826  loss 47.8698  lr 1.000e-03\n",
      "epoch 1827  loss 48.6699  lr 1.000e-03\n",
      "epoch 1828  loss 48.8424  lr 1.000e-03\n",
      "epoch 1829  loss 47.7572  lr 1.000e-03\n",
      "epoch 1830  loss 48.2916  lr 1.000e-03\n",
      "epoch 1831  loss 47.5217  lr 1.000e-03\n",
      "epoch 1832  loss 47.7449  lr 1.000e-03\n",
      "epoch 1833  loss 48.5977  lr 1.000e-03\n",
      "epoch 1834  loss 47.5614  lr 1.000e-03\n",
      "epoch 1835  loss 48.3752  lr 1.000e-03\n",
      "epoch 1836  loss 49.3717  lr 1.000e-03\n",
      "epoch 1837  loss 48.4077  lr 1.000e-03\n",
      "epoch 1838  loss 51.3306  lr 1.000e-03\n",
      "epoch 1839  loss 47.3161  lr 1.000e-03\n",
      "epoch 1840  loss 48.1698  lr 1.000e-03\n",
      "epoch 1841  loss 48.8472  lr 1.000e-03\n",
      "epoch 1842  loss 50.1334  lr 1.000e-03\n",
      "epoch 1843  loss 47.8684  lr 1.000e-03\n",
      "epoch 1844  loss 48.3897  lr 1.000e-03\n",
      "epoch 1845  loss 48.7125  lr 1.000e-03\n",
      "epoch 1846  loss 48.1409  lr 1.000e-03\n",
      "epoch 1847  loss 49.3799  lr 1.000e-03\n",
      "epoch 1848  loss 47.2761  lr 1.000e-03\n",
      "epoch 1849  loss 48.3660  lr 1.000e-03\n",
      "epoch 1850  loss 48.5434  lr 1.000e-03\n",
      "epoch 1851  loss 48.5365  lr 1.000e-03\n",
      "epoch 1852  loss 47.8289  lr 1.000e-03\n",
      "epoch 1853  loss 47.7520  lr 1.000e-03\n",
      "epoch 1854  loss 50.6196  lr 1.000e-03\n",
      "epoch 1855  loss 47.8650  lr 1.000e-03\n",
      "epoch 1856  loss 48.6875  lr 1.000e-03\n",
      "epoch 1857  loss 47.5918  lr 1.000e-03\n",
      "epoch 1858  loss 49.3719  lr 1.000e-03\n",
      "epoch 1859  loss 49.0462  lr 1.000e-03\n",
      "epoch 1860  loss 48.7083  lr 1.000e-03\n",
      "epoch 1861  loss 47.0247  lr 1.000e-03\n",
      "epoch 1862  loss 47.6587  lr 1.000e-03\n",
      "epoch 1863  loss 48.0566  lr 1.000e-03\n",
      "epoch 1864  loss 48.8162  lr 1.000e-03\n",
      "epoch 1865  loss 48.1245  lr 1.000e-03\n",
      "epoch 1866  loss 49.4244  lr 1.000e-03\n",
      "epoch 1867  loss 49.8766  lr 1.000e-03\n",
      "epoch 1868  loss 47.8820  lr 1.000e-03\n",
      "epoch 1869  loss 47.2396  lr 1.000e-03\n",
      "epoch 1870  loss 47.9334  lr 1.000e-03\n",
      "epoch 1871  loss 48.1374  lr 1.000e-03\n",
      "epoch 1872  loss 46.5011  lr 1.000e-03\n",
      "epoch 1873  loss 49.4014  lr 1.000e-03\n",
      "epoch 1874  loss 48.9311  lr 1.000e-03\n",
      "epoch 1875  loss 49.9742  lr 1.000e-03\n",
      "epoch 1876  loss 48.7814  lr 1.000e-03\n",
      "epoch 1877  loss 49.5797  lr 1.000e-03\n",
      "epoch 1878  loss 50.6780  lr 1.000e-03\n",
      "epoch 1879  loss 48.7737  lr 1.000e-03\n",
      "epoch 1880  loss 50.3068  lr 1.000e-03\n",
      "epoch 1881  loss 49.1154  lr 1.000e-03\n",
      "epoch 1882  loss 48.0804  lr 1.000e-03\n",
      "epoch 1883  loss 47.4796  lr 1.000e-03\n",
      "epoch 1884  loss 49.9546  lr 1.000e-03\n",
      "epoch 1885  loss 49.4898  lr 1.000e-03\n",
      "epoch 1886  loss 47.5130  lr 1.000e-03\n",
      "epoch 1887  loss 47.4627  lr 1.000e-03\n",
      "epoch 1888  loss 48.9030  lr 1.000e-03\n",
      "epoch 1889  loss 48.5796  lr 1.000e-03\n",
      "epoch 1890  loss 47.6731  lr 1.000e-03\n",
      "epoch 1891  loss 47.1359  lr 1.000e-03\n",
      "epoch 1892  loss 48.0835  lr 1.000e-03\n",
      "epoch 1893  loss 49.6865  lr 1.000e-03\n",
      "epoch 1894  loss 47.1983  lr 1.000e-03\n",
      "epoch 1895  loss 48.4783  lr 1.000e-03\n",
      "epoch 1896  loss 47.7641  lr 1.000e-03\n",
      "epoch 1897  loss 47.4959  lr 1.000e-03\n",
      "epoch 1898  loss 49.9558  lr 1.000e-03\n",
      "epoch 1899  loss 46.6140  lr 1.000e-03\n",
      "epoch 1900  loss 47.9194  lr 1.000e-03\n",
      "epoch 1901  loss 49.7613  lr 1.000e-03\n",
      "epoch 1902  loss 48.0421  lr 1.000e-03\n",
      "epoch 1903  loss 47.3102  lr 1.000e-03\n",
      "epoch 1904  loss 48.5972  lr 1.000e-03\n",
      "epoch 1905  loss 47.8447  lr 1.000e-03\n",
      "epoch 1906  loss 48.0593  lr 1.000e-03\n",
      "epoch 1907  loss 46.4243  lr 1.000e-03\n",
      "epoch 1908  loss 48.6564  lr 1.000e-03\n",
      "epoch 1909  loss 48.7634  lr 1.000e-03\n",
      "epoch 1910  loss 46.3609  lr 1.000e-03\n",
      "epoch 1911  loss 48.6987  lr 1.000e-03\n",
      "epoch 1912  loss 48.1601  lr 1.000e-03\n",
      "epoch 1913  loss 48.3045  lr 1.000e-03\n",
      "epoch 1914  loss 49.3047  lr 1.000e-03\n",
      "epoch 1915  loss 48.5341  lr 1.000e-03\n",
      "epoch 1916  loss 46.9821  lr 1.000e-03\n",
      "epoch 1917  loss 47.8664  lr 1.000e-03\n",
      "epoch 1918  loss 45.8495  lr 1.000e-03\n",
      "epoch 1919  loss 47.1712  lr 1.000e-03\n",
      "epoch 1920  loss 47.2000  lr 1.000e-03\n",
      "epoch 1921  loss 48.8258  lr 1.000e-03\n",
      "epoch 1922  loss 46.0788  lr 1.000e-03\n",
      "epoch 1923  loss 45.6747  lr 1.000e-03\n",
      "epoch 1924  loss 49.0818  lr 1.000e-03\n",
      "epoch 1925  loss 48.8202  lr 1.000e-03\n",
      "epoch 1926  loss 48.0580  lr 1.000e-03\n",
      "epoch 1927  loss 47.0768  lr 1.000e-03\n",
      "epoch 1928  loss 48.6679  lr 1.000e-03\n",
      "epoch 1929  loss 49.6313  lr 1.000e-03\n",
      "epoch 1930  loss 47.2610  lr 1.000e-03\n",
      "epoch 1931  loss 49.4483  lr 1.000e-03\n",
      "epoch 1932  loss 47.7289  lr 1.000e-03\n",
      "epoch 1933  loss 48.9299  lr 1.000e-03\n",
      "epoch 1934  loss 49.0408  lr 1.000e-03\n",
      "epoch 1935  loss 47.5407  lr 1.000e-03\n",
      "epoch 1936  loss 50.3521  lr 1.000e-03\n",
      "epoch 1937  loss 49.8365  lr 1.000e-03\n",
      "epoch 1938  loss 48.8505  lr 1.000e-03\n",
      "epoch 1939  loss 47.3759  lr 1.000e-03\n",
      "epoch 1940  loss 47.5068  lr 1.000e-03\n",
      "epoch 1941  loss 49.1392  lr 1.000e-03\n",
      "epoch 1942  loss 49.8884  lr 1.000e-03\n",
      "epoch 1943  loss 51.3888  lr 1.000e-03\n",
      "epoch 1944  loss 48.1744  lr 1.000e-03\n",
      "epoch 1945  loss 46.9172  lr 1.000e-03\n",
      "epoch 1946  loss 48.3646  lr 1.000e-03\n",
      "epoch 1947  loss 48.6092  lr 1.000e-03\n",
      "epoch 1948  loss 47.6420  lr 1.000e-03\n",
      "epoch 1949  loss 46.5687  lr 1.000e-03\n",
      "epoch 1950  loss 47.2485  lr 1.000e-03\n",
      "epoch 1951  loss 48.2657  lr 1.000e-03\n",
      "epoch 1952  loss 46.7116  lr 1.000e-03\n",
      "epoch 1953  loss 47.0441  lr 1.000e-03\n",
      "epoch 1954  loss 47.1979  lr 1.000e-03\n",
      "epoch 1955  loss 47.5004  lr 1.000e-03\n",
      "epoch 1956  loss 48.4284  lr 1.000e-03\n",
      "epoch 1957  loss 46.5262  lr 1.000e-03\n",
      "epoch 1958  loss 46.6705  lr 1.000e-03\n",
      "epoch 1959  loss 47.9531  lr 1.000e-03\n",
      "epoch 1960  loss 47.8257  lr 1.000e-03\n",
      "epoch 1961  loss 47.4764  lr 1.000e-03\n",
      "epoch 1962  loss 46.8659  lr 1.000e-03\n",
      "epoch 1963  loss 46.2378  lr 1.000e-03\n",
      "epoch 1964  loss 47.9870  lr 1.000e-03\n",
      "epoch 1965  loss 47.8350  lr 1.000e-03\n",
      "epoch 1966  loss 47.0738  lr 1.000e-03\n",
      "epoch 1967  loss 47.9450  lr 1.000e-03\n",
      "epoch 1968  loss 46.7800  lr 1.000e-03\n",
      "epoch 1969  loss 48.6717  lr 1.000e-03\n",
      "epoch 1970  loss 47.3465  lr 1.000e-03\n",
      "epoch 1971  loss 47.3517  lr 1.000e-03\n",
      "epoch 1972  loss 48.4170  lr 1.000e-03\n",
      "epoch 1973  loss 47.2936  lr 1.000e-03\n",
      "epoch 1974  loss 48.0844  lr 1.000e-03\n",
      "epoch 1975  loss 48.1196  lr 1.000e-03\n",
      "epoch 1976  loss 46.9856  lr 1.000e-03\n",
      "epoch 1977  loss 47.2264  lr 1.000e-03\n",
      "epoch 1978  loss 46.9380  lr 1.000e-03\n",
      "epoch 1979  loss 46.5712  lr 1.000e-03\n",
      "epoch 1980  loss 48.4018  lr 1.000e-03\n",
      "epoch 1981  loss 46.8656  lr 1.000e-03\n",
      "epoch 1982  loss 45.9569  lr 1.000e-03\n",
      "epoch 1983  loss 47.5685  lr 1.000e-03\n",
      "epoch 1984  loss 48.7130  lr 1.000e-03\n",
      "epoch 1985  loss 47.4203  lr 1.000e-03\n",
      "epoch 1986  loss 47.4786  lr 1.000e-03\n",
      "epoch 1987  loss 49.8723  lr 1.000e-03\n",
      "epoch 1988  loss 46.8930  lr 1.000e-03\n",
      "epoch 1989  loss 46.6845  lr 1.000e-03\n",
      "epoch 1990  loss 49.0252  lr 1.000e-03\n",
      "epoch 1991  loss 48.9978  lr 1.000e-03\n",
      "epoch 1992  loss 48.8945  lr 1.000e-03\n",
      "epoch 1993  loss 46.8727  lr 1.000e-03\n",
      "epoch 1994  loss 46.4460  lr 1.000e-03\n",
      "epoch 1995  loss 47.8745  lr 1.000e-03\n",
      "epoch 1996  loss 47.8796  lr 1.000e-03\n",
      "epoch 1997  loss 47.4282  lr 1.000e-03\n",
      "epoch 1998  loss 48.1274  lr 1.000e-03\n",
      "epoch 1999  loss 48.2705  lr 1.000e-03\n",
      "epoch 2000  loss 48.1096  lr 1.000e-03\n",
      "epoch 2001  loss 47.5266  lr 1.000e-03\n",
      "epoch 2002  loss 47.9020  lr 1.000e-03\n",
      "epoch 2003  loss 49.0958  lr 1.000e-03\n",
      "epoch 2004  loss 48.0168  lr 1.000e-03\n",
      "epoch 2005  loss 47.0773  lr 1.000e-03\n",
      "epoch 2006  loss 46.6332  lr 1.000e-03\n",
      "epoch 2007  loss 47.3725  lr 1.000e-03\n",
      "epoch 2008  loss 46.5106  lr 1.000e-03\n",
      "epoch 2009  loss 46.5989  lr 1.000e-03\n",
      "epoch 2010  loss 47.1592  lr 1.000e-03\n",
      "epoch 2011  loss 47.6618  lr 1.000e-03\n",
      "epoch 2012  loss 48.2834  lr 1.000e-03\n",
      "epoch 2013  loss 46.2211  lr 1.000e-03\n",
      "epoch 2014  loss 46.0976  lr 1.000e-03\n",
      "epoch 2015  loss 47.4291  lr 1.000e-03\n",
      "epoch 2016  loss 46.5085  lr 1.000e-03\n",
      "epoch 2017  loss 47.6928  lr 1.000e-03\n",
      "epoch 2018  loss 47.8065  lr 1.000e-03\n",
      "epoch 2019  loss 47.1284  lr 1.000e-03\n",
      "epoch 2020  loss 47.4056  lr 1.000e-03\n",
      "epoch 2021  loss 47.0720  lr 1.000e-03\n",
      "epoch 2022  loss 47.5729  lr 1.000e-03\n",
      "epoch 2023  loss 47.3410  lr 1.000e-03\n",
      "epoch 2024  loss 47.4517  lr 1.000e-03\n",
      "epoch 2025  loss 47.6220  lr 1.000e-03\n",
      "epoch 2026  loss 47.2497  lr 1.000e-03\n",
      "epoch 2027  loss 47.2976  lr 1.000e-03\n",
      "epoch 2028  loss 49.2677  lr 1.000e-03\n",
      "epoch 2029  loss 46.8591  lr 1.000e-03\n",
      "epoch 2030  loss 46.7502  lr 1.000e-03\n",
      "epoch 2031  loss 45.3145  lr 1.000e-03\n",
      "epoch 2032  loss 46.1441  lr 1.000e-03\n",
      "epoch 2033  loss 49.6275  lr 1.000e-03\n",
      "epoch 2034  loss 48.1806  lr 1.000e-03\n",
      "epoch 2035  loss 48.1269  lr 1.000e-03\n",
      "epoch 2036  loss 48.0888  lr 1.000e-03\n",
      "epoch 2037  loss 47.8548  lr 1.000e-03\n",
      "epoch 2038  loss 47.8069  lr 1.000e-03\n",
      "epoch 2039  loss 47.7072  lr 1.000e-03\n",
      "epoch 2040  loss 46.3927  lr 1.000e-03\n",
      "epoch 2041  loss 47.4349  lr 1.000e-03\n",
      "epoch 2042  loss 48.5880  lr 1.000e-03\n",
      "epoch 2043  loss 46.4653  lr 1.000e-03\n",
      "epoch 2044  loss 47.2139  lr 1.000e-03\n",
      "epoch 2045  loss 48.0649  lr 1.000e-03\n",
      "epoch 2046  loss 47.1953  lr 1.000e-03\n",
      "epoch 2047  loss 47.9879  lr 1.000e-03\n",
      "epoch 2048  loss 46.9600  lr 1.000e-03\n",
      "epoch 2049  loss 46.8803  lr 1.000e-03\n",
      "epoch 2050  loss 46.4834  lr 1.000e-03\n",
      "epoch 2051  loss 49.2736  lr 1.000e-03\n",
      "epoch 2052  loss 45.6187  lr 1.000e-03\n",
      "epoch 2053  loss 45.7845  lr 1.000e-03\n",
      "epoch 2054  loss 47.9091  lr 1.000e-03\n",
      "epoch 2055  loss 47.2313  lr 1.000e-03\n",
      "epoch 2056  loss 47.6585  lr 1.000e-03\n",
      "epoch 2057  loss 48.3703  lr 1.000e-03\n",
      "epoch 2058  loss 47.5149  lr 1.000e-03\n",
      "epoch 2059  loss 45.8725  lr 1.000e-03\n",
      "epoch 2060  loss 48.0196  lr 1.000e-03\n",
      "epoch 2061  loss 46.9074  lr 1.000e-03\n",
      "epoch 2062  loss 47.1972  lr 1.000e-03\n",
      "epoch 2063  loss 46.7998  lr 1.000e-03\n",
      "epoch 2064  loss 47.0216  lr 1.000e-03\n",
      "epoch 2065  loss 47.8829  lr 1.000e-03\n",
      "epoch 2066  loss 47.4500  lr 1.000e-03\n",
      "epoch 2067  loss 48.0707  lr 1.000e-03\n",
      "epoch 2068  loss 46.6425  lr 1.000e-03\n",
      "epoch 2069  loss 47.0016  lr 1.000e-03\n",
      "epoch 2070  loss 49.2793  lr 1.000e-03\n",
      "epoch 2071  loss 47.2059  lr 1.000e-03\n",
      "epoch 2072  loss 47.1299  lr 1.000e-03\n",
      "epoch 2073  loss 48.1334  lr 1.000e-03\n",
      "epoch 2074  loss 47.7477  lr 1.000e-03\n",
      "epoch 2075  loss 46.0389  lr 1.000e-03\n",
      "epoch 2076  loss 48.3292  lr 1.000e-03\n",
      "epoch 2077  loss 47.5227  lr 1.000e-03\n",
      "epoch 2078  loss 47.2417  lr 1.000e-03\n",
      "epoch 2079  loss 47.9160  lr 1.000e-03\n",
      "epoch 2080  loss 48.5915  lr 1.000e-03\n",
      "epoch 2081  loss 48.9660  lr 1.000e-03\n",
      "epoch 2082  loss 45.4430  lr 1.000e-03\n",
      "epoch 2083  loss 46.7095  lr 1.000e-03\n",
      "epoch 2084  loss 47.3574  lr 1.000e-03\n",
      "epoch 2085  loss 48.2030  lr 1.000e-03\n",
      "epoch 2086  loss 46.6420  lr 1.000e-03\n",
      "epoch 2087  loss 49.0323  lr 1.000e-03\n",
      "epoch 2088  loss 46.5772  lr 1.000e-03\n",
      "epoch 2089  loss 45.9708  lr 1.000e-03\n",
      "epoch 2090  loss 48.4647  lr 1.000e-03\n",
      "epoch 2091  loss 46.3515  lr 1.000e-03\n",
      "epoch 2092  loss 46.4469  lr 1.000e-03\n",
      "epoch 2093  loss 46.4882  lr 1.000e-03\n",
      "epoch 2094  loss 45.6812  lr 1.000e-03\n",
      "epoch 2095  loss 46.5235  lr 1.000e-03\n",
      "epoch 2096  loss 46.8618  lr 1.000e-03\n",
      "epoch 2097  loss 46.0267  lr 1.000e-03\n",
      "epoch 2098  loss 46.5133  lr 1.000e-03\n",
      "epoch 2099  loss 46.6386  lr 1.000e-03\n",
      "epoch 2100  loss 47.3183  lr 1.000e-03\n",
      "epoch 2101  loss 47.8643  lr 1.000e-03\n",
      "epoch 2102  loss 46.7589  lr 1.000e-03\n",
      "epoch 2103  loss 47.1444  lr 1.000e-03\n",
      "epoch 2104  loss 46.6466  lr 1.000e-03\n",
      "epoch 2105  loss 46.7346  lr 1.000e-03\n",
      "epoch 2106  loss 45.8179  lr 1.000e-03\n",
      "epoch 2107  loss 47.5011  lr 1.000e-03\n",
      "epoch 2108  loss 48.0849  lr 1.000e-03\n",
      "epoch 2109  loss 46.7076  lr 1.000e-03\n",
      "epoch 2110  loss 46.2822  lr 1.000e-03\n",
      "epoch 2111  loss 46.7519  lr 1.000e-03\n",
      "epoch 2112  loss 47.7562  lr 1.000e-03\n",
      "epoch 2113  loss 48.0484  lr 1.000e-03\n",
      "epoch 2114  loss 47.1242  lr 1.000e-03\n",
      "epoch 2115  loss 47.3676  lr 1.000e-03\n",
      "epoch 2116  loss 48.0251  lr 1.000e-03\n",
      "epoch 2117  loss 47.2971  lr 1.000e-03\n",
      "epoch 2118  loss 48.0612  lr 1.000e-03\n",
      "epoch 2119  loss 49.4617  lr 1.000e-03\n",
      "epoch 2120  loss 46.8733  lr 1.000e-03\n",
      "epoch 2121  loss 47.5857  lr 1.000e-03\n",
      "epoch 2122  loss 48.1329  lr 1.000e-03\n",
      "epoch 2123  loss 47.0827  lr 1.000e-03\n",
      "epoch 2124  loss 45.5845  lr 1.000e-03\n",
      "epoch 2125  loss 46.6048  lr 1.000e-03\n",
      "epoch 2126  loss 48.4506  lr 1.000e-03\n",
      "epoch 2127  loss 46.5804  lr 1.000e-03\n",
      "epoch 2128  loss 47.4235  lr 1.000e-03\n",
      "epoch 2129  loss 48.1612  lr 1.000e-03\n",
      "epoch 2130  loss 47.2179  lr 1.000e-03\n",
      "epoch 2131  loss 46.7377  lr 1.000e-03\n",
      "epoch 2132  loss 45.9021  lr 1.000e-03\n",
      "epoch 2133  loss 47.3711  lr 1.000e-03\n",
      "epoch 2134  loss 47.7844  lr 1.000e-03\n",
      "epoch 2135  loss 48.1888  lr 1.000e-03\n",
      "epoch 2136  loss 45.6724  lr 1.000e-03\n",
      "epoch 2137  loss 47.0586  lr 1.000e-03\n",
      "epoch 2138  loss 46.0007  lr 1.000e-03\n",
      "epoch 2139  loss 47.0163  lr 1.000e-03\n",
      "epoch 2140  loss 47.4408  lr 1.000e-03\n",
      "epoch 2141  loss 47.2690  lr 1.000e-03\n",
      "epoch 2142  loss 46.4697  lr 1.000e-03\n",
      "epoch 2143  loss 46.5355  lr 1.000e-03\n",
      "epoch 2144  loss 46.5544  lr 1.000e-03\n",
      "epoch 2145  loss 45.9405  lr 1.000e-03\n",
      "epoch 2146  loss 45.9419  lr 1.000e-03\n",
      "epoch 2147  loss 46.1267  lr 1.000e-03\n",
      "epoch 2148  loss 48.1694  lr 1.000e-03\n",
      "epoch 2149  loss 47.3503  lr 1.000e-03\n",
      "epoch 2150  loss 46.1537  lr 1.000e-03\n",
      "epoch 2151  loss 46.9696  lr 1.000e-03\n",
      "epoch 2152  loss 47.0803  lr 1.000e-03\n",
      "epoch 2153  loss 45.6409  lr 1.000e-03\n",
      "epoch 2154  loss 46.7377  lr 1.000e-03\n",
      "epoch 2155  loss 47.8289  lr 1.000e-03\n",
      "epoch 2156  loss 47.5398  lr 1.000e-03\n",
      "epoch 2157  loss 46.7511  lr 1.000e-03\n",
      "epoch 2158  loss 45.9662  lr 1.000e-03\n",
      "epoch 2159  loss 48.4289  lr 1.000e-03\n",
      "epoch 2160  loss 47.6514  lr 1.000e-03\n",
      "epoch 2161  loss 45.6145  lr 1.000e-03\n",
      "epoch 2162  loss 47.5011  lr 1.000e-03\n",
      "epoch 2163  loss 46.8910  lr 1.000e-03\n",
      "epoch 2164  loss 46.9235  lr 1.000e-03\n",
      "epoch 2165  loss 46.5858  lr 1.000e-03\n",
      "epoch 2166  loss 45.0572  lr 1.000e-03\n",
      "epoch 2167  loss 47.2391  lr 1.000e-03\n",
      "epoch 2168  loss 45.9005  lr 1.000e-03\n",
      "epoch 2169  loss 46.3703  lr 1.000e-03\n",
      "epoch 2170  loss 46.1197  lr 1.000e-03\n",
      "epoch 2171  loss 44.6879  lr 1.000e-03\n",
      "epoch 2172  loss 47.2377  lr 1.000e-03\n",
      "epoch 2173  loss 46.0153  lr 1.000e-03\n",
      "epoch 2174  loss 46.5427  lr 1.000e-03\n",
      "epoch 2175  loss 47.2610  lr 1.000e-03\n",
      "epoch 2176  loss 45.6123  lr 1.000e-03\n",
      "epoch 2177  loss 45.3295  lr 1.000e-03\n",
      "epoch 2178  loss 47.2279  lr 1.000e-03\n",
      "epoch 2179  loss 47.1484  lr 1.000e-03\n",
      "epoch 2180  loss 46.2336  lr 1.000e-03\n",
      "epoch 2181  loss 46.0101  lr 1.000e-03\n",
      "epoch 2182  loss 45.9019  lr 1.000e-03\n",
      "epoch 2183  loss 46.2249  lr 1.000e-03\n",
      "epoch 2184  loss 47.1446  lr 1.000e-03\n",
      "epoch 2185  loss 46.8949  lr 1.000e-03\n",
      "epoch 2186  loss 48.5763  lr 1.000e-03\n",
      "epoch 2187  loss 45.6545  lr 1.000e-03\n",
      "epoch 2188  loss 46.3557  lr 1.000e-03\n",
      "epoch 2189  loss 45.2355  lr 1.000e-03\n",
      "epoch 2190  loss 48.2461  lr 1.000e-03\n",
      "epoch 2191  loss 48.9858  lr 1.000e-03\n",
      "epoch 2192  loss 48.6797  lr 1.000e-03\n",
      "epoch 2193  loss 45.8121  lr 1.000e-03\n",
      "epoch 2194  loss 46.8427  lr 1.000e-03\n",
      "epoch 2195  loss 45.1751  lr 1.000e-03\n",
      "epoch 2196  loss 45.9541  lr 1.000e-03\n",
      "epoch 2197  loss 46.2502  lr 1.000e-03\n",
      "epoch 2198  loss 49.6166  lr 1.000e-03\n",
      "epoch 2199  loss 46.2436  lr 1.000e-03\n",
      "epoch 2200  loss 45.2901  lr 1.000e-03\n",
      "epoch 2201  loss 46.1521  lr 1.000e-03\n",
      "epoch 2202  loss 45.2246  lr 1.000e-03\n",
      "epoch 2203  loss 45.6890  lr 1.000e-03\n",
      "epoch 2204  loss 45.4885  lr 1.000e-03\n",
      "epoch 2205  loss 46.4946  lr 1.000e-03\n",
      "epoch 2206  loss 46.0834  lr 1.000e-03\n",
      "epoch 2207  loss 46.0945  lr 1.000e-03\n",
      "epoch 2208  loss 46.1025  lr 1.000e-03\n",
      "epoch 2209  loss 45.0934  lr 1.000e-03\n",
      "epoch 2210  loss 46.7071  lr 1.000e-03\n",
      "epoch 2211  loss 45.6694  lr 1.000e-03\n",
      "epoch 2212  loss 48.2001  lr 1.000e-03\n",
      "epoch 2213  loss 45.3971  lr 1.000e-03\n",
      "epoch 2214  loss 45.2705  lr 1.000e-03\n",
      "epoch 2215  loss 45.4650  lr 1.000e-03\n",
      "epoch 2216  loss 47.6165  lr 1.000e-03\n",
      "epoch 2217  loss 48.4670  lr 1.000e-03\n",
      "epoch 2218  loss 48.2538  lr 1.000e-03\n",
      "epoch 2219  loss 45.5865  lr 1.000e-03\n",
      "epoch 2220  loss 45.1763  lr 1.000e-03\n",
      "epoch 2221  loss 45.1428  lr 1.000e-03\n",
      "epoch 2222  loss 45.8860  lr 1.000e-03\n",
      "epoch 2223  loss 46.2367  lr 1.000e-03\n",
      "epoch 2224  loss 45.8862  lr 1.000e-03\n",
      "epoch 2225  loss 45.1643  lr 1.000e-03\n",
      "epoch 2226  loss 46.5354  lr 1.000e-03\n",
      "epoch 2227  loss 48.7687  lr 1.000e-03\n",
      "epoch 2228  loss 46.8534  lr 1.000e-03\n",
      "epoch 2229  loss 44.1839  lr 1.000e-03\n",
      "epoch 2230  loss 44.7129  lr 1.000e-03\n",
      "epoch 2231  loss 45.6394  lr 1.000e-03\n",
      "epoch 2232  loss 45.6875  lr 1.000e-03\n",
      "epoch 2233  loss 47.7987  lr 1.000e-03\n",
      "epoch 2234  loss 46.4574  lr 1.000e-03\n",
      "epoch 2235  loss 47.0914  lr 1.000e-03\n",
      "epoch 2236  loss 44.8565  lr 1.000e-03\n",
      "epoch 2237  loss 46.8276  lr 1.000e-03\n",
      "epoch 2238  loss 45.9230  lr 1.000e-03\n",
      "epoch 2239  loss 46.0485  lr 1.000e-03\n",
      "epoch 2240  loss 45.5668  lr 1.000e-03\n",
      "epoch 2241  loss 46.9720  lr 1.000e-03\n",
      "epoch 2242  loss 46.2204  lr 1.000e-03\n",
      "epoch 2243  loss 46.9803  lr 1.000e-03\n",
      "epoch 2244  loss 45.8965  lr 1.000e-03\n",
      "epoch 2245  loss 46.3832  lr 1.000e-03\n",
      "epoch 2246  loss 47.6166  lr 1.000e-03\n",
      "epoch 2247  loss 46.6409  lr 1.000e-03\n",
      "epoch 2248  loss 46.3122  lr 1.000e-03\n",
      "epoch 2249  loss 46.3935  lr 1.000e-03\n",
      "epoch 2250  loss 47.2227  lr 1.000e-03\n",
      "epoch 2251  loss 47.1938  lr 1.000e-03\n",
      "epoch 2252  loss 45.0088  lr 1.000e-03\n",
      "epoch 2253  loss 45.3841  lr 1.000e-03\n",
      "epoch 2254  loss 47.8833  lr 1.000e-03\n",
      "epoch 2255  loss 46.8271  lr 1.000e-03\n",
      "epoch 2256  loss 46.4874  lr 1.000e-03\n",
      "epoch 2257  loss 47.7096  lr 1.000e-03\n",
      "epoch 2258  loss 47.6462  lr 1.000e-03\n",
      "epoch 2259  loss 46.5810  lr 1.000e-03\n",
      "epoch 2260  loss 46.8468  lr 1.000e-03\n",
      "epoch 2261  loss 47.0572  lr 1.000e-03\n",
      "epoch 2262  loss 46.1899  lr 1.000e-03\n",
      "epoch 2263  loss 47.5594  lr 1.000e-03\n",
      "epoch 2264  loss 45.5139  lr 1.000e-03\n",
      "epoch 2265  loss 46.6928  lr 1.000e-03\n",
      "epoch 2266  loss 47.2912  lr 1.000e-03\n",
      "epoch 2267  loss 45.3927  lr 1.000e-03\n",
      "epoch 2268  loss 43.9421  lr 1.000e-03\n",
      "epoch 2269  loss 45.0229  lr 1.000e-03\n",
      "epoch 2270  loss 46.0617  lr 1.000e-03\n",
      "epoch 2271  loss 45.1713  lr 1.000e-03\n",
      "epoch 2272  loss 46.5190  lr 1.000e-03\n",
      "epoch 2273  loss 45.5214  lr 1.000e-03\n",
      "epoch 2274  loss 45.6905  lr 1.000e-03\n",
      "epoch 2275  loss 46.7699  lr 1.000e-03\n",
      "epoch 2276  loss 47.7044  lr 1.000e-03\n",
      "epoch 2277  loss 47.1002  lr 1.000e-03\n",
      "epoch 2278  loss 43.7623  lr 1.000e-03\n",
      "epoch 2279  loss 46.6641  lr 1.000e-03\n",
      "epoch 2280  loss 44.9207  lr 1.000e-03\n",
      "epoch 2281  loss 47.3796  lr 1.000e-03\n",
      "epoch 2282  loss 45.8548  lr 1.000e-03\n",
      "epoch 2283  loss 44.2234  lr 1.000e-03\n",
      "epoch 2284  loss 47.7093  lr 1.000e-03\n",
      "epoch 2285  loss 44.3955  lr 1.000e-03\n",
      "epoch 2286  loss 45.9707  lr 1.000e-03\n",
      "epoch 2287  loss 45.8964  lr 1.000e-03\n",
      "epoch 2288  loss 46.2551  lr 1.000e-03\n",
      "epoch 2289  loss 46.0519  lr 1.000e-03\n",
      "epoch 2290  loss 45.6025  lr 1.000e-03\n",
      "epoch 2291  loss 46.2565  lr 1.000e-03\n",
      "epoch 2292  loss 46.0813  lr 1.000e-03\n",
      "epoch 2293  loss 45.9906  lr 1.000e-03\n",
      "epoch 2294  loss 44.3905  lr 1.000e-03\n",
      "epoch 2295  loss 45.3078  lr 1.000e-03\n",
      "epoch 2296  loss 45.8844  lr 1.000e-03\n",
      "epoch 2297  loss 46.8421  lr 1.000e-03\n",
      "epoch 2298  loss 46.3459  lr 1.000e-03\n",
      "epoch 2299  loss 45.9333  lr 1.000e-03\n",
      "epoch 2300  loss 45.4822  lr 1.000e-03\n",
      "epoch 2301  loss 45.4264  lr 1.000e-03\n",
      "epoch 2302  loss 46.6363  lr 1.000e-03\n",
      "epoch 2303  loss 47.0277  lr 1.000e-03\n",
      "epoch 2304  loss 44.5902  lr 1.000e-03\n",
      "epoch 2305  loss 46.4065  lr 1.000e-03\n",
      "epoch 2306  loss 46.1828  lr 1.000e-03\n",
      "epoch 2307  loss 46.5281  lr 1.000e-03\n",
      "epoch 2308  loss 46.5657  lr 1.000e-03\n",
      "epoch 2309  loss 46.0784  lr 1.000e-03\n",
      "epoch 2310  loss 45.7330  lr 1.000e-03\n",
      "epoch 2311  loss 45.9432  lr 1.000e-03\n",
      "epoch 2312  loss 46.6451  lr 1.000e-03\n",
      "epoch 2313  loss 45.7004  lr 1.000e-03\n",
      "epoch 2314  loss 45.0618  lr 1.000e-03\n",
      "epoch 2315  loss 45.4832  lr 1.000e-03\n",
      "epoch 2316  loss 44.9432  lr 1.000e-03\n",
      "epoch 2317  loss 47.5650  lr 1.000e-03\n",
      "epoch 2318  loss 47.3957  lr 1.000e-03\n",
      "epoch 2319  loss 45.2878  lr 1.000e-03\n",
      "epoch 2320  loss 45.2198  lr 1.000e-03\n",
      "epoch 2321  loss 44.8780  lr 1.000e-03\n",
      "epoch 2322  loss 45.9905  lr 1.000e-03\n",
      "epoch 2323  loss 46.7265  lr 1.000e-03\n",
      "epoch 2324  loss 47.0880  lr 1.000e-03\n",
      "epoch 2325  loss 45.9801  lr 1.000e-03\n",
      "epoch 2326  loss 47.0392  lr 1.000e-03\n",
      "epoch 2327  loss 46.2608  lr 1.000e-03\n",
      "epoch 2328  loss 46.0353  lr 1.000e-03\n",
      "epoch 2329  loss 46.5462  lr 1.000e-03\n",
      "epoch 2330  loss 46.7032  lr 1.000e-03\n",
      "epoch 2331  loss 44.8799  lr 1.000e-03\n",
      "epoch 2332  loss 44.0238  lr 1.000e-03\n",
      "epoch 2333  loss 44.5010  lr 1.000e-03\n",
      "epoch 2334  loss 45.4742  lr 1.000e-03\n",
      "epoch 2335  loss 45.7668  lr 1.000e-03\n",
      "epoch 2336  loss 45.5027  lr 1.000e-03\n",
      "epoch 2337  loss 47.2445  lr 1.000e-03\n",
      "epoch 2338  loss 44.0698  lr 1.000e-03\n",
      "epoch 2339  loss 45.0255  lr 1.000e-03\n",
      "epoch 2340  loss 44.9706  lr 1.000e-03\n",
      "epoch 2341  loss 43.8551  lr 1.000e-03\n",
      "epoch 2342  loss 45.9919  lr 1.000e-03\n",
      "epoch 2343  loss 46.2447  lr 1.000e-03\n",
      "epoch 2344  loss 44.6373  lr 1.000e-03\n",
      "epoch 2345  loss 45.7633  lr 1.000e-03\n",
      "epoch 2346  loss 46.8168  lr 1.000e-03\n",
      "epoch 2347  loss 45.3131  lr 1.000e-03\n",
      "epoch 2348  loss 45.4736  lr 1.000e-03\n",
      "epoch 2349  loss 44.7583  lr 1.000e-03\n",
      "epoch 2350  loss 45.8358  lr 1.000e-03\n",
      "epoch 2351  loss 46.0778  lr 1.000e-03\n",
      "epoch 2352  loss 45.6805  lr 1.000e-03\n",
      "epoch 2353  loss 47.7740  lr 1.000e-03\n",
      "epoch 2354  loss 46.8827  lr 1.000e-03\n",
      "epoch 2355  loss 45.5146  lr 1.000e-03\n",
      "epoch 2356  loss 45.8217  lr 1.000e-03\n",
      "epoch 2357  loss 47.4329  lr 1.000e-03\n",
      "epoch 2358  loss 45.4245  lr 1.000e-03\n",
      "epoch 2359  loss 45.2777  lr 1.000e-03\n",
      "epoch 2360  loss 44.4005  lr 1.000e-03\n",
      "epoch 2361  loss 46.7523  lr 1.000e-03\n",
      "epoch 2362  loss 45.5143  lr 1.000e-03\n",
      "epoch 2363  loss 44.6834  lr 1.000e-03\n",
      "epoch 2364  loss 46.3580  lr 1.000e-03\n",
      "epoch 2365  loss 46.7886  lr 1.000e-03\n",
      "epoch 2366  loss 45.4945  lr 1.000e-03\n",
      "epoch 2367  loss 45.6196  lr 1.000e-03\n",
      "epoch 2368  loss 47.2506  lr 1.000e-03\n",
      "epoch 2369  loss 45.1774  lr 1.000e-03\n",
      "epoch 2370  loss 44.9141  lr 1.000e-03\n",
      "epoch 2371  loss 46.8203  lr 1.000e-03\n",
      "epoch 2372  loss 47.1136  lr 1.000e-03\n",
      "epoch 2373  loss 45.3152  lr 1.000e-03\n",
      "epoch 2374  loss 46.4269  lr 1.000e-03\n",
      "epoch 2375  loss 46.7111  lr 1.000e-03\n",
      "epoch 2376  loss 45.5804  lr 1.000e-03\n",
      "epoch 2377  loss 45.5757  lr 1.000e-03\n",
      "epoch 2378  loss 45.4704  lr 1.000e-03\n",
      "epoch 2379  loss 45.4422  lr 1.000e-03\n",
      "epoch 2380  loss 45.7137  lr 1.000e-03\n",
      "epoch 2381  loss 45.0470  lr 1.000e-03\n",
      "epoch 2382  loss 45.0190  lr 1.000e-03\n",
      "epoch 2383  loss 46.4617  lr 1.000e-03\n",
      "epoch 2384  loss 45.4093  lr 1.000e-03\n",
      "epoch 2385  loss 46.5162  lr 1.000e-03\n",
      "epoch 2386  loss 46.6650  lr 1.000e-03\n",
      "epoch 2387  loss 45.9242  lr 1.000e-03\n",
      "epoch 2388  loss 46.4892  lr 1.000e-03\n",
      "epoch 2389  loss 45.8056  lr 1.000e-03\n",
      "epoch 2390  loss 43.6895  lr 1.000e-03\n",
      "epoch 2391  loss 45.3856  lr 1.000e-03\n",
      "epoch 2392  loss 44.2904  lr 1.000e-03\n",
      "epoch 2393  loss 46.4855  lr 1.000e-03\n",
      "epoch 2394  loss 44.3849  lr 1.000e-03\n",
      "epoch 2395  loss 43.9239  lr 1.000e-03\n",
      "epoch 2396  loss 46.4279  lr 1.000e-03\n",
      "epoch 2397  loss 45.3587  lr 1.000e-03\n",
      "epoch 2398  loss 45.0048  lr 1.000e-03\n",
      "epoch 2399  loss 45.6732  lr 1.000e-03\n",
      "epoch 2400  loss 46.1097  lr 1.000e-03\n",
      "epoch 2401  loss 45.2731  lr 1.000e-03\n",
      "epoch 2402  loss 45.7222  lr 1.000e-03\n",
      "epoch 2403  loss 47.5918  lr 1.000e-03\n",
      "epoch 2404  loss 46.6423  lr 1.000e-03\n",
      "epoch 2405  loss 46.8747  lr 1.000e-03\n",
      "epoch 2406  loss 46.0708  lr 1.000e-03\n",
      "epoch 2407  loss 45.8966  lr 1.000e-03\n",
      "epoch 2408  loss 45.6194  lr 1.000e-03\n",
      "epoch 2409  loss 45.7856  lr 1.000e-03\n",
      "epoch 2410  loss 46.3722  lr 1.000e-03\n",
      "epoch 2411  loss 45.1090  lr 1.000e-03\n",
      "epoch 2412  loss 45.0324  lr 1.000e-03\n",
      "epoch 2413  loss 45.9566  lr 1.000e-03\n",
      "epoch 2414  loss 46.3067  lr 1.000e-03\n",
      "epoch 2415  loss 44.7921  lr 1.000e-03\n",
      "epoch 2416  loss 46.4260  lr 1.000e-03\n",
      "epoch 2417  loss 44.8051  lr 1.000e-03\n",
      "epoch 2418  loss 45.2248  lr 1.000e-03\n",
      "epoch 2419  loss 45.6285  lr 1.000e-03\n",
      "epoch 2420  loss 45.5949  lr 1.000e-03\n",
      "epoch 2421  loss 43.7510  lr 1.000e-03\n",
      "epoch 2422  loss 46.2681  lr 1.000e-03\n",
      "epoch 2423  loss 45.6302  lr 1.000e-03\n",
      "epoch 2424  loss 46.0774  lr 1.000e-03\n",
      "epoch 2425  loss 45.1875  lr 1.000e-03\n",
      "epoch 2426  loss 45.4018  lr 1.000e-03\n",
      "epoch 2427  loss 44.7886  lr 1.000e-03\n",
      "epoch 2428  loss 45.4278  lr 1.000e-03\n",
      "epoch 2429  loss 46.8461  lr 1.000e-03\n",
      "epoch 2430  loss 44.7919  lr 1.000e-03\n",
      "epoch 2431  loss 45.8299  lr 1.000e-03\n",
      "epoch 2432  loss 44.5532  lr 1.000e-03\n",
      "epoch 2433  loss 44.1563  lr 1.000e-03\n",
      "epoch 2434  loss 45.7274  lr 1.000e-03\n",
      "epoch 2435  loss 46.7039  lr 1.000e-03\n",
      "epoch 2436  loss 44.8804  lr 1.000e-03\n",
      "epoch 2437  loss 43.9112  lr 1.000e-03\n",
      "epoch 2438  loss 44.8275  lr 1.000e-03\n",
      "epoch 2439  loss 46.7725  lr 1.000e-03\n",
      "epoch 2440  loss 46.8369  lr 1.000e-03\n",
      "epoch 2441  loss 46.1315  lr 1.000e-03\n",
      "epoch 2442  loss 44.6919  lr 1.000e-03\n",
      "epoch 2443  loss 43.7597  lr 1.000e-03\n",
      "epoch 2444  loss 44.3570  lr 1.000e-03\n",
      "epoch 2445  loss 44.3214  lr 1.000e-03\n",
      "epoch 2446  loss 44.3377  lr 1.000e-03\n",
      "epoch 2447  loss 44.6917  lr 1.000e-03\n",
      "epoch 2448  loss 43.7449  lr 1.000e-03\n",
      "epoch 2449  loss 45.9725  lr 1.000e-03\n",
      "epoch 2450  loss 44.6405  lr 1.000e-03\n",
      "epoch 2451  loss 45.2334  lr 1.000e-03\n",
      "epoch 2452  loss 44.8584  lr 1.000e-03\n",
      "epoch 2453  loss 45.7367  lr 1.000e-03\n",
      "epoch 2454  loss 45.7941  lr 1.000e-03\n",
      "epoch 2455  loss 45.2590  lr 1.000e-03\n",
      "epoch 2456  loss 45.1479  lr 1.000e-03\n",
      "epoch 2457  loss 45.5508  lr 1.000e-03\n",
      "epoch 2458  loss 46.2174  lr 1.000e-03\n",
      "epoch 2459  loss 43.9877  lr 1.000e-03\n",
      "epoch 2460  loss 45.6450  lr 1.000e-03\n",
      "epoch 2461  loss 45.6413  lr 1.000e-03\n",
      "epoch 2462  loss 45.7625  lr 1.000e-03\n",
      "epoch 2463  loss 47.0436  lr 1.000e-03\n",
      "epoch 2464  loss 45.7419  lr 1.000e-03\n",
      "epoch 2465  loss 44.9633  lr 1.000e-03\n",
      "epoch 2466  loss 44.6716  lr 1.000e-03\n",
      "epoch 2467  loss 45.4935  lr 1.000e-03\n",
      "epoch 2468  loss 45.0590  lr 1.000e-03\n",
      "epoch 2469  loss 45.6924  lr 1.000e-03\n",
      "epoch 2470  loss 45.9836  lr 1.000e-03\n",
      "epoch 2471  loss 44.2033  lr 1.000e-03\n",
      "epoch 2472  loss 45.2576  lr 1.000e-03\n",
      "epoch 2473  loss 45.0708  lr 1.000e-03\n",
      "epoch 2474  loss 45.4489  lr 1.000e-03\n",
      "epoch 2475  loss 45.7224  lr 1.000e-03\n",
      "epoch 2476  loss 46.0994  lr 1.000e-03\n",
      "epoch 2477  loss 45.6122  lr 1.000e-03\n",
      "epoch 2478  loss 45.2585  lr 1.000e-03\n",
      "epoch 2479  loss 45.0725  lr 1.000e-03\n",
      "epoch 2480  loss 45.9081  lr 1.000e-03\n",
      "epoch 2481  loss 44.4191  lr 1.000e-03\n",
      "epoch 2482  loss 47.0323  lr 1.000e-03\n",
      "epoch 2483  loss 46.7353  lr 1.000e-03\n",
      "epoch 2484  loss 43.6372  lr 1.000e-03\n",
      "epoch 2485  loss 47.0262  lr 1.000e-03\n",
      "epoch 2486  loss 46.2287  lr 1.000e-03\n",
      "epoch 2487  loss 44.0959  lr 1.000e-03\n",
      "epoch 2488  loss 43.5684  lr 1.000e-03\n",
      "epoch 2489  loss 44.8550  lr 1.000e-03\n",
      "epoch 2490  loss 46.6990  lr 1.000e-03\n",
      "epoch 2491  loss 44.0027  lr 1.000e-03\n",
      "epoch 2492  loss 44.8440  lr 1.000e-03\n",
      "epoch 2493  loss 44.8864  lr 1.000e-03\n",
      "epoch 2494  loss 47.2496  lr 1.000e-03\n",
      "epoch 2495  loss 44.7236  lr 1.000e-03\n",
      "epoch 2496  loss 45.8190  lr 1.000e-03\n",
      "epoch 2497  loss 45.4578  lr 1.000e-03\n",
      "epoch 2498  loss 45.1603  lr 1.000e-03\n",
      "epoch 2499  loss 45.8622  lr 1.000e-03\n",
      "epoch 2500  loss 46.2587  lr 1.000e-03\n",
      "epoch 2501  loss 44.6622  lr 1.000e-03\n",
      "epoch 2502  loss 44.0576  lr 1.000e-03\n",
      "epoch 2503  loss 44.7421  lr 1.000e-03\n",
      "epoch 2504  loss 44.7984  lr 1.000e-03\n",
      "epoch 2505  loss 44.4408  lr 1.000e-03\n",
      "epoch 2506  loss 43.9414  lr 1.000e-03\n",
      "epoch 2507  loss 43.4580  lr 1.000e-03\n",
      "epoch 2508  loss 43.9400  lr 1.000e-03\n",
      "epoch 2509  loss 47.2116  lr 1.000e-03\n",
      "epoch 2510  loss 46.0768  lr 1.000e-03\n",
      "epoch 2511  loss 44.9620  lr 1.000e-03\n",
      "epoch 2512  loss 45.1233  lr 1.000e-03\n",
      "epoch 2513  loss 45.1954  lr 1.000e-03\n",
      "epoch 2514  loss 46.6650  lr 1.000e-03\n",
      "epoch 2515  loss 44.9207  lr 1.000e-03\n",
      "epoch 2516  loss 44.0818  lr 1.000e-03\n",
      "epoch 2517  loss 44.8908  lr 1.000e-03\n",
      "epoch 2518  loss 44.7046  lr 1.000e-03\n",
      "epoch 2519  loss 44.4078  lr 1.000e-03\n",
      "epoch 2520  loss 45.7101  lr 1.000e-03\n",
      "epoch 2521  loss 44.9548  lr 1.000e-03\n",
      "epoch 2522  loss 43.7919  lr 1.000e-03\n",
      "epoch 2523  loss 45.6356  lr 1.000e-03\n",
      "epoch 2524  loss 46.0193  lr 1.000e-03\n",
      "epoch 2525  loss 44.2547  lr 1.000e-03\n",
      "epoch 2526  loss 45.3235  lr 1.000e-03\n",
      "epoch 2527  loss 44.1609  lr 1.000e-03\n",
      "epoch 2528  loss 47.0985  lr 1.000e-03\n",
      "epoch 2529  loss 45.6910  lr 1.000e-03\n",
      "epoch 2530  loss 43.6607  lr 1.000e-03\n",
      "epoch 2531  loss 44.5441  lr 1.000e-03\n",
      "epoch 2532  loss 43.5989  lr 1.000e-03\n",
      "epoch 2533  loss 45.1883  lr 1.000e-03\n",
      "epoch 2534  loss 45.4866  lr 1.000e-03\n",
      "epoch 2535  loss 46.8334  lr 1.000e-03\n",
      "epoch 2536  loss 43.3611  lr 1.000e-03\n",
      "epoch 2537  loss 45.0247  lr 1.000e-03\n",
      "epoch 2538  loss 45.4693  lr 1.000e-03\n",
      "epoch 2539  loss 43.6077  lr 1.000e-03\n",
      "epoch 2540  loss 43.7303  lr 1.000e-03\n",
      "epoch 2541  loss 46.5953  lr 1.000e-03\n",
      "epoch 2542  loss 45.2967  lr 1.000e-03\n",
      "epoch 2543  loss 43.2176  lr 1.000e-03\n",
      "epoch 2544  loss 45.2341  lr 1.000e-03\n",
      "epoch 2545  loss 43.1220  lr 1.000e-03\n",
      "epoch 2546  loss 44.4843  lr 1.000e-03\n",
      "epoch 2547  loss 44.9047  lr 1.000e-03\n",
      "epoch 2548  loss 43.3864  lr 1.000e-03\n",
      "epoch 2549  loss 45.3315  lr 1.000e-03\n",
      "epoch 2550  loss 44.5046  lr 1.000e-03\n",
      "epoch 2551  loss 44.3246  lr 1.000e-03\n",
      "epoch 2552  loss 46.3081  lr 1.000e-03\n",
      "epoch 2553  loss 45.8622  lr 1.000e-03\n",
      "epoch 2554  loss 45.4215  lr 1.000e-03\n",
      "epoch 2555  loss 46.8898  lr 1.000e-03\n",
      "epoch 2556  loss 45.2149  lr 1.000e-03\n",
      "epoch 2557  loss 45.0374  lr 1.000e-03\n",
      "epoch 2558  loss 45.6227  lr 1.000e-03\n",
      "epoch 2559  loss 43.5264  lr 1.000e-03\n",
      "epoch 2560  loss 44.2951  lr 1.000e-03\n",
      "epoch 2561  loss 45.1864  lr 1.000e-03\n",
      "epoch 2562  loss 44.5417  lr 1.000e-03\n",
      "epoch 2563  loss 45.3751  lr 1.000e-03\n",
      "epoch 2564  loss 45.2095  lr 1.000e-03\n",
      "epoch 2565  loss 44.8928  lr 1.000e-03\n",
      "epoch 2566  loss 46.3312  lr 1.000e-03\n",
      "epoch 2567  loss 43.2063  lr 1.000e-03\n",
      "epoch 2568  loss 44.2467  lr 1.000e-03\n",
      "epoch 2569  loss 44.9931  lr 1.000e-03\n",
      "epoch 2570  loss 45.3146  lr 1.000e-03\n",
      "epoch 2571  loss 45.6672  lr 1.000e-03\n",
      "epoch 2572  loss 44.4376  lr 1.000e-03\n",
      "epoch 2573  loss 43.9860  lr 1.000e-03\n",
      "epoch 2574  loss 44.8812  lr 1.000e-03\n",
      "epoch 2575  loss 45.9053  lr 1.000e-03\n",
      "epoch 2576  loss 45.8565  lr 1.000e-03\n",
      "epoch 2577  loss 46.1605  lr 1.000e-03\n",
      "epoch 2578  loss 44.7416  lr 1.000e-03\n",
      "epoch 2579  loss 45.1153  lr 1.000e-03\n",
      "epoch 2580  loss 45.6036  lr 1.000e-03\n",
      "epoch 2581  loss 43.4136  lr 1.000e-03\n",
      "epoch 2582  loss 45.3750  lr 1.000e-03\n",
      "epoch 2583  loss 44.6347  lr 1.000e-03\n",
      "epoch 2584  loss 44.2136  lr 1.000e-03\n",
      "epoch 2585  loss 44.9241  lr 1.000e-03\n",
      "epoch 2586  loss 44.4340  lr 1.000e-03\n",
      "epoch 2587  loss 44.9909  lr 1.000e-03\n",
      "epoch 2588  loss 46.6388  lr 1.000e-03\n",
      "epoch 2589  loss 45.3671  lr 1.000e-03\n",
      "epoch 2590  loss 45.5047  lr 1.000e-03\n",
      "epoch 2591  loss 46.5826  lr 1.000e-03\n",
      "epoch 2592  loss 44.6556  lr 1.000e-03\n",
      "epoch 2593  loss 44.6330  lr 1.000e-03\n",
      "epoch 2594  loss 44.7203  lr 1.000e-03\n",
      "epoch 2595  loss 45.4498  lr 1.000e-03\n",
      "epoch 2596  loss 43.1897  lr 1.000e-03\n",
      "epoch 2597  loss 43.6615  lr 1.000e-03\n",
      "epoch 2598  loss 43.6899  lr 1.000e-03\n",
      "epoch 2599  loss 45.1705  lr 1.000e-03\n",
      "epoch 2600  loss 44.4587  lr 1.000e-03\n",
      "epoch 2601  loss 44.5919  lr 1.000e-03\n",
      "epoch 2602  loss 44.5408  lr 1.000e-03\n",
      "epoch 2603  loss 45.0552  lr 1.000e-03\n",
      "epoch 2604  loss 44.2484  lr 1.000e-03\n",
      "epoch 2605  loss 44.4125  lr 1.000e-03\n",
      "epoch 2606  loss 45.0165  lr 1.000e-03\n",
      "epoch 2607  loss 46.5088  lr 1.000e-03\n",
      "epoch 2608  loss 43.3706  lr 1.000e-03\n",
      "epoch 2609  loss 42.4871  lr 1.000e-03\n",
      "epoch 2610  loss 44.4251  lr 1.000e-03\n",
      "epoch 2611  loss 43.6471  lr 1.000e-03\n",
      "epoch 2612  loss 45.5097  lr 1.000e-03\n",
      "epoch 2613  loss 43.6283  lr 1.000e-03\n",
      "epoch 2614  loss 46.4310  lr 1.000e-03\n",
      "epoch 2615  loss 44.9327  lr 1.000e-03\n",
      "epoch 2616  loss 44.2167  lr 1.000e-03\n",
      "epoch 2617  loss 44.2151  lr 1.000e-03\n",
      "epoch 2618  loss 45.3078  lr 1.000e-03\n",
      "epoch 2619  loss 43.3637  lr 1.000e-03\n",
      "epoch 2620  loss 44.7941  lr 1.000e-03\n",
      "epoch 2621  loss 43.9608  lr 1.000e-03\n",
      "epoch 2622  loss 44.7999  lr 1.000e-03\n",
      "epoch 2623  loss 43.9290  lr 1.000e-03\n",
      "epoch 2624  loss 45.2612  lr 1.000e-03\n",
      "epoch 2625  loss 44.7290  lr 1.000e-03\n",
      "epoch 2626  loss 46.0581  lr 1.000e-03\n",
      "epoch 2627  loss 44.4615  lr 1.000e-03\n",
      "epoch 2628  loss 44.8453  lr 1.000e-03\n",
      "epoch 2629  loss 46.5100  lr 1.000e-03\n",
      "epoch 2630  loss 44.5169  lr 1.000e-03\n",
      "epoch 2631  loss 43.6496  lr 1.000e-03\n",
      "epoch 2632  loss 46.3213  lr 1.000e-03\n",
      "epoch 2633  loss 45.6424  lr 1.000e-03\n",
      "epoch 2634  loss 44.1079  lr 1.000e-03\n",
      "epoch 2635  loss 44.7803  lr 1.000e-03\n",
      "epoch 2636  loss 44.2196  lr 1.000e-03\n",
      "epoch 2637  loss 44.2894  lr 1.000e-03\n",
      "epoch 2638  loss 45.9098  lr 1.000e-03\n",
      "epoch 2639  loss 45.9583  lr 1.000e-03\n",
      "epoch 2640  loss 42.7631  lr 1.000e-03\n",
      "epoch 2641  loss 44.0832  lr 1.000e-03\n",
      "epoch 2642  loss 44.1174  lr 1.000e-03\n",
      "epoch 2643  loss 45.1371  lr 1.000e-03\n",
      "epoch 2644  loss 43.6435  lr 1.000e-03\n",
      "epoch 2645  loss 42.8351  lr 1.000e-03\n",
      "epoch 2646  loss 44.5961  lr 1.000e-03\n",
      "epoch 2647  loss 45.2138  lr 1.000e-03\n",
      "epoch 2648  loss 45.4754  lr 1.000e-03\n",
      "epoch 2649  loss 42.2417  lr 1.000e-03\n",
      "epoch 2650  loss 44.7684  lr 1.000e-03\n",
      "epoch 2651  loss 43.0408  lr 1.000e-03\n",
      "epoch 2652  loss 44.5875  lr 1.000e-03\n",
      "epoch 2653  loss 46.6542  lr 1.000e-03\n",
      "epoch 2654  loss 44.8533  lr 1.000e-03\n",
      "epoch 2655  loss 45.2792  lr 1.000e-03\n",
      "epoch 2656  loss 44.0728  lr 1.000e-03\n",
      "epoch 2657  loss 43.5234  lr 1.000e-03\n",
      "epoch 2658  loss 43.1122  lr 1.000e-03\n",
      "epoch 2659  loss 46.8755  lr 1.000e-03\n",
      "epoch 2660  loss 43.8646  lr 1.000e-03\n",
      "epoch 2661  loss 45.2666  lr 1.000e-03\n",
      "epoch 2662  loss 45.0332  lr 1.000e-03\n",
      "epoch 2663  loss 45.2050  lr 1.000e-03\n",
      "epoch 2664  loss 44.9675  lr 1.000e-03\n",
      "epoch 2665  loss 45.8037  lr 1.000e-03\n",
      "epoch 2666  loss 43.5680  lr 1.000e-03\n",
      "epoch 2667  loss 43.9191  lr 1.000e-03\n",
      "epoch 2668  loss 42.6616  lr 1.000e-03\n",
      "epoch 2669  loss 44.2128  lr 1.000e-03\n",
      "epoch 2670  loss 43.8107  lr 1.000e-03\n",
      "epoch 2671  loss 43.9281  lr 1.000e-03\n",
      "epoch 2672  loss 45.4537  lr 1.000e-03\n",
      "epoch 2673  loss 44.9581  lr 1.000e-03\n",
      "epoch 2674  loss 45.1752  lr 1.000e-03\n",
      "epoch 2675  loss 46.3477  lr 1.000e-03\n",
      "epoch 2676  loss 45.4100  lr 1.000e-03\n",
      "epoch 2677  loss 44.6634  lr 1.000e-03\n",
      "epoch 2678  loss 44.3559  lr 1.000e-03\n",
      "epoch 2679  loss 44.1916  lr 1.000e-03\n",
      "epoch 2680  loss 43.5459  lr 1.000e-03\n",
      "epoch 2681  loss 46.0366  lr 1.000e-03\n",
      "epoch 2682  loss 44.4358  lr 1.000e-03\n",
      "epoch 2683  loss 44.7454  lr 1.000e-03\n",
      "epoch 2684  loss 44.9616  lr 1.000e-03\n",
      "epoch 2685  loss 45.4358  lr 1.000e-03\n",
      "epoch 2686  loss 43.9400  lr 1.000e-03\n",
      "epoch 2687  loss 44.7562  lr 1.000e-03\n",
      "epoch 2688  loss 43.8323  lr 1.000e-03\n",
      "epoch 2689  loss 44.5125  lr 1.000e-03\n",
      "epoch 2690  loss 43.5991  lr 1.000e-03\n",
      "epoch 2691  loss 43.8324  lr 1.000e-03\n",
      "epoch 2692  loss 43.1876  lr 1.000e-03\n",
      "epoch 2693  loss 42.4742  lr 1.000e-03\n",
      "epoch 2694  loss 43.8660  lr 1.000e-03\n",
      "epoch 2695  loss 43.1558  lr 1.000e-03\n",
      "epoch 2696  loss 44.3366  lr 1.000e-03\n",
      "epoch 2697  loss 44.0540  lr 1.000e-03\n",
      "epoch 2698  loss 44.1872  lr 1.000e-03\n",
      "epoch 2699  loss 43.3416  lr 1.000e-03\n",
      "epoch 2700  loss 43.2787  lr 1.000e-03\n",
      "epoch 2701  loss 44.9072  lr 1.000e-03\n",
      "epoch 2702  loss 45.7363  lr 1.000e-03\n",
      "epoch 2703  loss 46.0282  lr 1.000e-03\n",
      "epoch 2704  loss 43.3463  lr 1.000e-03\n",
      "epoch 2705  loss 45.8878  lr 1.000e-03\n",
      "epoch 2706  loss 43.1214  lr 1.000e-03\n",
      "epoch 2707  loss 42.8754  lr 1.000e-03\n",
      "epoch 2708  loss 43.9442  lr 1.000e-03\n",
      "epoch 2709  loss 45.0847  lr 1.000e-03\n",
      "epoch 2710  loss 44.2141  lr 1.000e-03\n",
      "epoch 2711  loss 42.4634  lr 1.000e-03\n",
      "epoch 2712  loss 43.4886  lr 1.000e-03\n",
      "epoch 2713  loss 44.9558  lr 1.000e-03\n",
      "epoch 2714  loss 43.6292  lr 1.000e-03\n",
      "epoch 2715  loss 43.3533  lr 1.000e-03\n",
      "epoch 2716  loss 45.3426  lr 1.000e-03\n",
      "epoch 2717  loss 44.5709  lr 1.000e-03\n",
      "epoch 2718  loss 44.3046  lr 1.000e-03\n",
      "epoch 2719  loss 45.1805  lr 1.000e-03\n",
      "epoch 2720  loss 44.7295  lr 1.000e-03\n",
      "epoch 2721  loss 44.4618  lr 1.000e-03\n",
      "epoch 2722  loss 44.2581  lr 1.000e-03\n",
      "epoch 2723  loss 45.5855  lr 1.000e-03\n",
      "epoch 2724  loss 41.6994  lr 1.000e-03\n",
      "epoch 2725  loss 44.7432  lr 1.000e-03\n",
      "epoch 2726  loss 43.9672  lr 1.000e-03\n",
      "epoch 2727  loss 45.0014  lr 1.000e-03\n",
      "epoch 2728  loss 46.0311  lr 1.000e-03\n",
      "epoch 2729  loss 45.2981  lr 1.000e-03\n",
      "epoch 2730  loss 43.5183  lr 1.000e-03\n",
      "epoch 2731  loss 44.2602  lr 1.000e-03\n",
      "epoch 2732  loss 42.9349  lr 1.000e-03\n",
      "epoch 2733  loss 44.2466  lr 1.000e-03\n",
      "epoch 2734  loss 43.8189  lr 1.000e-03\n",
      "epoch 2735  loss 44.4204  lr 1.000e-03\n",
      "epoch 2736  loss 44.0790  lr 1.000e-03\n",
      "epoch 2737  loss 42.7850  lr 1.000e-03\n",
      "epoch 2738  loss 44.5205  lr 1.000e-03\n",
      "epoch 2739  loss 47.3032  lr 1.000e-03\n",
      "epoch 2740  loss 43.4989  lr 1.000e-03\n",
      "epoch 2741  loss 43.7441  lr 1.000e-03\n",
      "epoch 2742  loss 44.8425  lr 1.000e-03\n",
      "epoch 2743  loss 44.6081  lr 1.000e-03\n",
      "epoch 2744  loss 43.7551  lr 1.000e-03\n",
      "epoch 2745  loss 44.6586  lr 1.000e-03\n",
      "epoch 2746  loss 43.5005  lr 1.000e-03\n",
      "epoch 2747  loss 44.6103  lr 1.000e-03\n",
      "epoch 2748  loss 44.6340  lr 1.000e-03\n",
      "epoch 2749  loss 43.9605  lr 1.000e-03\n",
      "epoch 2750  loss 43.9281  lr 1.000e-03\n",
      "epoch 2751  loss 44.9349  lr 1.000e-03\n",
      "epoch 2752  loss 43.0570  lr 1.000e-03\n",
      "epoch 2753  loss 43.3003  lr 1.000e-03\n",
      "epoch 2754  loss 44.2540  lr 1.000e-03\n",
      "epoch 2755  loss 42.7084  lr 1.000e-03\n",
      "epoch 2756  loss 44.1812  lr 1.000e-03\n",
      "epoch 2757  loss 43.5420  lr 1.000e-03\n",
      "epoch 2758  loss 44.3607  lr 1.000e-03\n",
      "epoch 2759  loss 43.6904  lr 1.000e-03\n",
      "epoch 2760  loss 45.1251  lr 1.000e-03\n",
      "epoch 2761  loss 45.2343  lr 1.000e-03\n",
      "epoch 2762  loss 42.8794  lr 1.000e-03\n",
      "epoch 2763  loss 44.8187  lr 1.000e-03\n",
      "epoch 2764  loss 43.3032  lr 1.000e-03\n",
      "epoch 2765  loss 44.9518  lr 1.000e-03\n",
      "epoch 2766  loss 46.0504  lr 1.000e-03\n",
      "epoch 2767  loss 47.2027  lr 1.000e-03\n",
      "epoch 2768  loss 45.1053  lr 1.000e-03\n",
      "epoch 2769  loss 44.9091  lr 1.000e-03\n",
      "epoch 2770  loss 44.3254  lr 1.000e-03\n",
      "epoch 2771  loss 44.3770  lr 1.000e-03\n",
      "epoch 2772  loss 44.8831  lr 1.000e-03\n",
      "epoch 2773  loss 43.3468  lr 1.000e-03\n",
      "epoch 2774  loss 44.7518  lr 1.000e-03\n",
      "epoch 2775  loss 45.3362  lr 1.000e-03\n",
      "epoch 2776  loss 45.5243  lr 1.000e-03\n",
      "epoch 2777  loss 44.3518  lr 1.000e-03\n",
      "epoch 2778  loss 46.1513  lr 1.000e-03\n",
      "epoch 2779  loss 43.3227  lr 1.000e-03\n",
      "epoch 2780  loss 43.1721  lr 1.000e-03\n",
      "epoch 2781  loss 44.6379  lr 1.000e-03\n",
      "epoch 2782  loss 43.5948  lr 1.000e-03\n",
      "epoch 2783  loss 44.0484  lr 1.000e-03\n",
      "epoch 2784  loss 44.1870  lr 1.000e-03\n",
      "epoch 2785  loss 42.8425  lr 1.000e-03\n",
      "epoch 2786  loss 43.3884  lr 1.000e-03\n",
      "epoch 2787  loss 44.9718  lr 1.000e-03\n",
      "epoch 2788  loss 43.6596  lr 1.000e-03\n",
      "epoch 2789  loss 43.0886  lr 1.000e-03\n",
      "epoch 2790  loss 45.8136  lr 1.000e-03\n",
      "epoch 2791  loss 42.9251  lr 1.000e-03\n",
      "epoch 2792  loss 42.7020  lr 1.000e-03\n",
      "epoch 2793  loss 44.1873  lr 1.000e-03\n",
      "epoch 2794  loss 41.8473  lr 1.000e-03\n",
      "epoch 2795  loss 42.6846  lr 1.000e-03\n",
      "epoch 2796  loss 45.2661  lr 1.000e-03\n",
      "epoch 2797  loss 43.8905  lr 1.000e-03\n",
      "epoch 2798  loss 44.6927  lr 1.000e-03\n",
      "epoch 2799  loss 44.0985  lr 1.000e-03\n",
      "epoch 2800  loss 44.7128  lr 1.000e-03\n",
      "epoch 2801  loss 45.1623  lr 1.000e-03\n",
      "epoch 2802  loss 45.6084  lr 1.000e-03\n",
      "epoch 2803  loss 43.4901  lr 1.000e-03\n",
      "epoch 2804  loss 45.7175  lr 1.000e-03\n",
      "epoch 2805  loss 46.6351  lr 1.000e-03\n",
      "epoch 2806  loss 43.6426  lr 1.000e-03\n",
      "epoch 2807  loss 43.3518  lr 1.000e-03\n",
      "epoch 2808  loss 42.6810  lr 1.000e-03\n",
      "epoch 2809  loss 45.3191  lr 1.000e-03\n",
      "epoch 2810  loss 43.7368  lr 1.000e-03\n",
      "epoch 2811  loss 45.5081  lr 1.000e-03\n",
      "epoch 2812  loss 44.4572  lr 1.000e-03\n",
      "epoch 2813  loss 43.3563  lr 1.000e-03\n",
      "epoch 2814  loss 42.0357  lr 1.000e-03\n",
      "epoch 2815  loss 44.4921  lr 1.000e-03\n",
      "epoch 2816  loss 45.7278  lr 1.000e-03\n",
      "epoch 2817  loss 44.6653  lr 1.000e-03\n",
      "epoch 2818  loss 43.6209  lr 1.000e-03\n",
      "epoch 2819  loss 42.0513  lr 1.000e-03\n",
      "epoch 2820  loss 45.1427  lr 1.000e-03\n",
      "epoch 2821  loss 43.8911  lr 1.000e-03\n",
      "epoch 2822  loss 42.8678  lr 1.000e-03\n",
      "epoch 2823  loss 46.1761  lr 1.000e-03\n",
      "epoch 2824  loss 42.9576  lr 1.000e-03\n",
      "epoch 2825  loss 44.5530  lr 1.000e-03\n",
      "epoch 2826  loss 43.1097  lr 1.000e-03\n",
      "epoch 2827  loss 44.2684  lr 1.000e-03\n",
      "epoch 2828  loss 43.5514  lr 1.000e-03\n",
      "epoch 2829  loss 44.3189  lr 1.000e-03\n",
      "epoch 2830  loss 43.4504  lr 1.000e-03\n",
      "epoch 2831  loss 43.4872  lr 1.000e-03\n",
      "epoch 2832  loss 44.3123  lr 1.000e-03\n",
      "epoch 2833  loss 44.7220  lr 1.000e-03\n",
      "epoch 2834  loss 42.9580  lr 1.000e-03\n",
      "epoch 2835  loss 42.6503  lr 1.000e-03\n",
      "epoch 2836  loss 43.5008  lr 1.000e-03\n",
      "epoch 2837  loss 45.4122  lr 1.000e-03\n",
      "epoch 2838  loss 43.6620  lr 1.000e-03\n",
      "epoch 2839  loss 43.6938  lr 1.000e-03\n",
      "epoch 2840  loss 43.0004  lr 1.000e-03\n",
      "epoch 2841  loss 43.8586  lr 1.000e-03\n",
      "epoch 2842  loss 43.2866  lr 1.000e-03\n",
      "epoch 2843  loss 43.0768  lr 1.000e-03\n",
      "epoch 2844  loss 46.0450  lr 1.000e-03\n",
      "epoch 2845  loss 44.0277  lr 1.000e-03\n",
      "epoch 2846  loss 41.5621  lr 1.000e-03\n",
      "epoch 2847  loss 43.8567  lr 1.000e-03\n",
      "epoch 2848  loss 42.3107  lr 1.000e-03\n",
      "epoch 2849  loss 42.5934  lr 1.000e-03\n",
      "epoch 2850  loss 43.0254  lr 1.000e-03\n",
      "epoch 2851  loss 43.9572  lr 1.000e-03\n",
      "epoch 2852  loss 45.1060  lr 1.000e-03\n",
      "epoch 2853  loss 44.8888  lr 1.000e-03\n",
      "epoch 2854  loss 43.0577  lr 1.000e-03\n",
      "epoch 2855  loss 44.4977  lr 1.000e-03\n",
      "epoch 2856  loss 43.0416  lr 1.000e-03\n",
      "epoch 2857  loss 41.7283  lr 1.000e-03\n",
      "epoch 2858  loss 44.1503  lr 1.000e-03\n",
      "epoch 2859  loss 43.3958  lr 1.000e-03\n",
      "epoch 2860  loss 42.6741  lr 1.000e-03\n",
      "epoch 2861  loss 44.0608  lr 1.000e-03\n",
      "epoch 2862  loss 45.7425  lr 1.000e-03\n",
      "epoch 2863  loss 45.9983  lr 1.000e-03\n",
      "epoch 2864  loss 43.2365  lr 1.000e-03\n",
      "epoch 2865  loss 42.4497  lr 1.000e-03\n",
      "epoch 2866  loss 45.8340  lr 1.000e-03\n",
      "epoch 2867  loss 42.8916  lr 1.000e-03\n",
      "epoch 2868  loss 44.4659  lr 1.000e-03\n",
      "epoch 2869  loss 42.4990  lr 1.000e-03\n",
      "epoch 2870  loss 43.5925  lr 1.000e-03\n",
      "epoch 2871  loss 43.8936  lr 1.000e-03\n",
      "epoch 2872  loss 43.6847  lr 1.000e-03\n",
      "epoch 2873  loss 43.8278  lr 1.000e-03\n",
      "epoch 2874  loss 43.0409  lr 1.000e-03\n",
      "epoch 2875  loss 41.1436  lr 1.000e-03\n",
      "epoch 2876  loss 43.3745  lr 1.000e-03\n",
      "epoch 2877  loss 45.9234  lr 1.000e-03\n",
      "epoch 2878  loss 43.5963  lr 1.000e-03\n",
      "epoch 2879  loss 43.6021  lr 1.000e-03\n",
      "epoch 2880  loss 43.5743  lr 1.000e-03\n",
      "epoch 2881  loss 45.2292  lr 1.000e-03\n",
      "epoch 2882  loss 44.3231  lr 1.000e-03\n",
      "epoch 2883  loss 43.7572  lr 1.000e-03\n",
      "epoch 2884  loss 44.0280  lr 1.000e-03\n",
      "epoch 2885  loss 44.3934  lr 1.000e-03\n",
      "epoch 2886  loss 44.0544  lr 1.000e-03\n",
      "epoch 2887  loss 44.0960  lr 1.000e-03\n",
      "epoch 2888  loss 41.9261  lr 1.000e-03\n",
      "epoch 2889  loss 44.3978  lr 1.000e-03\n",
      "epoch 2890  loss 43.6056  lr 1.000e-03\n",
      "epoch 2891  loss 43.8593  lr 1.000e-03\n",
      "epoch 2892  loss 42.5470  lr 1.000e-03\n",
      "epoch 2893  loss 44.0516  lr 1.000e-03\n",
      "epoch 2894  loss 43.3521  lr 1.000e-03\n",
      "epoch 2895  loss 44.9105  lr 1.000e-03\n",
      "epoch 2896  loss 43.8800  lr 1.000e-03\n",
      "epoch 2897  loss 43.8767  lr 1.000e-03\n",
      "epoch 2898  loss 43.1749  lr 1.000e-03\n",
      "epoch 2899  loss 43.9464  lr 1.000e-03\n",
      "epoch 2900  loss 42.7008  lr 1.000e-03\n",
      "epoch 2901  loss 43.5838  lr 1.000e-03\n",
      "epoch 2902  loss 44.3162  lr 1.000e-03\n",
      "epoch 2903  loss 44.5113  lr 1.000e-03\n",
      "epoch 2904  loss 45.0267  lr 1.000e-03\n",
      "epoch 2905  loss 43.7930  lr 1.000e-03\n",
      "epoch 2906  loss 42.7589  lr 1.000e-03\n",
      "epoch 2907  loss 42.8022  lr 1.000e-03\n",
      "epoch 2908  loss 44.5727  lr 1.000e-03\n",
      "epoch 2909  loss 43.8554  lr 1.000e-03\n",
      "epoch 2910  loss 44.5571  lr 1.000e-03\n",
      "epoch 2911  loss 44.6139  lr 1.000e-03\n",
      "epoch 2912  loss 42.6564  lr 1.000e-03\n",
      "epoch 2913  loss 44.1154  lr 1.000e-03\n",
      "epoch 2914  loss 43.5096  lr 1.000e-03\n",
      "epoch 2915  loss 42.6518  lr 1.000e-03\n",
      "epoch 2916  loss 43.8850  lr 1.000e-03\n",
      "epoch 2917  loss 43.3861  lr 1.000e-03\n",
      "epoch 2918  loss 45.0368  lr 1.000e-03\n",
      "epoch 2919  loss 42.3373  lr 1.000e-03\n",
      "epoch 2920  loss 42.1974  lr 1.000e-03\n",
      "epoch 2921  loss 43.9342  lr 1.000e-03\n",
      "epoch 2922  loss 44.0701  lr 1.000e-03\n",
      "epoch 2923  loss 44.4878  lr 1.000e-03\n",
      "epoch 2924  loss 44.1726  lr 1.000e-03\n",
      "epoch 2925  loss 42.3341  lr 1.000e-03\n",
      "epoch 2926  loss 41.6716  lr 1.000e-03\n",
      "epoch 2927  loss 42.8299  lr 1.000e-03\n",
      "epoch 2928  loss 43.0253  lr 1.000e-03\n",
      "epoch 2929  loss 42.7120  lr 1.000e-03\n",
      "epoch 2930  loss 43.2159  lr 1.000e-03\n",
      "epoch 2931  loss 42.3432  lr 1.000e-03\n",
      "epoch 2932  loss 44.6756  lr 1.000e-03\n",
      "epoch 2933  loss 44.2098  lr 1.000e-03\n",
      "epoch 2934  loss 44.7379  lr 1.000e-03\n",
      "epoch 2935  loss 41.9469  lr 1.000e-03\n",
      "epoch 2936  loss 43.5821  lr 1.000e-03\n",
      "epoch 2937  loss 43.6709  lr 1.000e-03\n",
      "epoch 2938  loss 43.5905  lr 1.000e-03\n",
      "epoch 2939  loss 44.2041  lr 1.000e-03\n",
      "epoch 2940  loss 44.2838  lr 1.000e-03\n",
      "epoch 2941  loss 43.6945  lr 1.000e-03\n",
      "epoch 2942  loss 45.0014  lr 1.000e-03\n",
      "epoch 2943  loss 43.8683  lr 1.000e-03\n",
      "epoch 2944  loss 43.9450  lr 1.000e-03\n",
      "epoch 2945  loss 41.5368  lr 1.000e-03\n",
      "epoch 2946  loss 42.0394  lr 1.000e-03\n",
      "epoch 2947  loss 43.9278  lr 1.000e-03\n",
      "epoch 2948  loss 44.1593  lr 1.000e-03\n",
      "epoch 2949  loss 42.5599  lr 1.000e-03\n",
      "epoch 2950  loss 43.4706  lr 1.000e-03\n",
      "epoch 2951  loss 43.3627  lr 1.000e-03\n",
      "epoch 2952  loss 42.8792  lr 1.000e-03\n",
      "epoch 2953  loss 45.6316  lr 1.000e-03\n",
      "epoch 2954  loss 45.1937  lr 1.000e-03\n",
      "epoch 2955  loss 44.1901  lr 1.000e-03\n",
      "epoch 2956  loss 43.5053  lr 1.000e-03\n",
      "epoch 2957  loss 45.8908  lr 1.000e-03\n",
      "epoch 2958  loss 42.8750  lr 1.000e-03\n",
      "epoch 2959  loss 44.8266  lr 1.000e-03\n",
      "epoch 2960  loss 45.1283  lr 1.000e-03\n",
      "epoch 2961  loss 42.7345  lr 1.000e-03\n",
      "epoch 2962  loss 43.9611  lr 1.000e-03\n",
      "epoch 2963  loss 43.3944  lr 1.000e-03\n",
      "epoch 2964  loss 44.9411  lr 1.000e-03\n",
      "epoch 2965  loss 43.1592  lr 1.000e-03\n",
      "epoch 2966  loss 44.6018  lr 1.000e-03\n",
      "epoch 2967  loss 43.5072  lr 1.000e-03\n",
      "epoch 2968  loss 42.1929  lr 1.000e-03\n",
      "epoch 2969  loss 43.1439  lr 1.000e-03\n",
      "epoch 2970  loss 44.8155  lr 1.000e-03\n",
      "epoch 2971  loss 43.9883  lr 1.000e-03\n",
      "epoch 2972  loss 44.2754  lr 1.000e-03\n",
      "epoch 2973  loss 44.6302  lr 1.000e-03\n",
      "epoch 2974  loss 46.4885  lr 1.000e-03\n",
      "epoch 2975  loss 46.2685  lr 1.000e-03\n",
      "epoch 2976  loss 44.0659  lr 1.000e-03\n",
      "epoch 2977  loss 42.9010  lr 1.000e-03\n",
      "epoch 2978  loss 42.1919  lr 1.000e-03\n",
      "epoch 2979  loss 44.6232  lr 1.000e-03\n",
      "epoch 2980  loss 43.5306  lr 1.000e-03\n",
      "epoch 2981  loss 42.3215  lr 1.000e-03\n",
      "epoch 2982  loss 43.8262  lr 1.000e-03\n",
      "epoch 2983  loss 43.0238  lr 1.000e-03\n",
      "epoch 2984  loss 43.2544  lr 1.000e-03\n",
      "epoch 2985  loss 42.9480  lr 1.000e-03\n",
      "epoch 2986  loss 41.8517  lr 1.000e-03\n",
      "epoch 2987  loss 42.9073  lr 1.000e-03\n",
      "epoch 2988  loss 43.4176  lr 1.000e-03\n",
      "epoch 2989  loss 42.1828  lr 1.000e-03\n",
      "epoch 2990  loss 43.8322  lr 1.000e-03\n",
      "epoch 2991  loss 42.9897  lr 1.000e-03\n",
      "epoch 2992  loss 43.5328  lr 1.000e-03\n",
      "epoch 2993  loss 41.7495  lr 1.000e-03\n",
      "epoch 2994  loss 43.1602  lr 1.000e-03\n",
      "epoch 2995  loss 42.7735  lr 1.000e-03\n",
      "epoch 2996  loss 43.0648  lr 1.000e-03\n",
      "epoch 2997  loss 42.5046  lr 1.000e-03\n",
      "epoch 2998  loss 43.8554  lr 1.000e-03\n",
      "epoch 2999  loss 42.6108  lr 1.000e-03\n",
      "epoch 3000  loss 43.0469  lr 1.000e-03\n",
      "epoch 3001  loss 43.9471  lr 1.000e-03\n",
      "epoch 3002  loss 42.4208  lr 1.000e-03\n",
      "epoch 3003  loss 41.6113  lr 1.000e-03\n",
      "epoch 3004  loss 42.6701  lr 1.000e-03\n",
      "epoch 3005  loss 44.6528  lr 1.000e-03\n",
      "epoch 3006  loss 43.9773  lr 1.000e-03\n",
      "epoch 3007  loss 42.7856  lr 1.000e-03\n",
      "epoch 3008  loss 43.1932  lr 1.000e-03\n",
      "epoch 3009  loss 41.5945  lr 1.000e-03\n",
      "epoch 3010  loss 42.9590  lr 1.000e-03\n",
      "epoch 3011  loss 45.0144  lr 1.000e-03\n",
      "epoch 3012  loss 43.6661  lr 1.000e-03\n",
      "epoch 3013  loss 43.2336  lr 1.000e-03\n",
      "epoch 3014  loss 44.2844  lr 1.000e-03\n",
      "epoch 3015  loss 44.3173  lr 1.000e-03\n",
      "epoch 3016  loss 43.4332  lr 1.000e-03\n",
      "epoch 3017  loss 42.1769  lr 1.000e-03\n",
      "epoch 3018  loss 44.7811  lr 1.000e-03\n",
      "epoch 3019  loss 43.2622  lr 1.000e-03\n",
      "epoch 3020  loss 42.2271  lr 1.000e-03\n",
      "epoch 3021  loss 45.2566  lr 1.000e-03\n",
      "epoch 3022  loss 43.5532  lr 1.000e-03\n",
      "epoch 3023  loss 42.2178  lr 1.000e-03\n",
      "epoch 3024  loss 41.6484  lr 1.000e-03\n",
      "epoch 3025  loss 44.4406  lr 1.000e-03\n",
      "epoch 3026  loss 43.4289  lr 1.000e-03\n",
      "epoch 3027  loss 43.9269  lr 1.000e-03\n",
      "epoch 3028  loss 44.5945  lr 1.000e-03\n",
      "epoch 3029  loss 41.2654  lr 1.000e-03\n",
      "epoch 3030  loss 45.3866  lr 1.000e-03\n",
      "epoch 3031  loss 43.4434  lr 1.000e-03\n",
      "epoch 3032  loss 43.1128  lr 1.000e-03\n",
      "epoch 3033  loss 44.7835  lr 1.000e-03\n",
      "epoch 3034  loss 43.0123  lr 1.000e-03\n",
      "epoch 3035  loss 44.3034  lr 1.000e-03\n",
      "epoch 3036  loss 45.1241  lr 1.000e-03\n",
      "epoch 3037  loss 44.6903  lr 1.000e-03\n",
      "epoch 3038  loss 44.0260  lr 1.000e-03\n",
      "epoch 3039  loss 42.6802  lr 1.000e-03\n",
      "epoch 3040  loss 43.8227  lr 1.000e-03\n",
      "epoch 3041  loss 43.4173  lr 1.000e-03\n",
      "epoch 3042  loss 43.7097  lr 1.000e-03\n",
      "epoch 3043  loss 42.8324  lr 1.000e-03\n",
      "epoch 3044  loss 44.1399  lr 1.000e-03\n",
      "epoch 3045  loss 43.4075  lr 1.000e-03\n",
      "epoch 3046  loss 43.0049  lr 1.000e-03\n",
      "epoch 3047  loss 43.9469  lr 1.000e-03\n",
      "epoch 3048  loss 42.9731  lr 1.000e-03\n",
      "epoch 3049  loss 43.8459  lr 1.000e-03\n",
      "epoch 3050  loss 44.3662  lr 1.000e-03\n",
      "epoch 3051  loss 44.5426  lr 1.000e-03\n",
      "epoch 3052  loss 43.5999  lr 1.000e-03\n",
      "epoch 3053  loss 41.9029  lr 1.000e-03\n",
      "epoch 3054  loss 44.6545  lr 1.000e-03\n",
      "epoch 3055  loss 43.2736  lr 1.000e-03\n",
      "epoch 3056  loss 42.1134  lr 1.000e-03\n",
      "epoch 3057  loss 43.8083  lr 1.000e-03\n",
      "epoch 3058  loss 43.8025  lr 1.000e-03\n",
      "epoch 3059  loss 43.5982  lr 1.000e-03\n",
      "epoch 3060  loss 43.1019  lr 1.000e-03\n",
      "epoch 3061  loss 44.1743  lr 1.000e-03\n",
      "epoch 3062  loss 43.1078  lr 1.000e-03\n",
      "epoch 3063  loss 44.7295  lr 1.000e-03\n",
      "epoch 3064  loss 42.2232  lr 1.000e-03\n",
      "epoch 3065  loss 44.2685  lr 1.000e-03\n",
      "epoch 3066  loss 41.7908  lr 1.000e-03\n",
      "epoch 3067  loss 43.8213  lr 1.000e-03\n",
      "epoch 3068  loss 44.5730  lr 1.000e-03\n",
      "epoch 3069  loss 42.3526  lr 1.000e-03\n",
      "epoch 3070  loss 44.3865  lr 1.000e-03\n",
      "epoch 3071  loss 43.0892  lr 1.000e-03\n",
      "epoch 3072  loss 40.8670  lr 1.000e-03\n",
      "epoch 3073  loss 43.7901  lr 1.000e-03\n",
      "epoch 3074  loss 41.8437  lr 1.000e-03\n",
      "epoch 3075  loss 42.4302  lr 1.000e-03\n",
      "epoch 3076  loss 41.6870  lr 1.000e-03\n",
      "epoch 3077  loss 43.1117  lr 1.000e-03\n",
      "epoch 3078  loss 42.7911  lr 1.000e-03\n",
      "epoch 3079  loss 42.8578  lr 1.000e-03\n",
      "epoch 3080  loss 43.3447  lr 1.000e-03\n",
      "epoch 3081  loss 42.8945  lr 1.000e-03\n",
      "epoch 3082  loss 42.5253  lr 1.000e-03\n",
      "epoch 3083  loss 43.5085  lr 1.000e-03\n",
      "epoch 3084  loss 42.3896  lr 1.000e-03\n",
      "epoch 3085  loss 41.7243  lr 1.000e-03\n",
      "epoch 3086  loss 45.1146  lr 1.000e-03\n",
      "epoch 3087  loss 44.1197  lr 1.000e-03\n",
      "epoch 3088  loss 44.1115  lr 1.000e-03\n",
      "epoch 3089  loss 41.5334  lr 1.000e-03\n",
      "epoch 3090  loss 44.0705  lr 1.000e-03\n",
      "epoch 3091  loss 43.9791  lr 1.000e-03\n",
      "epoch 3092  loss 41.1585  lr 1.000e-03\n",
      "epoch 3093  loss 43.2659  lr 1.000e-03\n",
      "epoch 3094  loss 43.2211  lr 1.000e-03\n",
      "epoch 3095  loss 42.6783  lr 1.000e-03\n",
      "epoch 3096  loss 41.8800  lr 1.000e-03\n",
      "epoch 3097  loss 43.4149  lr 1.000e-03\n",
      "epoch 3098  loss 42.3680  lr 1.000e-03\n",
      "epoch 3099  loss 44.4727  lr 1.000e-03\n",
      "epoch 3100  loss 42.7143  lr 1.000e-03\n",
      "epoch 3101  loss 40.9255  lr 1.000e-03\n",
      "epoch 3102  loss 42.3914  lr 1.000e-03\n",
      "epoch 3103  loss 42.8678  lr 1.000e-03\n",
      "epoch 3104  loss 42.7028  lr 1.000e-03\n",
      "epoch 3105  loss 43.8625  lr 1.000e-03\n",
      "epoch 3106  loss 42.6439  lr 1.000e-03\n",
      "epoch 3107  loss 43.1489  lr 1.000e-03\n",
      "epoch 3108  loss 44.0467  lr 1.000e-03\n",
      "epoch 3109  loss 44.6258  lr 1.000e-03\n",
      "epoch 3110  loss 43.0452  lr 1.000e-03\n",
      "epoch 3111  loss 43.0426  lr 1.000e-03\n",
      "epoch 3112  loss 41.9367  lr 1.000e-03\n",
      "epoch 3113  loss 42.1506  lr 1.000e-03\n",
      "epoch 3114  loss 42.1423  lr 1.000e-03\n",
      "epoch 3115  loss 43.3685  lr 1.000e-03\n",
      "epoch 3116  loss 42.9940  lr 1.000e-03\n",
      "epoch 3117  loss 43.9273  lr 1.000e-03\n",
      "epoch 3118  loss 45.3107  lr 1.000e-03\n",
      "epoch 3119  loss 42.7449  lr 1.000e-03\n",
      "epoch 3120  loss 41.6059  lr 1.000e-03\n",
      "epoch 3121  loss 42.8846  lr 1.000e-03\n",
      "epoch 3122  loss 44.3727  lr 1.000e-03\n",
      "epoch 3123  loss 42.6511  lr 1.000e-03\n",
      "epoch 3124  loss 42.3395  lr 1.000e-03\n",
      "epoch 3125  loss 43.0378  lr 1.000e-03\n",
      "epoch 3126  loss 44.4540  lr 1.000e-03\n",
      "epoch 3127  loss 43.5944  lr 1.000e-03\n",
      "epoch 3128  loss 42.0435  lr 1.000e-03\n",
      "epoch 3129  loss 43.0383  lr 1.000e-03\n",
      "epoch 3130  loss 44.8881  lr 1.000e-03\n",
      "epoch 3131  loss 42.9359  lr 1.000e-03\n",
      "epoch 3132  loss 43.2982  lr 1.000e-03\n",
      "epoch 3133  loss 42.9632  lr 1.000e-03\n",
      "epoch 3134  loss 42.2847  lr 1.000e-03\n",
      "epoch 3135  loss 44.3598  lr 1.000e-03\n",
      "epoch 3136  loss 42.7803  lr 1.000e-03\n",
      "epoch 3137  loss 42.8611  lr 1.000e-03\n",
      "epoch 3138  loss 43.5771  lr 1.000e-03\n",
      "epoch 3139  loss 44.3510  lr 1.000e-03\n",
      "epoch 3140  loss 42.4494  lr 1.000e-03\n",
      "epoch 3141  loss 42.2406  lr 1.000e-03\n",
      "epoch 3142  loss 42.1816  lr 1.000e-03\n",
      "epoch 3143  loss 42.8843  lr 1.000e-03\n",
      "epoch 3144  loss 45.4418  lr 1.000e-03\n",
      "epoch 3145  loss 42.9153  lr 1.000e-03\n",
      "epoch 3146  loss 42.8519  lr 1.000e-03\n",
      "epoch 3147  loss 42.0929  lr 1.000e-03\n",
      "epoch 3148  loss 44.3784  lr 1.000e-03\n",
      "epoch 3149  loss 43.4965  lr 1.000e-03\n",
      "epoch 3150  loss 42.7792  lr 1.000e-03\n",
      "epoch 3151  loss 43.0303  lr 1.000e-03\n",
      "epoch 3152  loss 41.5443  lr 1.000e-03\n",
      "epoch 3153  loss 43.0825  lr 1.000e-03\n",
      "epoch 3154  loss 43.3426  lr 1.000e-03\n",
      "epoch 3155  loss 42.2739  lr 1.000e-03\n",
      "epoch 3156  loss 42.1491  lr 1.000e-03\n",
      "epoch 3157  loss 43.6984  lr 1.000e-03\n",
      "epoch 3158  loss 43.2359  lr 1.000e-03\n",
      "epoch 3159  loss 43.7611  lr 1.000e-03\n",
      "epoch 3160  loss 41.8189  lr 1.000e-03\n",
      "epoch 3161  loss 42.7262  lr 1.000e-03\n",
      "epoch 3162  loss 43.9974  lr 1.000e-03\n",
      "epoch 3163  loss 42.1805  lr 1.000e-03\n",
      "epoch 3164  loss 43.3130  lr 1.000e-03\n",
      "epoch 3165  loss 44.1779  lr 1.000e-03\n",
      "epoch 3166  loss 41.6894  lr 1.000e-03\n",
      "epoch 3167  loss 42.5666  lr 1.000e-03\n",
      "epoch 3168  loss 43.2741  lr 1.000e-03\n",
      "epoch 3169  loss 41.9075  lr 1.000e-03\n",
      "epoch 3170  loss 43.5226  lr 1.000e-03\n",
      "epoch 3171  loss 43.0898  lr 1.000e-03\n",
      "epoch 3172  loss 42.6549  lr 1.000e-03\n",
      "epoch 3173  loss 40.9334  lr 1.000e-03\n",
      "epoch 3174  loss 42.7987  lr 1.000e-03\n",
      "epoch 3175  loss 41.9992  lr 1.000e-03\n",
      "epoch 3176  loss 43.0414  lr 1.000e-03\n",
      "epoch 3177  loss 41.8368  lr 1.000e-03\n",
      "epoch 3178  loss 40.2845  lr 1.000e-03\n",
      "epoch 3179  loss 42.8971  lr 1.000e-03\n",
      "epoch 3180  loss 42.2290  lr 1.000e-03\n",
      "epoch 3181  loss 42.7161  lr 1.000e-03\n",
      "epoch 3182  loss 44.0784  lr 1.000e-03\n",
      "epoch 3183  loss 43.7729  lr 1.000e-03\n",
      "epoch 3184  loss 43.6046  lr 1.000e-03\n",
      "epoch 3185  loss 43.0158  lr 1.000e-03\n",
      "epoch 3186  loss 42.0174  lr 1.000e-03\n",
      "epoch 3187  loss 43.1829  lr 1.000e-03\n",
      "epoch 3188  loss 42.7390  lr 1.000e-03\n",
      "epoch 3189  loss 42.8411  lr 1.000e-03\n",
      "epoch 3190  loss 42.8241  lr 1.000e-03\n",
      "epoch 3191  loss 42.2464  lr 1.000e-03\n",
      "epoch 3192  loss 42.6274  lr 1.000e-03\n",
      "epoch 3193  loss 42.1197  lr 1.000e-03\n",
      "epoch 3194  loss 43.6765  lr 1.000e-03\n",
      "epoch 3195  loss 42.5842  lr 1.000e-03\n",
      "epoch 3196  loss 42.9168  lr 1.000e-03\n",
      "epoch 3197  loss 41.7153  lr 1.000e-03\n",
      "epoch 3198  loss 44.5994  lr 1.000e-03\n",
      "epoch 3199  loss 45.1149  lr 1.000e-03\n",
      "epoch 3200  loss 42.5146  lr 1.000e-03\n",
      "epoch 3201  loss 44.5506  lr 1.000e-03\n",
      "epoch 3202  loss 42.6744  lr 1.000e-03\n",
      "epoch 3203  loss 43.8895  lr 1.000e-03\n",
      "epoch 3204  loss 42.6520  lr 1.000e-03\n",
      "epoch 3205  loss 42.4516  lr 1.000e-03\n",
      "epoch 3206  loss 41.9552  lr 1.000e-03\n",
      "epoch 3207  loss 44.1092  lr 1.000e-03\n",
      "epoch 3208  loss 43.1054  lr 1.000e-03\n",
      "epoch 3209  loss 42.0605  lr 1.000e-03\n",
      "epoch 3210  loss 42.1580  lr 1.000e-03\n",
      "epoch 3211  loss 43.3330  lr 1.000e-03\n",
      "epoch 3212  loss 41.6557  lr 1.000e-03\n",
      "epoch 3213  loss 40.6202  lr 1.000e-03\n",
      "epoch 3214  loss 41.9845  lr 1.000e-03\n",
      "epoch 3215  loss 43.2594  lr 1.000e-03\n",
      "epoch 3216  loss 42.9756  lr 1.000e-03\n",
      "epoch 3217  loss 43.1269  lr 1.000e-03\n",
      "epoch 3218  loss 44.6901  lr 1.000e-03\n",
      "epoch 3219  loss 42.4639  lr 1.000e-03\n",
      "epoch 3220  loss 43.1684  lr 1.000e-03\n",
      "epoch 3221  loss 42.8270  lr 1.000e-03\n",
      "epoch 3222  loss 44.7351  lr 1.000e-03\n",
      "epoch 3223  loss 42.0970  lr 1.000e-03\n",
      "epoch 3224  loss 43.6074  lr 1.000e-03\n",
      "epoch 3225  loss 42.2191  lr 1.000e-03\n",
      "epoch 3226  loss 39.0995  lr 1.000e-03\n",
      "epoch 3227  loss 41.5255  lr 1.000e-03\n",
      "epoch 3228  loss 42.5986  lr 1.000e-03\n",
      "epoch 3229  loss 42.5110  lr 1.000e-03\n",
      "epoch 3230  loss 42.2505  lr 1.000e-03\n",
      "epoch 3231  loss 42.6431  lr 1.000e-03\n",
      "epoch 3232  loss 44.3518  lr 1.000e-03\n",
      "epoch 3233  loss 43.6244  lr 1.000e-03\n",
      "epoch 3234  loss 41.6781  lr 1.000e-03\n",
      "epoch 3235  loss 43.4833  lr 1.000e-03\n",
      "epoch 3236  loss 43.8192  lr 1.000e-03\n",
      "epoch 3237  loss 42.4230  lr 1.000e-03\n",
      "epoch 3238  loss 43.4264  lr 1.000e-03\n",
      "epoch 3239  loss 45.1719  lr 1.000e-03\n",
      "epoch 3240  loss 42.7647  lr 1.000e-03\n",
      "epoch 3241  loss 42.1736  lr 1.000e-03\n",
      "epoch 3242  loss 41.6175  lr 1.000e-03\n",
      "epoch 3243  loss 40.6631  lr 1.000e-03\n",
      "epoch 3244  loss 43.7573  lr 1.000e-03\n",
      "epoch 3245  loss 43.5526  lr 1.000e-03\n",
      "epoch 3246  loss 42.6213  lr 1.000e-03\n",
      "epoch 3247  loss 41.9656  lr 1.000e-03\n",
      "epoch 3248  loss 43.5314  lr 1.000e-03\n",
      "epoch 3249  loss 41.8151  lr 1.000e-03\n",
      "epoch 3250  loss 40.6989  lr 1.000e-03\n",
      "epoch 3251  loss 41.8677  lr 1.000e-03\n",
      "epoch 3252  loss 40.7930  lr 1.000e-03\n",
      "epoch 3253  loss 41.6197  lr 1.000e-03\n",
      "epoch 3254  loss 42.7781  lr 1.000e-03\n",
      "epoch 3255  loss 41.5281  lr 1.000e-03\n",
      "epoch 3256  loss 43.3384  lr 1.000e-03\n",
      "epoch 3257  loss 44.5513  lr 1.000e-03\n",
      "epoch 3258  loss 43.2590  lr 1.000e-03\n",
      "epoch 3259  loss 42.9322  lr 1.000e-03\n",
      "epoch 3260  loss 43.0873  lr 1.000e-03\n",
      "epoch 3261  loss 42.8785  lr 1.000e-03\n",
      "epoch 3262  loss 41.1147  lr 1.000e-03\n",
      "epoch 3263  loss 42.2783  lr 1.000e-03\n",
      "epoch 3264  loss 40.0033  lr 1.000e-03\n",
      "epoch 3265  loss 42.1054  lr 1.000e-03\n",
      "epoch 3266  loss 41.9606  lr 1.000e-03\n",
      "epoch 3267  loss 43.8431  lr 1.000e-03\n",
      "epoch 3268  loss 43.7808  lr 1.000e-03\n",
      "epoch 3269  loss 43.5616  lr 1.000e-03\n",
      "epoch 3270  loss 42.1589  lr 1.000e-03\n",
      "epoch 3271  loss 43.0871  lr 1.000e-03\n",
      "epoch 3272  loss 42.7105  lr 1.000e-03\n",
      "epoch 3273  loss 43.7667  lr 1.000e-03\n",
      "epoch 3274  loss 42.7885  lr 1.000e-03\n",
      "epoch 3275  loss 42.5259  lr 1.000e-03\n",
      "epoch 3276  loss 40.7849  lr 1.000e-03\n",
      "epoch 3277  loss 40.7609  lr 1.000e-03\n",
      "epoch 3278  loss 43.5238  lr 1.000e-03\n",
      "epoch 3279  loss 41.8042  lr 1.000e-03\n",
      "epoch 3280  loss 42.5415  lr 1.000e-03\n",
      "epoch 3281  loss 41.9777  lr 1.000e-03\n",
      "epoch 3282  loss 44.0014  lr 1.000e-03\n",
      "epoch 3283  loss 41.7687  lr 1.000e-03\n",
      "epoch 3284  loss 44.4835  lr 1.000e-03\n",
      "epoch 3285  loss 42.5389  lr 1.000e-03\n",
      "epoch 3286  loss 42.9454  lr 1.000e-03\n",
      "epoch 3287  loss 42.2462  lr 1.000e-03\n",
      "epoch 3288  loss 42.7801  lr 1.000e-03\n",
      "epoch 3289  loss 43.8297  lr 1.000e-03\n",
      "epoch 3290  loss 41.8828  lr 1.000e-03\n",
      "epoch 3291  loss 42.9292  lr 1.000e-03\n",
      "epoch 3292  loss 41.7517  lr 1.000e-03\n",
      "epoch 3293  loss 42.5010  lr 1.000e-03\n",
      "epoch 3294  loss 43.5711  lr 1.000e-03\n",
      "epoch 3295  loss 40.9233  lr 1.000e-03\n",
      "epoch 3296  loss 43.1134  lr 1.000e-03\n",
      "epoch 3297  loss 42.1663  lr 1.000e-03\n",
      "epoch 3298  loss 43.5008  lr 1.000e-03\n",
      "epoch 3299  loss 42.2012  lr 1.000e-03\n",
      "epoch 3300  loss 41.2391  lr 1.000e-03\n",
      "epoch 3301  loss 42.4326  lr 1.000e-03\n",
      "epoch 3302  loss 42.6728  lr 1.000e-03\n",
      "epoch 3303  loss 41.1147  lr 1.000e-03\n",
      "epoch 3304  loss 42.4566  lr 1.000e-03\n",
      "epoch 3305  loss 43.9060  lr 1.000e-03\n",
      "epoch 3306  loss 43.3984  lr 1.000e-03\n",
      "epoch 3307  loss 43.7058  lr 1.000e-03\n",
      "epoch 3308  loss 41.4357  lr 1.000e-03\n",
      "epoch 3309  loss 43.7007  lr 1.000e-03\n",
      "epoch 3310  loss 43.7113  lr 1.000e-03\n",
      "epoch 3311  loss 41.3161  lr 1.000e-03\n",
      "epoch 3312  loss 43.2011  lr 1.000e-03\n",
      "epoch 3313  loss 42.3647  lr 1.000e-03\n",
      "epoch 3314  loss 42.4011  lr 1.000e-03\n",
      "epoch 3315  loss 42.1162  lr 1.000e-03\n",
      "epoch 3316  loss 43.5251  lr 1.000e-03\n",
      "epoch 3317  loss 42.4907  lr 1.000e-03\n",
      "epoch 3318  loss 42.2173  lr 1.000e-03\n",
      "epoch 3319  loss 42.3525  lr 1.000e-03\n",
      "epoch 3320  loss 42.0530  lr 1.000e-03\n",
      "epoch 3321  loss 42.4416  lr 1.000e-03\n",
      "epoch 3322  loss 41.6982  lr 1.000e-03\n",
      "epoch 3323  loss 42.8609  lr 1.000e-03\n",
      "epoch 3324  loss 41.1699  lr 1.000e-03\n",
      "epoch 3325  loss 43.2104  lr 1.000e-03\n",
      "epoch 3326  loss 42.8608  lr 1.000e-03\n",
      "epoch 3327  loss 42.0923  lr 1.000e-03\n",
      "epoch 3328  loss 42.6285  lr 1.000e-03\n",
      "epoch 3329  loss 43.0222  lr 1.000e-03\n",
      "epoch 3330  loss 42.0970  lr 1.000e-03\n",
      "epoch 3331  loss 43.2452  lr 1.000e-03\n",
      "epoch 3332  loss 41.6008  lr 1.000e-03\n",
      "epoch 3333  loss 41.9177  lr 1.000e-03\n",
      "epoch 3334  loss 42.1623  lr 1.000e-03\n",
      "epoch 3335  loss 42.6537  lr 1.000e-03\n",
      "epoch 3336  loss 41.6748  lr 1.000e-03\n",
      "epoch 3337  loss 44.4749  lr 1.000e-03\n",
      "epoch 3338  loss 43.5502  lr 1.000e-03\n",
      "epoch 3339  loss 41.9644  lr 1.000e-03\n",
      "epoch 3340  loss 43.2858  lr 1.000e-03\n",
      "epoch 3341  loss 42.4828  lr 1.000e-03\n",
      "epoch 3342  loss 42.3980  lr 1.000e-03\n",
      "epoch 3343  loss 42.0501  lr 1.000e-03\n",
      "epoch 3344  loss 40.8565  lr 1.000e-03\n",
      "epoch 3345  loss 42.1588  lr 1.000e-03\n",
      "epoch 3346  loss 41.6130  lr 1.000e-03\n",
      "epoch 3347  loss 42.7282  lr 1.000e-03\n",
      "epoch 3348  loss 42.2873  lr 1.000e-03\n",
      "epoch 3349  loss 43.3607  lr 1.000e-03\n",
      "epoch 3350  loss 41.8502  lr 1.000e-03\n",
      "epoch 3351  loss 43.1083  lr 1.000e-03\n",
      "epoch 3352  loss 43.6254  lr 1.000e-03\n",
      "epoch 3353  loss 43.7799  lr 1.000e-03\n",
      "epoch 3354  loss 43.1696  lr 1.000e-03\n",
      "epoch 3355  loss 43.2614  lr 1.000e-03\n",
      "epoch 3356  loss 42.8750  lr 1.000e-03\n",
      "epoch 3357  loss 42.4303  lr 1.000e-03\n",
      "epoch 3358  loss 42.8332  lr 1.000e-03\n",
      "epoch 3359  loss 41.4551  lr 1.000e-03\n",
      "epoch 3360  loss 43.2563  lr 1.000e-03\n",
      "epoch 3361  loss 43.5724  lr 1.000e-03\n",
      "epoch 3362  loss 43.2827  lr 1.000e-03\n",
      "epoch 3363  loss 42.4861  lr 1.000e-03\n",
      "epoch 3364  loss 43.3282  lr 1.000e-03\n",
      "epoch 3365  loss 42.2384  lr 1.000e-03\n",
      "epoch 3366  loss 44.3971  lr 1.000e-03\n",
      "epoch 3367  loss 40.8955  lr 1.000e-03\n",
      "epoch 3368  loss 42.0726  lr 1.000e-03\n",
      "epoch 3369  loss 42.1550  lr 1.000e-03\n",
      "epoch 3370  loss 41.7846  lr 1.000e-03\n",
      "epoch 3371  loss 41.3014  lr 1.000e-03\n",
      "epoch 3372  loss 43.0910  lr 1.000e-03\n",
      "epoch 3373  loss 42.5810  lr 1.000e-03\n",
      "epoch 3374  loss 40.8259  lr 1.000e-03\n",
      "epoch 3375  loss 43.4322  lr 1.000e-03\n",
      "epoch 3376  loss 42.1836  lr 1.000e-03\n",
      "epoch 3377  loss 41.1547  lr 1.000e-03\n",
      "epoch 3378  loss 41.6115  lr 1.000e-03\n",
      "epoch 3379  loss 42.7733  lr 1.000e-03\n",
      "epoch 3380  loss 42.3368  lr 1.000e-03\n",
      "epoch 3381  loss 42.5123  lr 1.000e-03\n",
      "epoch 3382  loss 42.6575  lr 1.000e-03\n",
      "epoch 3383  loss 43.9329  lr 1.000e-03\n",
      "epoch 3384  loss 42.6528  lr 1.000e-03\n",
      "epoch 3385  loss 41.2740  lr 1.000e-03\n",
      "epoch 3386  loss 42.3184  lr 1.000e-03\n",
      "epoch 3387  loss 43.2467  lr 1.000e-03\n",
      "epoch 3388  loss 41.5365  lr 1.000e-03\n",
      "epoch 3389  loss 44.5051  lr 1.000e-03\n",
      "epoch 3390  loss 42.5090  lr 1.000e-03\n",
      "epoch 3391  loss 42.7958  lr 1.000e-03\n",
      "epoch 3392  loss 42.6888  lr 1.000e-03\n",
      "epoch 3393  loss 41.9328  lr 1.000e-03\n",
      "epoch 3394  loss 41.5202  lr 1.000e-03\n",
      "epoch 3395  loss 43.5108  lr 1.000e-03\n",
      "epoch 3396  loss 43.1989  lr 1.000e-03\n",
      "epoch 3397  loss 41.6573  lr 1.000e-03\n",
      "epoch 3398  loss 43.4350  lr 1.000e-03\n",
      "epoch 3399  loss 41.2076  lr 1.000e-03\n",
      "epoch 3400  loss 41.5920  lr 1.000e-03\n",
      "epoch 3401  loss 42.5300  lr 1.000e-03\n",
      "epoch 3402  loss 43.9040  lr 1.000e-03\n",
      "epoch 3403  loss 40.4832  lr 1.000e-03\n",
      "epoch 3404  loss 42.1739  lr 1.000e-03\n",
      "epoch 3405  loss 41.6787  lr 1.000e-03\n",
      "epoch 3406  loss 42.0256  lr 1.000e-03\n",
      "epoch 3407  loss 42.6910  lr 1.000e-03\n",
      "epoch 3408  loss 41.8384  lr 1.000e-03\n",
      "epoch 3409  loss 42.7240  lr 1.000e-03\n",
      "epoch 3410  loss 41.0761  lr 1.000e-03\n",
      "epoch 3411  loss 43.1493  lr 1.000e-03\n",
      "epoch 3412  loss 42.5709  lr 1.000e-03\n",
      "epoch 3413  loss 41.4076  lr 1.000e-03\n",
      "epoch 3414  loss 43.2758  lr 1.000e-03\n",
      "epoch 3415  loss 42.1307  lr 1.000e-03\n",
      "epoch 3416  loss 42.7712  lr 1.000e-03\n",
      "epoch 3417  loss 42.0690  lr 1.000e-03\n",
      "epoch 3418  loss 41.3753  lr 1.000e-03\n",
      "epoch 3419  loss 39.7719  lr 1.000e-03\n",
      "epoch 3420  loss 42.9221  lr 1.000e-03\n",
      "epoch 3421  loss 41.1631  lr 1.000e-03\n",
      "epoch 3422  loss 42.6903  lr 1.000e-03\n",
      "epoch 3423  loss 42.3947  lr 1.000e-03\n",
      "epoch 3424  loss 42.1090  lr 1.000e-03\n",
      "epoch 3425  loss 41.6135  lr 1.000e-03\n",
      "epoch 3426  loss 41.2378  lr 1.000e-03\n",
      "epoch 3427  loss 42.9999  lr 1.000e-03\n",
      "epoch 3428  loss 42.2119  lr 1.000e-03\n",
      "epoch 3429  loss 41.2297  lr 1.000e-03\n",
      "epoch 3430  loss 42.6232  lr 1.000e-03\n",
      "epoch 3431  loss 41.7041  lr 1.000e-03\n",
      "epoch 3432  loss 41.5977  lr 1.000e-03\n",
      "epoch 3433  loss 42.8604  lr 1.000e-03\n",
      "epoch 3434  loss 42.5990  lr 1.000e-03\n",
      "epoch 3435  loss 43.8649  lr 1.000e-03\n",
      "epoch 3436  loss 42.4410  lr 1.000e-03\n",
      "epoch 3437  loss 43.7195  lr 1.000e-03\n",
      "epoch 3438  loss 42.6744  lr 1.000e-03\n",
      "epoch 3439  loss 42.8431  lr 1.000e-03\n",
      "epoch 3440  loss 42.1397  lr 1.000e-03\n",
      "epoch 3441  loss 41.3661  lr 1.000e-03\n",
      "epoch 3442  loss 40.6933  lr 1.000e-03\n",
      "epoch 3443  loss 42.5360  lr 1.000e-03\n",
      "epoch 3444  loss 42.1800  lr 1.000e-03\n",
      "epoch 3445  loss 43.0374  lr 1.000e-03\n",
      "epoch 3446  loss 42.6398  lr 1.000e-03\n",
      "epoch 3447  loss 43.1667  lr 1.000e-03\n",
      "epoch 3448  loss 42.3810  lr 1.000e-03\n",
      "epoch 3449  loss 42.6950  lr 1.000e-03\n",
      "epoch 3450  loss 42.8571  lr 1.000e-03\n",
      "epoch 3451  loss 42.9914  lr 1.000e-03\n",
      "epoch 3452  loss 43.1828  lr 1.000e-03\n",
      "epoch 3453  loss 41.4916  lr 1.000e-03\n",
      "epoch 3454  loss 42.5590  lr 1.000e-03\n",
      "epoch 3455  loss 41.6400  lr 1.000e-03\n",
      "epoch 3456  loss 43.1859  lr 1.000e-03\n",
      "epoch 3457  loss 42.9841  lr 1.000e-03\n",
      "epoch 3458  loss 41.7400  lr 1.000e-03\n",
      "epoch 3459  loss 41.0244  lr 1.000e-03\n",
      "epoch 3460  loss 43.3022  lr 1.000e-03\n",
      "epoch 3461  loss 42.1568  lr 1.000e-03\n",
      "epoch 3462  loss 42.2532  lr 1.000e-03\n",
      "epoch 3463  loss 43.2063  lr 1.000e-03\n",
      "epoch 3464  loss 41.9257  lr 1.000e-03\n",
      "epoch 3465  loss 42.9446  lr 1.000e-03\n",
      "epoch 3466  loss 41.9312  lr 1.000e-03\n",
      "epoch 3467  loss 41.1697  lr 1.000e-03\n",
      "epoch 3468  loss 42.7367  lr 1.000e-03\n",
      "epoch 3469  loss 41.4722  lr 1.000e-03\n",
      "epoch 3470  loss 41.5673  lr 1.000e-03\n",
      "epoch 3471  loss 40.9203  lr 1.000e-03\n",
      "epoch 3472  loss 41.3584  lr 1.000e-03\n",
      "epoch 3473  loss 42.0076  lr 1.000e-03\n",
      "epoch 3474  loss 42.9706  lr 1.000e-03\n",
      "epoch 3475  loss 41.8308  lr 1.000e-03\n",
      "epoch 3476  loss 42.2237  lr 1.000e-03\n",
      "epoch 3477  loss 41.2445  lr 1.000e-03\n",
      "epoch 3478  loss 41.6489  lr 1.000e-03\n",
      "epoch 3479  loss 42.1498  lr 1.000e-03\n",
      "epoch 3480  loss 42.2838  lr 1.000e-03\n",
      "epoch 3481  loss 42.5850  lr 1.000e-03\n",
      "epoch 3482  loss 41.4185  lr 1.000e-03\n",
      "epoch 3483  loss 42.6576  lr 1.000e-03\n",
      "epoch 3484  loss 41.4906  lr 1.000e-03\n",
      "epoch 3485  loss 42.7930  lr 1.000e-03\n",
      "epoch 3486  loss 43.0147  lr 1.000e-03\n",
      "epoch 3487  loss 41.9990  lr 1.000e-03\n",
      "epoch 3488  loss 42.7946  lr 1.000e-03\n",
      "epoch 3489  loss 42.3088  lr 1.000e-03\n",
      "epoch 3490  loss 40.5367  lr 1.000e-03\n",
      "epoch 3491  loss 41.6022  lr 1.000e-03\n",
      "epoch 3492  loss 40.8906  lr 1.000e-03\n",
      "epoch 3493  loss 43.1142  lr 1.000e-03\n",
      "epoch 3494  loss 41.4974  lr 1.000e-03\n",
      "epoch 3495  loss 41.0871  lr 1.000e-03\n",
      "epoch 3496  loss 41.6819  lr 1.000e-03\n",
      "epoch 3497  loss 41.6519  lr 1.000e-03\n",
      "epoch 3498  loss 42.0119  lr 1.000e-03\n",
      "epoch 3499  loss 40.8177  lr 1.000e-03\n",
      "epoch 3500  loss 42.2690  lr 1.000e-03\n",
      "epoch 3501  loss 43.2882  lr 1.000e-03\n",
      "epoch 3502  loss 43.0666  lr 1.000e-03\n",
      "epoch 3503  loss 42.6276  lr 1.000e-03\n",
      "epoch 3504  loss 39.9094  lr 1.000e-03\n",
      "epoch 3505  loss 42.3152  lr 1.000e-03\n",
      "epoch 3506  loss 41.9845  lr 1.000e-03\n",
      "epoch 3507  loss 41.4213  lr 1.000e-03\n",
      "epoch 3508  loss 42.9987  lr 1.000e-03\n",
      "epoch 3509  loss 43.1034  lr 1.000e-03\n",
      "epoch 3510  loss 42.7846  lr 1.000e-03\n",
      "epoch 3511  loss 42.1595  lr 1.000e-03\n",
      "epoch 3512  loss 41.3571  lr 1.000e-03\n",
      "epoch 3513  loss 40.5640  lr 1.000e-03\n",
      "epoch 3514  loss 41.2068  lr 1.000e-03\n",
      "epoch 3515  loss 42.7168  lr 1.000e-03\n",
      "epoch 3516  loss 42.4667  lr 1.000e-03\n",
      "epoch 3517  loss 41.4990  lr 1.000e-03\n",
      "epoch 3518  loss 41.8774  lr 1.000e-03\n",
      "epoch 3519  loss 42.0986  lr 1.000e-03\n",
      "epoch 3520  loss 43.6392  lr 1.000e-03\n",
      "epoch 3521  loss 42.0270  lr 1.000e-03\n",
      "epoch 3522  loss 41.9396  lr 1.000e-03\n",
      "epoch 3523  loss 42.5077  lr 1.000e-03\n",
      "epoch 3524  loss 42.8173  lr 1.000e-03\n",
      "epoch 3525  loss 41.4584  lr 1.000e-03\n",
      "epoch 3526  loss 42.8708  lr 1.000e-03\n",
      "epoch 3527  loss 43.4111  lr 1.000e-03\n",
      "epoch 3528  loss 41.0424  lr 1.000e-03\n",
      "epoch 3529  loss 43.1382  lr 1.000e-03\n",
      "epoch 3530  loss 40.7104  lr 1.000e-03\n",
      "epoch 3531  loss 42.1669  lr 1.000e-03\n",
      "epoch 3532  loss 42.3524  lr 1.000e-03\n",
      "epoch 3533  loss 42.6481  lr 1.000e-03\n",
      "epoch 3534  loss 40.6983  lr 1.000e-03\n",
      "epoch 3535  loss 40.7754  lr 1.000e-03\n",
      "epoch 3536  loss 42.4542  lr 1.000e-03\n",
      "epoch 3537  loss 42.4784  lr 1.000e-03\n",
      "epoch 3538  loss 41.6827  lr 1.000e-03\n",
      "epoch 3539  loss 43.6904  lr 1.000e-03\n",
      "epoch 3540  loss 41.2981  lr 1.000e-03\n",
      "epoch 3541  loss 42.8590  lr 1.000e-03\n",
      "epoch 3542  loss 42.0121  lr 1.000e-03\n",
      "epoch 3543  loss 42.1195  lr 1.000e-03\n",
      "epoch 3544  loss 41.8759  lr 1.000e-03\n",
      "epoch 3545  loss 43.0791  lr 1.000e-03\n",
      "epoch 3546  loss 43.5933  lr 1.000e-03\n",
      "epoch 3547  loss 41.9440  lr 1.000e-03\n",
      "epoch 3548  loss 42.0810  lr 1.000e-03\n",
      "epoch 3549  loss 42.5522  lr 1.000e-03\n",
      "epoch 3550  loss 41.8275  lr 1.000e-03\n",
      "epoch 3551  loss 42.4351  lr 1.000e-03\n",
      "epoch 3552  loss 43.7353  lr 1.000e-03\n",
      "epoch 3553  loss 42.4543  lr 1.000e-03\n",
      "epoch 3554  loss 42.3229  lr 1.000e-03\n",
      "epoch 3555  loss 41.0673  lr 1.000e-03\n",
      "epoch 3556  loss 41.5771  lr 1.000e-03\n",
      "epoch 3557  loss 42.8769  lr 1.000e-03\n",
      "epoch 3558  loss 41.2218  lr 1.000e-03\n",
      "epoch 3559  loss 42.5443  lr 1.000e-03\n",
      "epoch 3560  loss 41.9945  lr 1.000e-03\n",
      "epoch 3561  loss 41.4582  lr 1.000e-03\n",
      "epoch 3562  loss 43.5789  lr 1.000e-03\n",
      "epoch 3563  loss 40.5107  lr 1.000e-03\n",
      "epoch 3564  loss 40.9915  lr 1.000e-03\n",
      "epoch 3565  loss 39.7184  lr 1.000e-03\n",
      "epoch 3566  loss 40.4069  lr 1.000e-03\n",
      "epoch 3567  loss 41.3207  lr 1.000e-03\n",
      "epoch 3568  loss 40.9056  lr 1.000e-03\n",
      "epoch 3569  loss 40.7290  lr 1.000e-03\n",
      "epoch 3570  loss 42.9496  lr 1.000e-03\n",
      "epoch 3571  loss 40.8990  lr 1.000e-03\n",
      "epoch 3572  loss 43.9574  lr 1.000e-03\n",
      "epoch 3573  loss 41.5138  lr 1.000e-03\n",
      "epoch 3574  loss 43.2800  lr 1.000e-03\n",
      "epoch 3575  loss 42.2929  lr 1.000e-03\n",
      "epoch 3576  loss 44.5198  lr 1.000e-03\n",
      "epoch 3577  loss 40.3540  lr 1.000e-03\n",
      "epoch 3578  loss 42.0720  lr 1.000e-03\n",
      "epoch 3579  loss 41.7924  lr 1.000e-03\n",
      "epoch 3580  loss 42.7534  lr 1.000e-03\n",
      "epoch 3581  loss 42.0362  lr 1.000e-03\n",
      "epoch 3582  loss 42.3246  lr 1.000e-03\n",
      "epoch 3583  loss 41.2693  lr 1.000e-03\n",
      "epoch 3584  loss 42.2427  lr 1.000e-03\n",
      "epoch 3585  loss 41.3566  lr 1.000e-03\n",
      "epoch 3586  loss 39.7892  lr 1.000e-03\n",
      "epoch 3587  loss 41.7063  lr 1.000e-03\n",
      "epoch 3588  loss 42.1565  lr 1.000e-03\n",
      "epoch 3589  loss 41.1423  lr 1.000e-03\n",
      "epoch 3590  loss 42.8595  lr 1.000e-03\n",
      "epoch 3591  loss 43.0605  lr 1.000e-03\n",
      "epoch 3592  loss 41.7399  lr 1.000e-03\n",
      "epoch 3593  loss 42.2726  lr 1.000e-03\n",
      "epoch 3594  loss 41.3424  lr 1.000e-03\n",
      "epoch 3595  loss 42.8346  lr 1.000e-03\n",
      "epoch 3596  loss 40.8573  lr 1.000e-03\n",
      "epoch 3597  loss 41.1804  lr 1.000e-03\n",
      "epoch 3598  loss 42.1351  lr 1.000e-03\n",
      "epoch 3599  loss 42.4850  lr 1.000e-03\n",
      "epoch 3600  loss 42.7030  lr 1.000e-03\n",
      "epoch 3601  loss 42.7111  lr 1.000e-03\n",
      "epoch 3602  loss 43.0596  lr 1.000e-03\n",
      "epoch 3603  loss 42.6435  lr 1.000e-03\n",
      "epoch 3604  loss 41.3478  lr 1.000e-03\n",
      "epoch 3605  loss 40.5783  lr 1.000e-03\n",
      "epoch 3606  loss 40.3837  lr 1.000e-03\n",
      "epoch 3607  loss 40.2959  lr 1.000e-03\n",
      "epoch 3608  loss 42.8813  lr 1.000e-03\n",
      "epoch 3609  loss 41.4421  lr 1.000e-03\n",
      "epoch 3610  loss 41.3859  lr 1.000e-03\n",
      "epoch 3611  loss 42.2931  lr 1.000e-03\n",
      "epoch 3612  loss 41.4337  lr 1.000e-03\n",
      "epoch 3613  loss 42.1796  lr 1.000e-03\n",
      "epoch 3614  loss 42.1229  lr 1.000e-03\n",
      "epoch 3615  loss 42.7223  lr 1.000e-03\n",
      "epoch 3616  loss 42.6622  lr 1.000e-03\n",
      "epoch 3617  loss 41.5665  lr 1.000e-03\n",
      "epoch 3618  loss 44.0666  lr 1.000e-03\n",
      "epoch 3619  loss 42.3149  lr 1.000e-03\n",
      "epoch 3620  loss 42.7194  lr 1.000e-03\n",
      "epoch 3621  loss 42.0528  lr 1.000e-03\n",
      "epoch 3622  loss 42.3695  lr 1.000e-03\n",
      "epoch 3623  loss 42.6336  lr 1.000e-03\n",
      "epoch 3624  loss 41.6855  lr 1.000e-03\n",
      "epoch 3625  loss 40.4148  lr 1.000e-03\n",
      "epoch 3626  loss 41.7860  lr 1.000e-03\n",
      "epoch 3627  loss 41.6742  lr 1.000e-03\n",
      "epoch 3628  loss 41.1627  lr 1.000e-03\n",
      "epoch 3629  loss 42.6215  lr 1.000e-03\n",
      "epoch 3630  loss 41.2572  lr 1.000e-03\n",
      "epoch 3631  loss 39.6475  lr 1.000e-03\n",
      "epoch 3632  loss 41.3351  lr 1.000e-03\n",
      "epoch 3633  loss 40.9791  lr 1.000e-03\n",
      "epoch 3634  loss 40.7926  lr 1.000e-03\n",
      "epoch 3635  loss 42.5623  lr 1.000e-03\n",
      "epoch 3636  loss 43.4491  lr 1.000e-03\n",
      "epoch 3637  loss 41.9668  lr 1.000e-03\n",
      "epoch 3638  loss 41.4144  lr 1.000e-03\n",
      "epoch 3639  loss 40.6249  lr 1.000e-03\n",
      "epoch 3640  loss 40.5030  lr 1.000e-03\n",
      "epoch 3641  loss 42.1606  lr 1.000e-03\n",
      "epoch 3642  loss 41.9317  lr 1.000e-03\n",
      "epoch 3643  loss 41.9015  lr 1.000e-03\n",
      "epoch 3644  loss 41.9213  lr 1.000e-03\n",
      "epoch 3645  loss 41.5821  lr 1.000e-03\n",
      "epoch 3646  loss 41.3635  lr 1.000e-03\n",
      "epoch 3647  loss 40.5770  lr 1.000e-03\n",
      "epoch 3648  loss 42.1558  lr 1.000e-03\n",
      "epoch 3649  loss 40.9672  lr 1.000e-03\n",
      "epoch 3650  loss 40.7292  lr 1.000e-03\n",
      "epoch 3651  loss 41.3530  lr 1.000e-03\n",
      "epoch 3652  loss 42.4592  lr 1.000e-03\n",
      "epoch 3653  loss 41.9238  lr 1.000e-03\n",
      "epoch 3654  loss 42.4077  lr 1.000e-03\n",
      "epoch 3655  loss 41.3214  lr 1.000e-03\n",
      "epoch 3656  loss 40.1866  lr 1.000e-03\n",
      "epoch 3657  loss 42.2471  lr 1.000e-03\n",
      "epoch 3658  loss 44.4190  lr 1.000e-03\n",
      "epoch 3659  loss 42.6904  lr 1.000e-03\n",
      "epoch 3660  loss 41.7235  lr 1.000e-03\n",
      "epoch 3661  loss 40.8964  lr 1.000e-03\n",
      "epoch 3662  loss 41.7883  lr 1.000e-03\n",
      "epoch 3663  loss 41.8046  lr 1.000e-03\n",
      "epoch 3664  loss 41.3276  lr 1.000e-03\n",
      "epoch 3665  loss 41.0538  lr 1.000e-03\n",
      "epoch 3666  loss 41.9172  lr 1.000e-03\n",
      "epoch 3667  loss 41.6198  lr 1.000e-03\n",
      "epoch 3668  loss 41.5536  lr 1.000e-03\n",
      "epoch 3669  loss 41.9807  lr 1.000e-03\n",
      "epoch 3670  loss 41.1740  lr 1.000e-03\n",
      "epoch 3671  loss 41.9332  lr 1.000e-03\n",
      "epoch 3672  loss 42.1468  lr 1.000e-03\n",
      "epoch 3673  loss 41.7785  lr 1.000e-03\n",
      "epoch 3674  loss 41.3713  lr 1.000e-03\n",
      "epoch 3675  loss 39.8124  lr 1.000e-03\n",
      "epoch 3676  loss 40.9936  lr 1.000e-03\n",
      "epoch 3677  loss 44.1824  lr 1.000e-03\n",
      "epoch 3678  loss 41.5977  lr 1.000e-03\n",
      "epoch 3679  loss 41.4624  lr 1.000e-03\n",
      "epoch 3680  loss 39.6888  lr 1.000e-03\n",
      "epoch 3681  loss 39.9528  lr 1.000e-03\n",
      "epoch 3682  loss 40.7710  lr 1.000e-03\n",
      "epoch 3683  loss 42.2879  lr 1.000e-03\n",
      "epoch 3684  loss 40.5018  lr 1.000e-03\n",
      "epoch 3685  loss 42.9582  lr 1.000e-03\n",
      "epoch 3686  loss 41.3102  lr 1.000e-03\n",
      "epoch 3687  loss 42.8963  lr 1.000e-03\n",
      "epoch 3688  loss 42.2194  lr 1.000e-03\n",
      "epoch 3689  loss 42.8763  lr 1.000e-03\n",
      "epoch 3690  loss 42.2432  lr 1.000e-03\n",
      "epoch 3691  loss 40.9778  lr 1.000e-03\n",
      "epoch 3692  loss 42.6132  lr 1.000e-03\n",
      "epoch 3693  loss 42.5416  lr 1.000e-03\n",
      "epoch 3694  loss 42.3958  lr 1.000e-03\n",
      "epoch 3695  loss 40.7474  lr 1.000e-03\n",
      "epoch 3696  loss 42.1245  lr 1.000e-03\n",
      "epoch 3697  loss 41.9404  lr 1.000e-03\n",
      "epoch 3698  loss 41.8589  lr 1.000e-03\n",
      "epoch 3699  loss 42.4161  lr 1.000e-03\n",
      "epoch 3700  loss 41.9038  lr 1.000e-03\n",
      "epoch 3701  loss 42.2225  lr 1.000e-03\n",
      "epoch 3702  loss 42.1800  lr 1.000e-03\n",
      "epoch 3703  loss 40.5537  lr 1.000e-03\n",
      "epoch 3704  loss 40.3237  lr 1.000e-03\n",
      "epoch 3705  loss 40.4540  lr 1.000e-03\n",
      "epoch 3706  loss 41.5394  lr 1.000e-03\n",
      "epoch 3707  loss 40.5573  lr 1.000e-03\n",
      "epoch 3708  loss 41.0135  lr 1.000e-03\n",
      "epoch 3709  loss 41.3712  lr 1.000e-03\n",
      "epoch 3710  loss 42.3469  lr 1.000e-03\n",
      "epoch 3711  loss 41.4106  lr 1.000e-03\n",
      "epoch 3712  loss 39.8382  lr 1.000e-03\n",
      "epoch 3713  loss 41.2238  lr 1.000e-03\n",
      "epoch 3714  loss 42.3978  lr 1.000e-03\n",
      "epoch 3715  loss 40.8178  lr 1.000e-03\n",
      "epoch 3716  loss 42.2067  lr 1.000e-03\n",
      "epoch 3717  loss 41.3449  lr 1.000e-03\n",
      "epoch 3718  loss 41.0050  lr 1.000e-03\n",
      "epoch 3719  loss 42.7016  lr 1.000e-03\n",
      "epoch 3720  loss 40.9974  lr 1.000e-03\n",
      "epoch 3721  loss 41.3611  lr 1.000e-03\n",
      "epoch 3722  loss 43.1774  lr 1.000e-03\n",
      "epoch 3723  loss 41.2432  lr 1.000e-03\n",
      "epoch 3724  loss 41.0300  lr 1.000e-03\n",
      "epoch 3725  loss 40.8618  lr 1.000e-03\n",
      "epoch 3726  loss 41.9335  lr 1.000e-03\n",
      "epoch 3727  loss 40.9193  lr 1.000e-03\n",
      "epoch 3728  loss 42.0895  lr 1.000e-03\n",
      "epoch 3729  loss 41.6998  lr 1.000e-03\n",
      "epoch 3730  loss 41.0171  lr 1.000e-03\n",
      "epoch 3731  loss 41.8707  lr 1.000e-03\n",
      "epoch 3732  loss 42.3372  lr 1.000e-03\n",
      "epoch 3733  loss 41.2529  lr 1.000e-03\n",
      "epoch 3734  loss 41.3475  lr 1.000e-03\n",
      "epoch 3735  loss 41.9476  lr 1.000e-03\n",
      "epoch 3736  loss 40.8954  lr 1.000e-03\n",
      "epoch 3737  loss 42.3776  lr 1.000e-03\n",
      "epoch 3738  loss 42.2590  lr 1.000e-03\n",
      "epoch 3739  loss 40.9534  lr 1.000e-03\n",
      "epoch 3740  loss 42.5405  lr 1.000e-03\n",
      "epoch 3741  loss 42.7790  lr 1.000e-03\n",
      "epoch 3742  loss 41.6505  lr 1.000e-03\n",
      "epoch 3743  loss 39.4721  lr 1.000e-03\n",
      "epoch 3744  loss 40.4729  lr 1.000e-03\n",
      "epoch 3745  loss 39.4993  lr 1.000e-03\n",
      "epoch 3746  loss 41.6816  lr 1.000e-03\n",
      "epoch 3747  loss 41.5087  lr 1.000e-03\n",
      "epoch 3748  loss 43.1062  lr 1.000e-03\n",
      "epoch 3749  loss 40.9985  lr 1.000e-03\n",
      "epoch 3750  loss 41.0605  lr 1.000e-03\n",
      "epoch 3751  loss 41.3854  lr 1.000e-03\n",
      "epoch 3752  loss 41.9002  lr 1.000e-03\n",
      "epoch 3753  loss 41.2540  lr 1.000e-03\n",
      "epoch 3754  loss 42.7720  lr 1.000e-03\n",
      "epoch 3755  loss 42.5269  lr 1.000e-03\n",
      "epoch 3756  loss 42.2164  lr 1.000e-03\n",
      "epoch 3757  loss 42.3069  lr 1.000e-03\n",
      "epoch 3758  loss 41.2803  lr 1.000e-03\n",
      "epoch 3759  loss 42.0150  lr 1.000e-03\n",
      "epoch 3760  loss 41.5245  lr 1.000e-03\n",
      "epoch 3761  loss 40.7997  lr 1.000e-03\n",
      "epoch 3762  loss 41.7294  lr 1.000e-03\n",
      "epoch 3763  loss 40.6400  lr 1.000e-03\n",
      "epoch 3764  loss 40.6411  lr 1.000e-03\n",
      "epoch 3765  loss 42.6545  lr 1.000e-03\n",
      "epoch 3766  loss 43.7076  lr 1.000e-03\n",
      "epoch 3767  loss 41.2748  lr 1.000e-03\n",
      "epoch 3768  loss 41.8771  lr 1.000e-03\n",
      "epoch 3769  loss 39.6445  lr 1.000e-03\n",
      "epoch 3770  loss 41.2161  lr 1.000e-03\n",
      "epoch 3771  loss 40.8003  lr 1.000e-03\n",
      "epoch 3772  loss 40.7264  lr 1.000e-03\n",
      "epoch 3773  loss 41.6614  lr 1.000e-03\n",
      "epoch 3774  loss 43.2138  lr 1.000e-03\n",
      "epoch 3775  loss 40.5961  lr 1.000e-03\n",
      "epoch 3776  loss 42.5466  lr 1.000e-03\n",
      "epoch 3777  loss 41.3168  lr 1.000e-03\n",
      "epoch 3778  loss 41.7112  lr 1.000e-03\n",
      "epoch 3779  loss 41.3531  lr 1.000e-03\n",
      "epoch 3780  loss 40.9229  lr 1.000e-03\n",
      "epoch 3781  loss 42.2647  lr 1.000e-03\n",
      "epoch 3782  loss 40.5105  lr 1.000e-03\n",
      "epoch 3783  loss 41.7245  lr 1.000e-03\n",
      "epoch 3784  loss 41.4221  lr 1.000e-03\n",
      "epoch 3785  loss 40.7811  lr 1.000e-03\n",
      "epoch 3786  loss 40.7505  lr 1.000e-03\n",
      "epoch 3787  loss 40.7286  lr 1.000e-03\n",
      "epoch 3788  loss 43.4421  lr 1.000e-03\n",
      "epoch 3789  loss 40.7194  lr 1.000e-03\n",
      "epoch 3790  loss 42.7153  lr 1.000e-03\n",
      "epoch 3791  loss 43.0955  lr 1.000e-03\n",
      "epoch 3792  loss 39.3990  lr 1.000e-03\n",
      "epoch 3793  loss 40.5870  lr 1.000e-03\n",
      "epoch 3794  loss 42.5363  lr 1.000e-03\n",
      "epoch 3795  loss 40.4974  lr 1.000e-03\n",
      "epoch 3796  loss 41.9432  lr 1.000e-03\n",
      "epoch 3797  loss 42.1840  lr 1.000e-03\n",
      "epoch 3798  loss 40.0998  lr 1.000e-03\n",
      "epoch 3799  loss 40.8571  lr 1.000e-03\n",
      "epoch 3800  loss 40.3946  lr 1.000e-03\n",
      "epoch 3801  loss 42.2120  lr 1.000e-03\n",
      "epoch 3802  loss 41.1462  lr 1.000e-03\n",
      "epoch 3803  loss 40.9849  lr 1.000e-03\n",
      "epoch 3804  loss 40.9000  lr 1.000e-03\n",
      "epoch 3805  loss 41.7281  lr 1.000e-03\n",
      "epoch 3806  loss 40.0411  lr 1.000e-03\n",
      "epoch 3807  loss 39.5335  lr 1.000e-03\n",
      "epoch 3808  loss 40.8551  lr 1.000e-03\n",
      "epoch 3809  loss 40.6101  lr 1.000e-03\n",
      "epoch 3810  loss 42.7576  lr 1.000e-03\n",
      "epoch 3811  loss 42.2257  lr 1.000e-03\n",
      "epoch 3812  loss 41.2378  lr 1.000e-03\n",
      "epoch 3813  loss 43.5145  lr 1.000e-03\n",
      "epoch 3814  loss 42.2177  lr 1.000e-03\n",
      "epoch 3815  loss 42.1762  lr 1.000e-03\n",
      "epoch 3816  loss 41.5944  lr 1.000e-03\n",
      "epoch 3817  loss 42.2086  lr 1.000e-03\n",
      "epoch 3818  loss 40.7371  lr 1.000e-03\n",
      "epoch 3819  loss 40.8464  lr 1.000e-03\n",
      "epoch 3820  loss 41.2591  lr 1.000e-03\n",
      "epoch 3821  loss 41.8768  lr 1.000e-03\n",
      "epoch 3822  loss 40.2063  lr 1.000e-03\n",
      "epoch 3823  loss 41.0559  lr 1.000e-03\n",
      "epoch 3824  loss 40.9580  lr 1.000e-03\n",
      "epoch 3825  loss 41.6771  lr 1.000e-03\n",
      "epoch 3826  loss 42.5529  lr 1.000e-03\n",
      "epoch 3827  loss 41.3447  lr 1.000e-03\n",
      "epoch 3828  loss 40.1631  lr 1.000e-03\n",
      "epoch 3829  loss 42.7159  lr 1.000e-03\n",
      "epoch 3830  loss 42.7301  lr 1.000e-03\n",
      "epoch 3831  loss 43.4462  lr 1.000e-03\n",
      "epoch 3832  loss 40.9529  lr 1.000e-03\n",
      "epoch 3833  loss 40.7830  lr 1.000e-03\n",
      "epoch 3834  loss 41.8071  lr 1.000e-03\n",
      "epoch 3835  loss 42.2616  lr 1.000e-03\n",
      "epoch 3836  loss 41.2303  lr 1.000e-03\n",
      "epoch 3837  loss 41.2093  lr 1.000e-03\n",
      "epoch 3838  loss 40.3915  lr 1.000e-03\n",
      "epoch 3839  loss 42.6162  lr 1.000e-03\n",
      "epoch 3840  loss 39.6048  lr 1.000e-03\n",
      "epoch 3841  loss 41.3776  lr 1.000e-03\n",
      "epoch 3842  loss 41.9323  lr 1.000e-03\n",
      "epoch 3843  loss 41.5644  lr 1.000e-03\n",
      "epoch 3844  loss 41.7104  lr 1.000e-03\n",
      "epoch 3845  loss 42.5761  lr 1.000e-03\n",
      "epoch 3846  loss 40.5781  lr 1.000e-03\n",
      "epoch 3847  loss 40.6959  lr 1.000e-03\n",
      "epoch 3848  loss 40.2224  lr 1.000e-03\n",
      "epoch 3849  loss 41.3076  lr 1.000e-03\n",
      "epoch 3850  loss 42.2641  lr 1.000e-03\n",
      "epoch 3851  loss 43.9375  lr 1.000e-03\n",
      "epoch 3852  loss 40.7164  lr 1.000e-03\n",
      "epoch 3853  loss 40.7982  lr 1.000e-03\n",
      "epoch 3854  loss 41.1260  lr 1.000e-03\n",
      "epoch 3855  loss 42.1320  lr 1.000e-03\n",
      "epoch 3856  loss 41.9033  lr 1.000e-03\n",
      "epoch 3857  loss 43.3770  lr 1.000e-03\n",
      "epoch 3858  loss 43.2064  lr 1.000e-03\n",
      "epoch 3859  loss 42.2391  lr 1.000e-03\n",
      "epoch 3860  loss 42.1412  lr 1.000e-03\n",
      "epoch 3861  loss 42.3362  lr 1.000e-03\n",
      "epoch 3862  loss 41.5119  lr 1.000e-03\n",
      "epoch 3863  loss 41.1590  lr 1.000e-03\n",
      "epoch 3864  loss 40.4858  lr 1.000e-03\n",
      "epoch 3865  loss 41.0222  lr 1.000e-03\n",
      "epoch 3866  loss 41.6086  lr 1.000e-03\n",
      "epoch 3867  loss 42.0618  lr 1.000e-03\n",
      "epoch 3868  loss 41.2774  lr 1.000e-03\n",
      "epoch 3869  loss 41.2010  lr 1.000e-03\n",
      "epoch 3870  loss 42.4155  lr 1.000e-03\n",
      "epoch 3871  loss 39.8853  lr 1.000e-03\n",
      "epoch 3872  loss 40.1486  lr 1.000e-03\n",
      "epoch 3873  loss 41.4413  lr 1.000e-03\n",
      "epoch 3874  loss 40.7615  lr 1.000e-03\n",
      "epoch 3875  loss 41.0074  lr 1.000e-03\n",
      "epoch 3876  loss 41.3352  lr 1.000e-03\n",
      "epoch 3877  loss 40.3602  lr 1.000e-03\n",
      "epoch 3878  loss 40.2522  lr 1.000e-03\n",
      "epoch 3879  loss 40.7008  lr 1.000e-03\n",
      "epoch 3880  loss 40.5159  lr 1.000e-03\n",
      "epoch 3881  loss 40.8239  lr 1.000e-03\n",
      "epoch 3882  loss 40.6771  lr 1.000e-03\n",
      "epoch 3883  loss 41.0762  lr 1.000e-03\n",
      "epoch 3884  loss 42.2492  lr 1.000e-03\n",
      "epoch 3885  loss 42.8549  lr 1.000e-03\n",
      "epoch 3886  loss 41.9425  lr 1.000e-03\n",
      "epoch 3887  loss 42.1967  lr 1.000e-03\n",
      "epoch 3888  loss 40.4655  lr 1.000e-03\n",
      "epoch 3889  loss 41.8277  lr 1.000e-03\n",
      "epoch 3890  loss 42.0401  lr 1.000e-03\n",
      "epoch 3891  loss 40.5450  lr 1.000e-03\n",
      "epoch 3892  loss 40.9982  lr 1.000e-03\n",
      "epoch 3893  loss 39.4244  lr 1.000e-03\n",
      "epoch 3894  loss 40.4332  lr 1.000e-03\n",
      "epoch 3895  loss 40.9861  lr 1.000e-03\n",
      "epoch 3896  loss 40.7961  lr 1.000e-03\n",
      "epoch 3897  loss 41.7776  lr 1.000e-03\n",
      "epoch 3898  loss 40.6602  lr 1.000e-03\n",
      "epoch 3899  loss 40.7042  lr 1.000e-03\n",
      "epoch 3900  loss 40.4074  lr 1.000e-03\n",
      "epoch 3901  loss 42.9049  lr 1.000e-03\n",
      "epoch 3902  loss 40.2681  lr 1.000e-03\n",
      "epoch 3903  loss 40.2299  lr 1.000e-03\n",
      "epoch 3904  loss 41.0166  lr 1.000e-03\n",
      "epoch 3905  loss 40.9620  lr 1.000e-03\n",
      "epoch 3906  loss 42.8266  lr 1.000e-03\n",
      "epoch 3907  loss 39.7660  lr 1.000e-03\n",
      "epoch 3908  loss 41.9903  lr 1.000e-03\n",
      "epoch 3909  loss 41.8948  lr 1.000e-03\n",
      "epoch 3910  loss 42.2311  lr 1.000e-03\n",
      "epoch 3911  loss 40.7523  lr 1.000e-03\n",
      "epoch 3912  loss 41.2612  lr 1.000e-03\n",
      "epoch 3913  loss 40.4764  lr 1.000e-03\n",
      "epoch 3914  loss 41.4775  lr 1.000e-03\n",
      "epoch 3915  loss 41.5195  lr 1.000e-03\n",
      "epoch 3916  loss 42.4783  lr 1.000e-03\n",
      "epoch 3917  loss 41.7000  lr 1.000e-03\n",
      "epoch 3918  loss 42.1214  lr 1.000e-03\n",
      "epoch 3919  loss 41.9841  lr 1.000e-03\n",
      "epoch 3920  loss 41.1003  lr 1.000e-03\n",
      "epoch 3921  loss 40.5416  lr 1.000e-03\n",
      "epoch 3922  loss 40.7155  lr 1.000e-03\n",
      "epoch 3923  loss 41.3886  lr 1.000e-03\n",
      "epoch 3924  loss 40.2595  lr 1.000e-03\n",
      "epoch 3925  loss 42.1559  lr 1.000e-03\n",
      "epoch 3926  loss 40.5793  lr 1.000e-03\n",
      "epoch 3927  loss 40.7791  lr 1.000e-03\n",
      "epoch 3928  loss 41.2414  lr 1.000e-03\n",
      "epoch 3929  loss 40.6297  lr 1.000e-03\n",
      "epoch 3930  loss 42.5662  lr 1.000e-03\n",
      "epoch 3931  loss 42.8630  lr 1.000e-03\n",
      "epoch 3932  loss 42.5515  lr 1.000e-03\n",
      "epoch 3933  loss 42.4138  lr 1.000e-03\n",
      "epoch 3934  loss 40.2219  lr 1.000e-03\n",
      "epoch 3935  loss 40.7206  lr 1.000e-03\n",
      "epoch 3936  loss 43.0667  lr 1.000e-03\n",
      "epoch 3937  loss 41.0438  lr 1.000e-03\n",
      "epoch 3938  loss 39.4672  lr 1.000e-03\n",
      "epoch 3939  loss 40.0570  lr 1.000e-03\n",
      "epoch 3940  loss 41.0438  lr 1.000e-03\n",
      "epoch 3941  loss 41.2902  lr 1.000e-03\n",
      "epoch 3942  loss 42.1912  lr 1.000e-03\n",
      "epoch 3943  loss 41.7599  lr 1.000e-03\n",
      "epoch 3944  loss 41.8168  lr 1.000e-03\n",
      "epoch 3945  loss 42.1909  lr 1.000e-03\n",
      "epoch 3946  loss 40.6541  lr 1.000e-03\n",
      "epoch 3947  loss 41.2708  lr 1.000e-03\n",
      "epoch 3948  loss 39.1492  lr 1.000e-03\n",
      "epoch 3949  loss 39.9430  lr 1.000e-03\n",
      "epoch 3950  loss 43.0332  lr 1.000e-03\n",
      "epoch 3951  loss 39.8529  lr 1.000e-03\n",
      "epoch 3952  loss 39.4112  lr 1.000e-03\n",
      "epoch 3953  loss 39.3228  lr 1.000e-03\n",
      "epoch 3954  loss 40.2478  lr 1.000e-03\n",
      "epoch 3955  loss 40.8208  lr 1.000e-03\n",
      "epoch 3956  loss 40.9664  lr 1.000e-03\n",
      "epoch 3957  loss 41.3536  lr 1.000e-03\n",
      "epoch 3958  loss 40.1575  lr 1.000e-03\n",
      "epoch 3959  loss 40.6531  lr 1.000e-03\n",
      "epoch 3960  loss 40.4215  lr 1.000e-03\n",
      "epoch 3961  loss 41.4535  lr 1.000e-03\n",
      "epoch 3962  loss 40.2647  lr 1.000e-03\n",
      "epoch 3963  loss 40.6608  lr 1.000e-03\n",
      "epoch 3964  loss 40.5950  lr 1.000e-03\n",
      "epoch 3965  loss 40.3736  lr 1.000e-03\n",
      "epoch 3966  loss 39.6336  lr 1.000e-03\n",
      "epoch 3967  loss 40.8773  lr 1.000e-03\n",
      "epoch 3968  loss 40.5540  lr 1.000e-03\n",
      "epoch 3969  loss 40.6279  lr 1.000e-03\n",
      "epoch 3970  loss 40.5901  lr 1.000e-03\n",
      "epoch 3971  loss 41.0099  lr 1.000e-03\n",
      "epoch 3972  loss 40.3584  lr 1.000e-03\n",
      "epoch 3973  loss 39.8214  lr 1.000e-03\n",
      "epoch 3974  loss 41.9166  lr 1.000e-03\n",
      "epoch 3975  loss 41.5920  lr 1.000e-03\n",
      "epoch 3976  loss 42.3500  lr 1.000e-03\n",
      "epoch 3977  loss 42.7191  lr 1.000e-03\n",
      "epoch 3978  loss 42.2615  lr 1.000e-03\n",
      "epoch 3979  loss 41.8153  lr 1.000e-03\n",
      "epoch 3980  loss 41.9299  lr 1.000e-03\n",
      "epoch 3981  loss 40.9219  lr 1.000e-03\n",
      "epoch 3982  loss 42.9019  lr 1.000e-03\n",
      "epoch 3983  loss 39.6271  lr 1.000e-03\n",
      "epoch 3984  loss 41.6767  lr 1.000e-03\n",
      "epoch 3985  loss 40.7668  lr 1.000e-03\n",
      "epoch 3986  loss 41.0607  lr 1.000e-03\n",
      "epoch 3987  loss 41.7537  lr 1.000e-03\n",
      "epoch 3988  loss 41.0796  lr 1.000e-03\n",
      "epoch 3989  loss 41.0372  lr 1.000e-03\n",
      "epoch 3990  loss 40.3317  lr 1.000e-03\n",
      "epoch 3991  loss 41.5787  lr 1.000e-03\n",
      "epoch 3992  loss 42.0096  lr 1.000e-03\n",
      "epoch 3993  loss 39.7904  lr 1.000e-03\n",
      "epoch 3994  loss 39.7426  lr 1.000e-03\n",
      "epoch 3995  loss 41.3767  lr 1.000e-03\n",
      "epoch 3996  loss 40.3842  lr 1.000e-03\n",
      "epoch 3997  loss 41.2794  lr 1.000e-03\n",
      "epoch 3998  loss 39.3200  lr 1.000e-03\n",
      "epoch 3999  loss 40.4166  lr 1.000e-03\n",
      "epoch 4000  loss 38.9335  lr 1.000e-03\n",
      "epoch 4001  loss 39.7527  lr 1.000e-03\n",
      "epoch 4002  loss 41.1339  lr 1.000e-03\n",
      "epoch 4003  loss 40.0071  lr 1.000e-03\n",
      "epoch 4004  loss 41.5252  lr 1.000e-03\n",
      "epoch 4005  loss 40.9464  lr 1.000e-03\n",
      "epoch 4006  loss 44.0626  lr 1.000e-03\n",
      "epoch 4007  loss 41.7038  lr 1.000e-03\n",
      "epoch 4008  loss 41.7558  lr 1.000e-03\n",
      "epoch 4009  loss 41.5441  lr 1.000e-03\n",
      "epoch 4010  loss 41.8350  lr 1.000e-03\n",
      "epoch 4011  loss 41.6910  lr 1.000e-03\n",
      "epoch 4012  loss 41.6354  lr 1.000e-03\n",
      "epoch 4013  loss 39.3208  lr 1.000e-03\n",
      "epoch 4014  loss 41.5890  lr 1.000e-03\n",
      "epoch 4015  loss 39.1330  lr 1.000e-03\n",
      "epoch 4016  loss 42.1513  lr 1.000e-03\n",
      "epoch 4017  loss 42.0066  lr 1.000e-03\n",
      "epoch 4018  loss 41.0798  lr 1.000e-03\n",
      "epoch 4019  loss 41.5511  lr 1.000e-03\n",
      "epoch 4020  loss 42.1456  lr 1.000e-03\n",
      "epoch 4021  loss 41.1096  lr 1.000e-03\n",
      "epoch 4022  loss 41.0456  lr 1.000e-03\n",
      "epoch 4023  loss 39.6099  lr 1.000e-03\n",
      "epoch 4024  loss 41.7707  lr 1.000e-03\n",
      "epoch 4025  loss 40.5889  lr 1.000e-03\n",
      "epoch 4026  loss 40.9004  lr 1.000e-03\n",
      "epoch 4027  loss 41.3284  lr 1.000e-03\n",
      "epoch 4028  loss 41.2157  lr 1.000e-03\n",
      "epoch 4029  loss 41.1754  lr 1.000e-03\n",
      "epoch 4030  loss 39.7939  lr 1.000e-03\n",
      "epoch 4031  loss 39.4300  lr 1.000e-03\n",
      "epoch 4032  loss 40.8731  lr 1.000e-03\n",
      "epoch 4033  loss 41.4818  lr 1.000e-03\n",
      "epoch 4034  loss 42.2868  lr 1.000e-03\n",
      "epoch 4035  loss 41.3521  lr 1.000e-03\n",
      "epoch 4036  loss 43.3247  lr 1.000e-03\n",
      "epoch 4037  loss 42.2545  lr 1.000e-03\n",
      "epoch 4038  loss 41.0954  lr 1.000e-03\n",
      "epoch 4039  loss 39.5702  lr 1.000e-03\n",
      "epoch 4040  loss 41.1722  lr 1.000e-03\n",
      "epoch 4041  loss 41.8338  lr 1.000e-03\n",
      "epoch 4042  loss 43.0110  lr 1.000e-03\n",
      "epoch 4043  loss 40.9471  lr 1.000e-03\n",
      "epoch 4044  loss 40.1610  lr 1.000e-03\n",
      "epoch 4045  loss 39.3997  lr 1.000e-03\n",
      "epoch 4046  loss 41.2243  lr 1.000e-03\n",
      "epoch 4047  loss 41.7117  lr 1.000e-03\n",
      "epoch 4048  loss 42.1434  lr 1.000e-03\n",
      "epoch 4049  loss 38.4322  lr 1.000e-03\n",
      "epoch 4050  loss 40.6758  lr 1.000e-03\n",
      "epoch 4051  loss 40.4356  lr 1.000e-03\n",
      "epoch 4052  loss 41.3749  lr 1.000e-03\n",
      "epoch 4053  loss 41.4206  lr 1.000e-03\n",
      "epoch 4054  loss 40.9929  lr 1.000e-03\n",
      "epoch 4055  loss 41.2998  lr 1.000e-03\n",
      "epoch 4056  loss 40.6484  lr 1.000e-03\n",
      "epoch 4057  loss 39.9285  lr 1.000e-03\n",
      "epoch 4058  loss 43.5560  lr 1.000e-03\n",
      "epoch 4059  loss 40.4978  lr 1.000e-03\n",
      "epoch 4060  loss 41.4430  lr 1.000e-03\n",
      "epoch 4061  loss 40.7523  lr 1.000e-03\n",
      "epoch 4062  loss 39.2295  lr 1.000e-03\n",
      "epoch 4063  loss 41.2475  lr 1.000e-03\n",
      "epoch 4064  loss 40.8281  lr 1.000e-03\n",
      "epoch 4065  loss 40.6804  lr 1.000e-03\n",
      "epoch 4066  loss 40.6398  lr 1.000e-03\n",
      "epoch 4067  loss 42.5413  lr 1.000e-03\n",
      "epoch 4068  loss 38.5344  lr 1.000e-03\n",
      "epoch 4069  loss 39.9858  lr 1.000e-03\n",
      "epoch 4070  loss 40.8282  lr 1.000e-03\n",
      "epoch 4071  loss 40.3855  lr 1.000e-03\n",
      "epoch 4072  loss 39.3152  lr 1.000e-03\n",
      "epoch 4073  loss 41.0977  lr 1.000e-03\n",
      "epoch 4074  loss 41.3678  lr 1.000e-03\n",
      "epoch 4075  loss 40.3454  lr 1.000e-03\n",
      "epoch 4076  loss 39.6223  lr 1.000e-03\n",
      "epoch 4077  loss 40.4625  lr 1.000e-03\n",
      "epoch 4078  loss 40.0005  lr 1.000e-03\n",
      "epoch 4079  loss 40.1237  lr 1.000e-03\n",
      "epoch 4080  loss 40.9780  lr 1.000e-03\n",
      "epoch 4081  loss 41.6593  lr 1.000e-03\n",
      "epoch 4082  loss 40.7737  lr 1.000e-03\n",
      "epoch 4083  loss 42.1913  lr 1.000e-03\n",
      "epoch 4084  loss 41.0360  lr 1.000e-03\n",
      "epoch 4085  loss 41.2842  lr 1.000e-03\n",
      "epoch 4086  loss 40.4787  lr 1.000e-03\n",
      "epoch 4087  loss 41.3049  lr 1.000e-03\n",
      "epoch 4088  loss 39.8121  lr 1.000e-03\n",
      "epoch 4089  loss 41.1923  lr 1.000e-03\n",
      "epoch 4090  loss 41.0066  lr 1.000e-03\n",
      "epoch 4091  loss 41.0252  lr 1.000e-03\n",
      "epoch 4092  loss 40.0271  lr 1.000e-03\n",
      "epoch 4093  loss 40.1028  lr 1.000e-03\n",
      "epoch 4094  loss 39.4118  lr 1.000e-03\n",
      "epoch 4095  loss 42.8327  lr 1.000e-03\n",
      "epoch 4096  loss 40.1929  lr 1.000e-03\n",
      "epoch 4097  loss 42.2151  lr 1.000e-03\n",
      "epoch 4098  loss 40.5727  lr 1.000e-03\n",
      "epoch 4099  loss 41.0268  lr 1.000e-03\n",
      "epoch 4100  loss 41.3911  lr 1.000e-03\n",
      "epoch 4101  loss 40.4693  lr 1.000e-03\n",
      "epoch 4102  loss 40.2101  lr 1.000e-03\n",
      "epoch 4103  loss 39.8673  lr 1.000e-03\n",
      "epoch 4104  loss 40.6959  lr 1.000e-03\n",
      "epoch 4105  loss 40.3413  lr 1.000e-03\n",
      "epoch 4106  loss 41.6261  lr 1.000e-03\n",
      "epoch 4107  loss 41.9388  lr 1.000e-03\n",
      "epoch 4108  loss 39.9977  lr 1.000e-03\n",
      "epoch 4109  loss 39.2709  lr 1.000e-03\n",
      "epoch 4110  loss 40.4064  lr 1.000e-03\n",
      "epoch 4111  loss 40.8107  lr 1.000e-03\n",
      "epoch 4112  loss 41.7306  lr 1.000e-03\n",
      "epoch 4113  loss 43.8265  lr 1.000e-03\n",
      "epoch 4114  loss 41.0849  lr 1.000e-03\n",
      "epoch 4115  loss 39.3432  lr 1.000e-03\n",
      "epoch 4116  loss 41.8391  lr 1.000e-03\n",
      "epoch 4117  loss 40.8944  lr 1.000e-03\n",
      "epoch 4118  loss 40.1339  lr 1.000e-03\n",
      "epoch 4119  loss 41.0461  lr 1.000e-03\n",
      "epoch 4120  loss 40.9809  lr 1.000e-03\n",
      "epoch 4121  loss 41.0918  lr 1.000e-03\n",
      "epoch 4122  loss 41.5429  lr 1.000e-03\n",
      "epoch 4123  loss 41.0559  lr 1.000e-03\n",
      "epoch 4124  loss 41.4171  lr 1.000e-03\n",
      "epoch 4125  loss 38.4035  lr 1.000e-03\n",
      "epoch 4126  loss 40.4530  lr 1.000e-03\n",
      "epoch 4127  loss 40.9403  lr 1.000e-03\n",
      "epoch 4128  loss 41.1907  lr 1.000e-03\n",
      "epoch 4129  loss 40.7104  lr 1.000e-03\n",
      "epoch 4130  loss 41.0132  lr 1.000e-03\n",
      "epoch 4131  loss 41.3933  lr 1.000e-03\n",
      "epoch 4132  loss 41.1699  lr 1.000e-03\n",
      "epoch 4133  loss 39.8215  lr 1.000e-03\n",
      "epoch 4134  loss 41.2455  lr 1.000e-03\n",
      "epoch 4135  loss 42.6738  lr 1.000e-03\n",
      "epoch 4136  loss 41.4167  lr 1.000e-03\n",
      "epoch 4137  loss 39.9550  lr 1.000e-03\n",
      "epoch 4138  loss 40.8477  lr 1.000e-03\n",
      "epoch 4139  loss 41.4835  lr 1.000e-03\n",
      "epoch 4140  loss 40.9246  lr 1.000e-03\n",
      "epoch 4141  loss 40.8235  lr 1.000e-03\n",
      "epoch 4142  loss 41.6348  lr 1.000e-03\n",
      "epoch 4143  loss 40.0582  lr 1.000e-03\n",
      "epoch 4144  loss 41.6678  lr 1.000e-03\n",
      "epoch 4145  loss 41.2432  lr 1.000e-03\n",
      "epoch 4146  loss 40.5780  lr 1.000e-03\n",
      "epoch 4147  loss 40.6011  lr 1.000e-03\n",
      "epoch 4148  loss 40.3414  lr 1.000e-03\n",
      "epoch 4149  loss 39.5840  lr 1.000e-03\n",
      "epoch 4150  loss 39.4798  lr 1.000e-03\n",
      "epoch 4151  loss 40.2121  lr 1.000e-03\n",
      "epoch 4152  loss 40.6834  lr 1.000e-03\n",
      "epoch 4153  loss 40.1786  lr 1.000e-03\n",
      "epoch 4154  loss 39.9148  lr 1.000e-03\n",
      "epoch 4155  loss 40.4197  lr 1.000e-03\n",
      "epoch 4156  loss 41.3437  lr 1.000e-03\n",
      "epoch 4157  loss 39.5288  lr 1.000e-03\n",
      "epoch 4158  loss 40.1562  lr 1.000e-03\n",
      "epoch 4159  loss 40.9206  lr 1.000e-03\n",
      "epoch 4160  loss 39.4844  lr 1.000e-03\n",
      "epoch 4161  loss 39.6159  lr 1.000e-03\n",
      "epoch 4162  loss 39.6893  lr 1.000e-03\n",
      "epoch 4163  loss 40.9022  lr 1.000e-03\n",
      "epoch 4164  loss 43.7955  lr 1.000e-03\n",
      "epoch 4165  loss 41.9426  lr 1.000e-03\n",
      "epoch 4166  loss 41.7007  lr 1.000e-03\n",
      "epoch 4167  loss 41.5071  lr 1.000e-03\n",
      "epoch 4168  loss 41.3033  lr 1.000e-03\n",
      "epoch 4169  loss 39.1445  lr 1.000e-03\n",
      "epoch 4170  loss 41.1829  lr 1.000e-03\n",
      "epoch 4171  loss 40.3355  lr 1.000e-03\n",
      "epoch 4172  loss 40.1831  lr 1.000e-03\n",
      "epoch 4173  loss 39.0639  lr 1.000e-03\n",
      "epoch 4174  loss 40.2091  lr 1.000e-03\n",
      "epoch 4175  loss 40.3595  lr 1.000e-03\n",
      "epoch 4176  loss 40.5800  lr 1.000e-03\n",
      "epoch 4177  loss 40.2157  lr 1.000e-03\n",
      "epoch 4178  loss 41.7132  lr 1.000e-03\n",
      "epoch 4179  loss 40.9401  lr 1.000e-03\n",
      "epoch 4180  loss 41.6098  lr 1.000e-03\n",
      "epoch 4181  loss 39.1512  lr 1.000e-03\n",
      "epoch 4182  loss 40.1043  lr 1.000e-03\n",
      "epoch 4183  loss 41.8806  lr 1.000e-03\n",
      "epoch 4184  loss 41.6296  lr 1.000e-03\n",
      "epoch 4185  loss 40.1138  lr 1.000e-03\n",
      "epoch 4186  loss 40.3575  lr 1.000e-03\n",
      "epoch 4187  loss 41.0913  lr 1.000e-03\n",
      "epoch 4188  loss 40.5427  lr 1.000e-03\n",
      "epoch 4189  loss 40.8059  lr 1.000e-03\n",
      "epoch 4190  loss 40.8604  lr 1.000e-03\n",
      "epoch 4191  loss 40.8243  lr 1.000e-03\n",
      "epoch 4192  loss 41.7277  lr 1.000e-03\n",
      "epoch 4193  loss 40.7455  lr 1.000e-03\n",
      "epoch 4194  loss 39.6861  lr 1.000e-03\n",
      "epoch 4195  loss 41.4275  lr 1.000e-03\n",
      "epoch 4196  loss 41.3581  lr 1.000e-03\n",
      "epoch 4197  loss 41.2273  lr 1.000e-03\n",
      "epoch 4198  loss 41.4226  lr 1.000e-03\n",
      "epoch 4199  loss 41.7302  lr 1.000e-03\n",
      "epoch 4200  loss 40.5913  lr 1.000e-03\n",
      "epoch 4201  loss 40.1316  lr 1.000e-03\n",
      "epoch 4202  loss 39.3904  lr 1.000e-03\n",
      "epoch 4203  loss 41.1959  lr 1.000e-03\n",
      "epoch 4204  loss 39.6976  lr 1.000e-03\n",
      "epoch 4205  loss 41.0533  lr 1.000e-03\n",
      "epoch 4206  loss 41.2725  lr 1.000e-03\n",
      "epoch 4207  loss 41.4952  lr 1.000e-03\n",
      "epoch 4208  loss 41.1410  lr 1.000e-03\n",
      "epoch 4209  loss 41.6629  lr 1.000e-03\n",
      "epoch 4210  loss 40.8066  lr 1.000e-03\n",
      "epoch 4211  loss 38.7786  lr 1.000e-03\n",
      "epoch 4212  loss 40.9578  lr 1.000e-03\n",
      "epoch 4213  loss 40.8358  lr 1.000e-03\n",
      "epoch 4214  loss 41.2360  lr 1.000e-03\n",
      "epoch 4215  loss 40.4289  lr 1.000e-03\n",
      "epoch 4216  loss 40.4544  lr 1.000e-03\n",
      "epoch 4217  loss 40.2378  lr 1.000e-03\n",
      "epoch 4218  loss 38.7427  lr 1.000e-03\n",
      "epoch 4219  loss 40.5254  lr 1.000e-03\n",
      "epoch 4220  loss 40.3854  lr 1.000e-03\n",
      "epoch 4221  loss 41.4967  lr 1.000e-03\n",
      "epoch 4222  loss 40.1883  lr 1.000e-03\n",
      "epoch 4223  loss 40.7858  lr 1.000e-03\n",
      "epoch 4224  loss 39.9392  lr 1.000e-03\n",
      "epoch 4225  loss 39.8826  lr 1.000e-03\n",
      "epoch 4226  loss 39.9555  lr 1.000e-03\n",
      "epoch 4227  loss 41.6187  lr 1.000e-03\n",
      "epoch 4228  loss 39.1965  lr 1.000e-03\n",
      "epoch 4229  loss 41.3284  lr 1.000e-03\n",
      "epoch 4230  loss 41.0788  lr 1.000e-03\n",
      "epoch 4231  loss 40.0507  lr 1.000e-03\n",
      "epoch 4232  loss 39.6792  lr 1.000e-03\n",
      "epoch 4233  loss 40.6940  lr 1.000e-03\n",
      "epoch 4234  loss 43.2624  lr 1.000e-03\n",
      "epoch 4235  loss 40.4500  lr 1.000e-03\n",
      "epoch 4236  loss 42.5386  lr 1.000e-03\n",
      "epoch 4237  loss 39.9983  lr 1.000e-03\n",
      "epoch 4238  loss 43.2599  lr 1.000e-03\n",
      "epoch 4239  loss 39.6653  lr 1.000e-03\n",
      "epoch 4240  loss 40.7587  lr 1.000e-03\n",
      "epoch 4241  loss 39.5299  lr 1.000e-03\n",
      "epoch 4242  loss 40.4499  lr 1.000e-03\n",
      "epoch 4243  loss 39.8842  lr 1.000e-03\n",
      "epoch 4244  loss 39.8029  lr 1.000e-03\n",
      "epoch 4245  loss 41.0981  lr 1.000e-03\n",
      "epoch 4246  loss 39.9442  lr 1.000e-03\n",
      "epoch 4247  loss 42.1701  lr 1.000e-03\n",
      "epoch 4248  loss 40.1969  lr 1.000e-03\n",
      "epoch 4249  loss 42.1520  lr 1.000e-03\n",
      "epoch 4250  loss 40.8135  lr 1.000e-03\n",
      "epoch 4251  loss 40.0720  lr 1.000e-03\n",
      "epoch 4252  loss 39.7339  lr 1.000e-03\n",
      "epoch 4253  loss 39.6758  lr 1.000e-03\n",
      "epoch 4254  loss 39.8125  lr 1.000e-03\n",
      "epoch 4255  loss 39.5775  lr 1.000e-03\n",
      "epoch 4256  loss 39.8408  lr 1.000e-03\n",
      "epoch 4257  loss 42.4390  lr 1.000e-03\n",
      "epoch 4258  loss 42.2754  lr 1.000e-03\n",
      "epoch 4259  loss 39.3572  lr 1.000e-03\n",
      "epoch 4260  loss 40.4965  lr 1.000e-03\n",
      "epoch 4261  loss 39.8915  lr 1.000e-03\n",
      "epoch 4262  loss 40.6242  lr 1.000e-03\n",
      "epoch 4263  loss 41.4110  lr 1.000e-03\n",
      "epoch 4264  loss 42.1236  lr 1.000e-03\n",
      "epoch 4265  loss 39.0108  lr 1.000e-03\n",
      "epoch 4266  loss 41.8623  lr 1.000e-03\n",
      "epoch 4267  loss 39.9503  lr 1.000e-03\n",
      "epoch 4268  loss 40.0748  lr 1.000e-03\n",
      "epoch 4269  loss 40.5514  lr 1.000e-03\n",
      "epoch 4270  loss 40.8506  lr 1.000e-03\n",
      "epoch 4271  loss 41.9259  lr 1.000e-03\n",
      "epoch 4272  loss 41.5215  lr 1.000e-03\n",
      "epoch 4273  loss 40.3815  lr 1.000e-03\n",
      "epoch 4274  loss 39.5415  lr 1.000e-03\n",
      "epoch 4275  loss 42.5521  lr 1.000e-03\n",
      "epoch 4276  loss 39.2660  lr 1.000e-03\n",
      "epoch 4277  loss 39.4319  lr 1.000e-03\n",
      "epoch 4278  loss 41.3202  lr 1.000e-03\n",
      "epoch 4279  loss 41.1629  lr 1.000e-03\n",
      "epoch 4280  loss 41.6120  lr 1.000e-03\n",
      "epoch 4281  loss 40.5638  lr 1.000e-03\n",
      "epoch 4282  loss 40.4908  lr 1.000e-03\n",
      "epoch 4283  loss 41.1487  lr 1.000e-03\n",
      "epoch 4284  loss 40.6160  lr 1.000e-03\n",
      "epoch 4285  loss 40.2756  lr 1.000e-03\n",
      "epoch 4286  loss 40.4075  lr 1.000e-03\n",
      "epoch 4287  loss 39.7976  lr 1.000e-03\n",
      "epoch 4288  loss 39.6133  lr 1.000e-03\n",
      "epoch 4289  loss 40.6710  lr 1.000e-03\n",
      "epoch 4290  loss 40.5705  lr 1.000e-03\n",
      "epoch 4291  loss 41.6974  lr 1.000e-03\n",
      "epoch 4292  loss 41.7917  lr 1.000e-03\n",
      "epoch 4293  loss 41.2723  lr 1.000e-03\n",
      "epoch 4294  loss 40.7905  lr 1.000e-03\n",
      "epoch 4295  loss 38.8600  lr 1.000e-03\n",
      "epoch 4296  loss 38.7141  lr 1.000e-03\n",
      "epoch 4297  loss 38.8842  lr 1.000e-03\n",
      "epoch 4298  loss 41.2933  lr 1.000e-03\n",
      "epoch 4299  loss 39.1018  lr 1.000e-03\n",
      "epoch 4300  loss 40.6569  lr 1.000e-03\n",
      "epoch 4301  loss 40.8389  lr 1.000e-03\n",
      "epoch 4302  loss 39.8319  lr 1.000e-03\n",
      "epoch 4303  loss 41.1963  lr 1.000e-03\n",
      "epoch 4304  loss 40.6280  lr 1.000e-03\n",
      "epoch 4305  loss 40.4029  lr 1.000e-03\n",
      "epoch 4306  loss 41.0336  lr 1.000e-03\n",
      "epoch 4307  loss 41.1888  lr 1.000e-03\n",
      "epoch 4308  loss 40.4598  lr 1.000e-03\n",
      "epoch 4309  loss 40.5653  lr 1.000e-03\n",
      "epoch 4310  loss 39.9717  lr 1.000e-03\n",
      "epoch 4311  loss 44.3724  lr 1.000e-03\n",
      "epoch 4312  loss 39.9186  lr 1.000e-03\n",
      "epoch 4313  loss 40.2289  lr 1.000e-03\n",
      "epoch 4314  loss 41.6878  lr 1.000e-03\n",
      "epoch 4315  loss 39.8928  lr 1.000e-03\n",
      "epoch 4316  loss 39.0706  lr 1.000e-03\n",
      "epoch 4317  loss 39.9304  lr 1.000e-03\n",
      "epoch 4318  loss 41.2757  lr 1.000e-03\n",
      "epoch 4319  loss 41.6918  lr 1.000e-03\n",
      "epoch 4320  loss 39.9696  lr 1.000e-03\n",
      "epoch 4321  loss 41.4247  lr 1.000e-03\n",
      "epoch 4322  loss 41.0574  lr 1.000e-03\n",
      "epoch 4323  loss 41.4570  lr 1.000e-03\n",
      "epoch 4324  loss 40.8247  lr 1.000e-03\n",
      "epoch 4325  loss 40.1783  lr 1.000e-03\n",
      "epoch 4326  loss 41.0148  lr 1.000e-03\n",
      "epoch 4327  loss 41.2596  lr 1.000e-03\n",
      "epoch 4328  loss 40.7678  lr 1.000e-03\n",
      "epoch 4329  loss 40.2325  lr 1.000e-03\n",
      "epoch 4330  loss 41.1107  lr 1.000e-03\n",
      "epoch 4331  loss 40.0208  lr 1.000e-03\n",
      "epoch 4332  loss 40.7189  lr 1.000e-03\n",
      "epoch 4333  loss 41.0140  lr 1.000e-03\n",
      "epoch 4334  loss 41.0827  lr 1.000e-03\n",
      "epoch 4335  loss 39.9336  lr 1.000e-03\n",
      "epoch 4336  loss 40.4976  lr 1.000e-03\n",
      "epoch 4337  loss 40.8810  lr 1.000e-03\n",
      "epoch 4338  loss 40.1220  lr 1.000e-03\n",
      "epoch 4339  loss 40.2988  lr 1.000e-03\n",
      "epoch 4340  loss 42.4060  lr 1.000e-03\n",
      "epoch 4341  loss 39.7568  lr 1.000e-03\n",
      "epoch 4342  loss 41.1538  lr 1.000e-03\n",
      "epoch 4343  loss 41.7735  lr 1.000e-03\n",
      "epoch 4344  loss 40.1433  lr 1.000e-03\n",
      "epoch 4345  loss 40.8404  lr 1.000e-03\n",
      "epoch 4346  loss 39.0582  lr 1.000e-03\n",
      "epoch 4347  loss 41.3498  lr 1.000e-03\n",
      "epoch 4348  loss 40.4137  lr 1.000e-03\n",
      "epoch 4349  loss 39.5312  lr 1.000e-03\n",
      "epoch 4350  loss 40.9132  lr 1.000e-03\n",
      "epoch 4351  loss 41.8592  lr 1.000e-03\n",
      "epoch 4352  loss 40.7890  lr 1.000e-03\n",
      "epoch 4353  loss 40.2236  lr 1.000e-03\n",
      "epoch 4354  loss 41.0181  lr 1.000e-03\n",
      "epoch 4355  loss 39.9492  lr 1.000e-03\n",
      "epoch 4356  loss 41.2073  lr 1.000e-03\n",
      "epoch 4357  loss 40.7431  lr 1.000e-03\n",
      "epoch 4358  loss 41.2906  lr 1.000e-03\n",
      "epoch 4359  loss 41.7804  lr 1.000e-03\n",
      "epoch 4360  loss 40.5811  lr 1.000e-03\n",
      "epoch 4361  loss 42.5529  lr 1.000e-03\n",
      "epoch 4362  loss 39.8045  lr 1.000e-03\n",
      "epoch 4363  loss 40.8540  lr 1.000e-03\n",
      "epoch 4364  loss 41.2629  lr 1.000e-03\n",
      "epoch 4365  loss 39.5368  lr 1.000e-03\n",
      "epoch 4366  loss 40.3898  lr 1.000e-03\n",
      "epoch 4367  loss 40.5236  lr 1.000e-03\n",
      "epoch 4368  loss 38.0865  lr 1.000e-03\n",
      "epoch 4369  loss 40.8138  lr 1.000e-03\n",
      "epoch 4370  loss 41.2842  lr 1.000e-03\n",
      "epoch 4371  loss 40.5723  lr 1.000e-03\n",
      "epoch 4372  loss 41.0642  lr 1.000e-03\n",
      "epoch 4373  loss 40.0485  lr 1.000e-03\n",
      "epoch 4374  loss 39.4919  lr 1.000e-03\n",
      "epoch 4375  loss 40.4513  lr 1.000e-03\n",
      "epoch 4376  loss 40.0858  lr 1.000e-03\n",
      "epoch 4377  loss 40.7470  lr 1.000e-03\n",
      "epoch 4378  loss 41.2654  lr 1.000e-03\n",
      "epoch 4379  loss 40.5321  lr 1.000e-03\n",
      "epoch 4380  loss 39.6351  lr 1.000e-03\n",
      "epoch 4381  loss 40.3308  lr 1.000e-03\n",
      "epoch 4382  loss 40.0286  lr 1.000e-03\n",
      "epoch 4383  loss 40.2586  lr 1.000e-03\n",
      "epoch 4384  loss 39.7010  lr 1.000e-03\n",
      "epoch 4385  loss 39.8628  lr 1.000e-03\n",
      "epoch 4386  loss 41.2027  lr 1.000e-03\n",
      "epoch 4387  loss 41.5738  lr 1.000e-03\n",
      "epoch 4388  loss 40.5222  lr 1.000e-03\n",
      "epoch 4389  loss 39.5678  lr 1.000e-03\n",
      "epoch 4390  loss 39.8999  lr 1.000e-03\n",
      "epoch 4391  loss 39.4859  lr 1.000e-03\n",
      "epoch 4392  loss 39.3316  lr 1.000e-03\n",
      "epoch 4393  loss 40.9568  lr 1.000e-03\n",
      "epoch 4394  loss 40.6663  lr 1.000e-03\n",
      "epoch 4395  loss 41.2932  lr 1.000e-03\n",
      "epoch 4396  loss 40.5920  lr 1.000e-03\n",
      "epoch 4397  loss 39.1343  lr 1.000e-03\n",
      "epoch 4398  loss 40.5422  lr 1.000e-03\n",
      "epoch 4399  loss 40.8280  lr 1.000e-03\n",
      "epoch 4400  loss 39.4820  lr 1.000e-03\n",
      "epoch 4401  loss 40.8921  lr 1.000e-03\n",
      "epoch 4402  loss 41.3557  lr 1.000e-03\n",
      "epoch 4403  loss 40.1118  lr 1.000e-03\n",
      "epoch 4404  loss 41.1038  lr 1.000e-03\n",
      "epoch 4405  loss 40.9186  lr 1.000e-03\n",
      "epoch 4406  loss 39.5453  lr 1.000e-03\n",
      "epoch 4407  loss 40.4244  lr 1.000e-03\n",
      "epoch 4408  loss 39.6353  lr 1.000e-03\n",
      "epoch 4409  loss 39.8702  lr 1.000e-03\n",
      "epoch 4410  loss 40.6169  lr 1.000e-03\n",
      "epoch 4411  loss 39.7749  lr 1.000e-03\n",
      "epoch 4412  loss 39.8387  lr 1.000e-03\n",
      "epoch 4413  loss 39.6023  lr 1.000e-03\n",
      "epoch 4414  loss 39.7062  lr 1.000e-03\n",
      "epoch 4415  loss 39.4424  lr 1.000e-03\n",
      "epoch 4416  loss 39.6565  lr 1.000e-03\n",
      "epoch 4417  loss 40.8603  lr 1.000e-03\n",
      "epoch 4418  loss 40.5701  lr 1.000e-03\n",
      "epoch 4419  loss 39.8154  lr 1.000e-03\n",
      "epoch 4420  loss 42.8766  lr 1.000e-03\n",
      "epoch 4421  loss 39.9713  lr 1.000e-03\n",
      "epoch 4422  loss 40.9565  lr 1.000e-03\n",
      "epoch 4423  loss 39.6663  lr 1.000e-03\n",
      "epoch 4424  loss 41.6063  lr 1.000e-03\n",
      "epoch 4425  loss 39.5123  lr 1.000e-03\n",
      "epoch 4426  loss 40.2933  lr 1.000e-03\n",
      "epoch 4427  loss 39.8206  lr 1.000e-03\n",
      "epoch 4428  loss 41.1515  lr 1.000e-03\n",
      "epoch 4429  loss 40.9543  lr 1.000e-03\n",
      "epoch 4430  loss 41.1695  lr 1.000e-03\n",
      "epoch 4431  loss 41.0380  lr 1.000e-03\n",
      "epoch 4432  loss 39.6999  lr 1.000e-03\n",
      "epoch 4433  loss 41.7281  lr 1.000e-03\n",
      "epoch 4434  loss 40.3721  lr 1.000e-03\n",
      "epoch 4435  loss 40.5386  lr 1.000e-03\n",
      "epoch 4436  loss 38.5507  lr 1.000e-03\n",
      "epoch 4437  loss 40.8517  lr 1.000e-03\n",
      "epoch 4438  loss 40.3974  lr 1.000e-03\n",
      "epoch 4439  loss 42.0825  lr 1.000e-03\n",
      "epoch 4440  loss 40.5299  lr 1.000e-03\n",
      "epoch 4441  loss 39.8989  lr 1.000e-03\n",
      "epoch 4442  loss 39.9437  lr 1.000e-03\n",
      "epoch 4443  loss 40.8786  lr 1.000e-03\n",
      "epoch 4444  loss 41.7200  lr 1.000e-03\n",
      "epoch 4445  loss 40.6611  lr 1.000e-03\n",
      "epoch 4446  loss 39.3652  lr 1.000e-03\n",
      "epoch 4447  loss 40.0633  lr 1.000e-03\n",
      "epoch 4448  loss 39.7921  lr 1.000e-03\n",
      "epoch 4449  loss 39.8570  lr 1.000e-03\n",
      "epoch 4450  loss 39.2358  lr 1.000e-03\n",
      "epoch 4451  loss 41.5198  lr 1.000e-03\n",
      "epoch 4452  loss 40.2550  lr 1.000e-03\n",
      "epoch 4453  loss 41.1271  lr 1.000e-03\n",
      "epoch 4454  loss 39.5115  lr 1.000e-03\n",
      "epoch 4455  loss 40.2466  lr 1.000e-03\n",
      "epoch 4456  loss 40.2136  lr 1.000e-03\n",
      "epoch 4457  loss 40.0940  lr 1.000e-03\n",
      "epoch 4458  loss 40.6504  lr 1.000e-03\n",
      "epoch 4459  loss 42.0809  lr 1.000e-03\n",
      "epoch 4460  loss 40.4772  lr 1.000e-03\n",
      "epoch 4461  loss 39.7848  lr 1.000e-03\n",
      "epoch 4462  loss 40.0139  lr 1.000e-03\n",
      "epoch 4463  loss 41.0743  lr 1.000e-03\n",
      "epoch 4464  loss 41.7085  lr 1.000e-03\n",
      "epoch 4465  loss 41.3040  lr 1.000e-03\n",
      "epoch 4466  loss 40.5613  lr 1.000e-03\n",
      "epoch 4467  loss 39.7237  lr 1.000e-03\n",
      "epoch 4468  loss 39.1802  lr 1.000e-03\n",
      "epoch 4469  loss 39.7388  lr 1.000e-03\n",
      "epoch 4470  loss 39.3576  lr 1.000e-03\n",
      "epoch 4471  loss 41.0516  lr 1.000e-03\n",
      "epoch 4472  loss 39.6513  lr 1.000e-03\n",
      "epoch 4473  loss 40.0411  lr 1.000e-03\n",
      "epoch 4474  loss 40.8211  lr 1.000e-03\n",
      "epoch 4475  loss 40.3337  lr 1.000e-03\n",
      "epoch 4476  loss 40.8634  lr 1.000e-03\n",
      "epoch 4477  loss 39.5661  lr 1.000e-03\n",
      "epoch 4478  loss 40.8816  lr 1.000e-03\n",
      "epoch 4479  loss 40.1076  lr 1.000e-03\n",
      "epoch 4480  loss 40.0749  lr 1.000e-03\n",
      "epoch 4481  loss 42.0516  lr 1.000e-03\n",
      "epoch 4482  loss 38.7504  lr 1.000e-03\n",
      "epoch 4483  loss 40.7773  lr 1.000e-03\n",
      "epoch 4484  loss 41.8755  lr 1.000e-03\n",
      "epoch 4485  loss 39.5568  lr 1.000e-03\n",
      "epoch 4486  loss 40.6497  lr 1.000e-03\n",
      "epoch 4487  loss 40.0824  lr 1.000e-03\n",
      "epoch 4488  loss 39.2137  lr 1.000e-03\n",
      "epoch 4489  loss 39.6630  lr 1.000e-03\n",
      "epoch 4490  loss 39.9305  lr 1.000e-03\n",
      "epoch 4491  loss 39.7370  lr 1.000e-03\n",
      "epoch 4492  loss 42.0416  lr 1.000e-03\n",
      "epoch 4493  loss 40.9241  lr 1.000e-03\n",
      "epoch 4494  loss 39.5671  lr 1.000e-03\n",
      "epoch 4495  loss 38.7897  lr 1.000e-03\n",
      "epoch 4496  loss 39.0870  lr 1.000e-03\n",
      "epoch 4497  loss 39.3241  lr 1.000e-03\n",
      "epoch 4498  loss 40.4282  lr 1.000e-03\n",
      "epoch 4499  loss 38.7815  lr 1.000e-03\n",
      "epoch 4500  loss 38.8672  lr 1.000e-03\n",
      "epoch 4501  loss 40.4766  lr 1.000e-03\n",
      "epoch 4502  loss 40.8209  lr 1.000e-03\n",
      "epoch 4503  loss 39.3719  lr 1.000e-03\n",
      "epoch 4504  loss 38.6483  lr 1.000e-03\n",
      "epoch 4505  loss 40.0184  lr 1.000e-03\n",
      "epoch 4506  loss 39.5919  lr 1.000e-03\n",
      "epoch 4507  loss 40.3072  lr 1.000e-03\n",
      "epoch 4508  loss 40.5518  lr 1.000e-03\n",
      "epoch 4509  loss 40.3401  lr 1.000e-03\n",
      "epoch 4510  loss 40.5112  lr 1.000e-03\n",
      "epoch 4511  loss 39.3512  lr 1.000e-03\n",
      "epoch 4512  loss 38.8986  lr 1.000e-03\n",
      "epoch 4513  loss 39.5754  lr 1.000e-03\n",
      "epoch 4514  loss 40.6932  lr 1.000e-03\n",
      "epoch 4515  loss 42.3001  lr 1.000e-03\n",
      "epoch 4516  loss 41.0930  lr 1.000e-03\n",
      "epoch 4517  loss 39.9246  lr 1.000e-03\n",
      "epoch 4518  loss 40.5312  lr 1.000e-03\n",
      "epoch 4519  loss 40.9993  lr 1.000e-03\n",
      "epoch 4520  loss 39.5651  lr 1.000e-03\n",
      "epoch 4521  loss 39.9659  lr 1.000e-03\n",
      "epoch 4522  loss 38.5843  lr 1.000e-03\n",
      "epoch 4523  loss 40.3756  lr 1.000e-03\n",
      "epoch 4524  loss 38.6378  lr 1.000e-03\n",
      "epoch 4525  loss 39.6330  lr 1.000e-03\n",
      "epoch 4526  loss 39.6498  lr 1.000e-03\n",
      "epoch 4527  loss 39.9061  lr 1.000e-03\n",
      "epoch 4528  loss 39.5817  lr 1.000e-03\n",
      "epoch 4529  loss 42.1542  lr 1.000e-03\n",
      "epoch 4530  loss 39.7718  lr 1.000e-03\n",
      "epoch 4531  loss 40.9871  lr 1.000e-03\n",
      "epoch 4532  loss 37.9612  lr 1.000e-03\n",
      "epoch 4533  loss 39.2736  lr 1.000e-03\n",
      "epoch 4534  loss 39.9009  lr 1.000e-03\n",
      "epoch 4535  loss 40.7463  lr 1.000e-03\n",
      "epoch 4536  loss 40.3988  lr 1.000e-03\n",
      "epoch 4537  loss 39.8272  lr 1.000e-03\n",
      "epoch 4538  loss 39.2673  lr 1.000e-03\n",
      "epoch 4539  loss 38.7254  lr 1.000e-03\n",
      "epoch 4540  loss 38.4173  lr 1.000e-03\n",
      "epoch 4541  loss 40.6439  lr 1.000e-03\n",
      "epoch 4542  loss 40.1597  lr 1.000e-03\n",
      "epoch 4543  loss 39.0767  lr 1.000e-03\n",
      "epoch 4544  loss 39.7685  lr 1.000e-03\n",
      "epoch 4545  loss 40.2150  lr 1.000e-03\n",
      "epoch 4546  loss 39.7982  lr 1.000e-03\n",
      "epoch 4547  loss 40.2415  lr 1.000e-03\n",
      "epoch 4548  loss 40.2141  lr 1.000e-03\n",
      "epoch 4549  loss 40.0490  lr 1.000e-03\n",
      "epoch 4550  loss 41.7761  lr 1.000e-03\n",
      "epoch 4551  loss 40.7252  lr 1.000e-03\n",
      "epoch 4552  loss 40.5976  lr 1.000e-03\n",
      "epoch 4553  loss 40.4428  lr 1.000e-03\n",
      "epoch 4554  loss 40.3265  lr 1.000e-03\n",
      "epoch 4555  loss 40.5106  lr 1.000e-03\n",
      "epoch 4556  loss 41.8434  lr 1.000e-03\n",
      "epoch 4557  loss 39.4579  lr 1.000e-03\n",
      "epoch 4558  loss 40.8158  lr 1.000e-03\n",
      "epoch 4559  loss 41.6021  lr 1.000e-03\n",
      "epoch 4560  loss 39.7263  lr 1.000e-03\n",
      "epoch 4561  loss 39.8161  lr 1.000e-03\n",
      "epoch 4562  loss 39.0567  lr 1.000e-03\n",
      "epoch 4563  loss 39.9371  lr 1.000e-03\n",
      "epoch 4564  loss 38.9584  lr 1.000e-03\n",
      "epoch 4565  loss 38.9663  lr 1.000e-03\n",
      "epoch 4566  loss 38.9186  lr 1.000e-03\n",
      "epoch 4567  loss 38.9053  lr 1.000e-03\n",
      "epoch 4568  loss 39.6013  lr 1.000e-03\n",
      "epoch 4569  loss 40.3099  lr 1.000e-03\n",
      "epoch 4570  loss 40.8677  lr 1.000e-03\n",
      "epoch 4571  loss 40.6053  lr 1.000e-03\n",
      "epoch 4572  loss 40.1546  lr 1.000e-03\n",
      "epoch 4573  loss 39.2556  lr 1.000e-03\n",
      "epoch 4574  loss 40.2178  lr 1.000e-03\n",
      "epoch 4575  loss 41.0727  lr 1.000e-03\n",
      "epoch 4576  loss 40.4698  lr 1.000e-03\n",
      "epoch 4577  loss 39.6695  lr 1.000e-03\n",
      "epoch 4578  loss 40.4464  lr 1.000e-03\n",
      "epoch 4579  loss 40.2634  lr 1.000e-03\n",
      "epoch 4580  loss 40.1729  lr 1.000e-03\n",
      "epoch 4581  loss 39.8731  lr 1.000e-03\n",
      "epoch 4582  loss 38.2872  lr 1.000e-03\n",
      "epoch 4583  loss 39.4896  lr 1.000e-03\n",
      "epoch 4584  loss 38.9155  lr 1.000e-03\n",
      "epoch 4585  loss 41.4057  lr 1.000e-03\n",
      "epoch 4586  loss 40.0348  lr 1.000e-03\n",
      "epoch 4587  loss 41.5235  lr 1.000e-03\n",
      "epoch 4588  loss 39.1987  lr 1.000e-03\n",
      "epoch 4589  loss 41.6305  lr 1.000e-03\n",
      "epoch 4590  loss 41.5935  lr 1.000e-03\n",
      "epoch 4591  loss 41.0890  lr 1.000e-03\n",
      "epoch 4592  loss 40.7059  lr 1.000e-03\n",
      "epoch 4593  loss 40.5853  lr 1.000e-03\n",
      "epoch 4594  loss 40.0686  lr 1.000e-03\n",
      "epoch 4595  loss 40.4057  lr 1.000e-03\n",
      "epoch 4596  loss 41.1909  lr 1.000e-03\n",
      "epoch 4597  loss 39.4498  lr 1.000e-03\n",
      "epoch 4598  loss 38.9830  lr 1.000e-03\n",
      "epoch 4599  loss 40.3470  lr 1.000e-03\n",
      "epoch 4600  loss 39.5280  lr 1.000e-03\n",
      "epoch 4601  loss 40.9852  lr 1.000e-03\n",
      "epoch 4602  loss 39.1459  lr 1.000e-03\n",
      "epoch 4603  loss 38.8642  lr 1.000e-03\n",
      "epoch 4604  loss 39.9886  lr 1.000e-03\n",
      "epoch 4605  loss 39.7013  lr 1.000e-03\n",
      "epoch 4606  loss 41.3776  lr 1.000e-03\n",
      "epoch 4607  loss 39.2785  lr 1.000e-03\n",
      "epoch 4608  loss 40.8223  lr 1.000e-03\n",
      "epoch 4609  loss 39.5451  lr 1.000e-03\n",
      "epoch 4610  loss 39.1121  lr 1.000e-03\n",
      "epoch 4611  loss 39.1645  lr 1.000e-03\n",
      "epoch 4612  loss 39.9381  lr 1.000e-03\n",
      "epoch 4613  loss 39.8199  lr 1.000e-03\n",
      "epoch 4614  loss 42.2786  lr 1.000e-03\n",
      "epoch 4615  loss 40.7069  lr 1.000e-03\n",
      "epoch 4616  loss 40.3832  lr 1.000e-03\n",
      "epoch 4617  loss 38.3731  lr 1.000e-03\n",
      "epoch 4618  loss 39.8604  lr 1.000e-03\n",
      "epoch 4619  loss 38.9894  lr 1.000e-03\n",
      "epoch 4620  loss 40.5977  lr 1.000e-03\n",
      "epoch 4621  loss 40.2839  lr 1.000e-03\n",
      "epoch 4622  loss 40.4730  lr 1.000e-03\n",
      "epoch 4623  loss 42.7968  lr 1.000e-03\n",
      "epoch 4624  loss 39.9604  lr 1.000e-03\n",
      "epoch 4625  loss 40.1746  lr 1.000e-03\n",
      "epoch 4626  loss 40.1198  lr 1.000e-03\n",
      "epoch 4627  loss 39.3243  lr 1.000e-03\n",
      "epoch 4628  loss 39.1818  lr 1.000e-03\n",
      "epoch 4629  loss 39.6244  lr 1.000e-03\n",
      "epoch 4630  loss 42.4869  lr 1.000e-03\n",
      "epoch 4631  loss 39.9785  lr 1.000e-03\n",
      "epoch 4632  loss 39.7980  lr 1.000e-03\n",
      "epoch 4633  loss 39.7808  lr 1.000e-03\n",
      "epoch 4634  loss 40.7676  lr 1.000e-03\n",
      "epoch 4635  loss 39.5985  lr 1.000e-03\n",
      "epoch 4636  loss 39.4336  lr 1.000e-03\n",
      "epoch 4637  loss 39.5741  lr 1.000e-03\n",
      "epoch 4638  loss 36.6451  lr 1.000e-03\n",
      "epoch 4639  loss 40.8698  lr 1.000e-03\n",
      "epoch 4640  loss 39.6003  lr 1.000e-03\n",
      "epoch 4641  loss 39.5171  lr 1.000e-03\n",
      "epoch 4642  loss 39.9017  lr 1.000e-03\n",
      "epoch 4643  loss 38.5317  lr 1.000e-03\n",
      "epoch 4644  loss 38.7271  lr 1.000e-03\n",
      "epoch 4645  loss 40.2376  lr 1.000e-03\n",
      "epoch 4646  loss 40.0579  lr 1.000e-03\n",
      "epoch 4647  loss 41.3746  lr 1.000e-03\n",
      "epoch 4648  loss 38.1810  lr 1.000e-03\n",
      "epoch 4649  loss 40.2127  lr 1.000e-03\n",
      "epoch 4650  loss 39.7423  lr 1.000e-03\n",
      "epoch 4651  loss 38.8984  lr 1.000e-03\n",
      "epoch 4652  loss 41.1974  lr 1.000e-03\n",
      "epoch 4653  loss 40.3658  lr 1.000e-03\n",
      "epoch 4654  loss 40.4491  lr 1.000e-03\n",
      "epoch 4655  loss 40.6581  lr 1.000e-03\n",
      "epoch 4656  loss 38.5045  lr 1.000e-03\n",
      "epoch 4657  loss 39.5781  lr 1.000e-03\n",
      "epoch 4658  loss 38.1364  lr 1.000e-03\n",
      "epoch 4659  loss 39.6102  lr 1.000e-03\n",
      "epoch 4660  loss 39.3613  lr 1.000e-03\n",
      "epoch 4661  loss 39.4072  lr 1.000e-03\n",
      "epoch 4662  loss 39.5936  lr 1.000e-03\n",
      "epoch 4663  loss 41.2904  lr 1.000e-03\n",
      "epoch 4664  loss 41.3098  lr 1.000e-03\n",
      "epoch 4665  loss 40.0295  lr 1.000e-03\n",
      "epoch 4666  loss 40.7630  lr 1.000e-03\n",
      "epoch 4667  loss 39.8412  lr 1.000e-03\n",
      "epoch 4668  loss 39.9666  lr 1.000e-03\n",
      "epoch 4669  loss 38.4706  lr 1.000e-03\n",
      "epoch 4670  loss 40.8633  lr 1.000e-03\n",
      "epoch 4671  loss 40.3871  lr 1.000e-03\n",
      "epoch 4672  loss 40.3155  lr 1.000e-03\n",
      "epoch 4673  loss 38.4400  lr 1.000e-03\n",
      "epoch 4674  loss 39.9065  lr 1.000e-03\n",
      "epoch 4675  loss 39.3614  lr 1.000e-03\n",
      "epoch 4676  loss 41.0293  lr 1.000e-03\n",
      "epoch 4677  loss 41.0779  lr 1.000e-03\n",
      "epoch 4678  loss 39.5469  lr 1.000e-03\n",
      "epoch 4679  loss 40.4521  lr 1.000e-03\n",
      "epoch 4680  loss 39.8529  lr 1.000e-03\n",
      "epoch 4681  loss 39.2962  lr 1.000e-03\n",
      "epoch 4682  loss 38.8317  lr 1.000e-03\n",
      "epoch 4683  loss 40.0608  lr 1.000e-03\n",
      "epoch 4684  loss 38.2975  lr 1.000e-03\n",
      "epoch 4685  loss 40.4053  lr 1.000e-03\n",
      "epoch 4686  loss 39.9731  lr 1.000e-03\n",
      "epoch 4687  loss 40.0768  lr 1.000e-03\n",
      "epoch 4688  loss 40.6307  lr 1.000e-03\n",
      "epoch 4689  loss 39.1199  lr 1.000e-03\n",
      "epoch 4690  loss 38.4827  lr 1.000e-03\n",
      "epoch 4691  loss 39.3940  lr 1.000e-03\n",
      "epoch 4692  loss 39.5666  lr 1.000e-03\n",
      "epoch 4693  loss 39.3328  lr 1.000e-03\n",
      "epoch 4694  loss 39.8582  lr 1.000e-03\n",
      "epoch 4695  loss 39.7203  lr 1.000e-03\n",
      "epoch 4696  loss 40.5485  lr 1.000e-03\n",
      "epoch 4697  loss 39.6850  lr 1.000e-03\n",
      "epoch 4698  loss 42.7820  lr 1.000e-03\n",
      "epoch 4699  loss 39.7119  lr 1.000e-03\n",
      "epoch 4700  loss 39.9207  lr 1.000e-03\n",
      "epoch 4701  loss 40.5690  lr 1.000e-03\n",
      "epoch 4702  loss 39.8791  lr 1.000e-03\n",
      "epoch 4703  loss 39.7523  lr 1.000e-03\n",
      "epoch 4704  loss 40.0275  lr 1.000e-03\n",
      "epoch 4705  loss 41.8782  lr 1.000e-03\n",
      "epoch 4706  loss 40.4139  lr 1.000e-03\n",
      "epoch 4707  loss 39.0697  lr 1.000e-03\n",
      "epoch 4708  loss 41.0434  lr 1.000e-03\n",
      "epoch 4709  loss 40.0267  lr 1.000e-03\n",
      "epoch 4710  loss 40.3022  lr 1.000e-03\n",
      "epoch 4711  loss 41.5574  lr 1.000e-03\n",
      "epoch 4712  loss 39.2368  lr 1.000e-03\n",
      "epoch 4713  loss 40.3996  lr 1.000e-03\n",
      "epoch 4714  loss 39.3610  lr 1.000e-03\n",
      "epoch 4715  loss 39.8216  lr 1.000e-03\n",
      "epoch 4716  loss 40.3197  lr 1.000e-03\n",
      "epoch 4717  loss 39.2897  lr 1.000e-03\n",
      "epoch 4718  loss 39.4615  lr 1.000e-03\n",
      "epoch 4719  loss 40.6425  lr 1.000e-03\n",
      "epoch 4720  loss 38.4828  lr 1.000e-03\n",
      "epoch 4721  loss 40.2462  lr 1.000e-03\n",
      "epoch 4722  loss 39.6472  lr 1.000e-03\n",
      "epoch 4723  loss 38.5603  lr 1.000e-03\n",
      "epoch 4724  loss 39.7667  lr 1.000e-03\n",
      "epoch 4725  loss 39.5476  lr 1.000e-03\n",
      "epoch 4726  loss 38.8895  lr 1.000e-03\n",
      "epoch 4727  loss 40.7765  lr 1.000e-03\n",
      "epoch 4728  loss 40.2680  lr 1.000e-03\n",
      "epoch 4729  loss 38.9580  lr 1.000e-03\n",
      "epoch 4730  loss 39.6911  lr 1.000e-03\n",
      "epoch 4731  loss 40.9713  lr 1.000e-03\n",
      "epoch 4732  loss 39.7548  lr 1.000e-03\n",
      "epoch 4733  loss 39.7152  lr 1.000e-03\n",
      "epoch 4734  loss 38.4423  lr 1.000e-03\n",
      "epoch 4735  loss 39.6118  lr 1.000e-03\n",
      "epoch 4736  loss 38.6481  lr 1.000e-03\n",
      "epoch 4737  loss 38.6238  lr 1.000e-03\n",
      "epoch 4738  loss 38.6778  lr 1.000e-03\n",
      "epoch 4739  loss 38.9049  lr 1.000e-03\n",
      "epoch 4740  loss 39.2719  lr 1.000e-03\n",
      "epoch 4741  loss 40.3548  lr 1.000e-03\n",
      "epoch 4742  loss 39.6628  lr 1.000e-03\n",
      "epoch 4743  loss 40.7212  lr 1.000e-03\n",
      "epoch 4744  loss 39.1087  lr 1.000e-03\n",
      "epoch 4745  loss 39.7384  lr 1.000e-03\n",
      "epoch 4746  loss 40.5630  lr 1.000e-03\n",
      "epoch 4747  loss 40.8058  lr 1.000e-03\n",
      "epoch 4748  loss 41.7411  lr 1.000e-03\n",
      "epoch 4749  loss 40.4338  lr 1.000e-03\n",
      "epoch 4750  loss 40.0341  lr 1.000e-03\n",
      "epoch 4751  loss 39.5722  lr 1.000e-03\n",
      "epoch 4752  loss 40.4452  lr 1.000e-03\n",
      "epoch 4753  loss 38.9918  lr 1.000e-03\n",
      "epoch 4754  loss 40.5542  lr 1.000e-03\n",
      "epoch 4755  loss 40.0989  lr 1.000e-03\n",
      "epoch 4756  loss 39.9092  lr 1.000e-03\n",
      "epoch 4757  loss 38.2715  lr 1.000e-03\n",
      "epoch 4758  loss 38.8005  lr 1.000e-03\n",
      "epoch 4759  loss 38.4419  lr 1.000e-03\n",
      "epoch 4760  loss 39.8893  lr 1.000e-03\n",
      "epoch 4761  loss 42.3638  lr 1.000e-03\n",
      "epoch 4762  loss 40.3427  lr 1.000e-03\n",
      "epoch 4763  loss 39.2570  lr 1.000e-03\n",
      "epoch 4764  loss 41.2179  lr 1.000e-03\n",
      "epoch 4765  loss 39.3999  lr 1.000e-03\n",
      "epoch 4766  loss 40.2158  lr 1.000e-03\n",
      "epoch 4767  loss 39.7380  lr 1.000e-03\n",
      "epoch 4768  loss 40.3943  lr 1.000e-03\n",
      "epoch 4769  loss 39.2578  lr 1.000e-03\n",
      "epoch 4770  loss 41.8835  lr 1.000e-03\n",
      "epoch 4771  loss 39.0355  lr 1.000e-03\n",
      "epoch 4772  loss 40.6708  lr 1.000e-03\n",
      "epoch 4773  loss 40.9108  lr 1.000e-03\n",
      "epoch 4774  loss 38.8188  lr 1.000e-03\n",
      "epoch 4775  loss 38.3195  lr 1.000e-03\n",
      "epoch 4776  loss 39.3912  lr 1.000e-03\n",
      "epoch 4777  loss 40.5757  lr 1.000e-03\n",
      "epoch 4778  loss 40.7448  lr 1.000e-03\n",
      "epoch 4779  loss 40.1508  lr 1.000e-03\n",
      "epoch 4780  loss 40.6874  lr 1.000e-03\n",
      "epoch 4781  loss 39.6650  lr 1.000e-03\n",
      "epoch 4782  loss 41.2267  lr 1.000e-03\n",
      "epoch 4783  loss 39.4788  lr 1.000e-03\n",
      "epoch 4784  loss 38.6908  lr 1.000e-03\n",
      "epoch 4785  loss 39.5649  lr 1.000e-03\n",
      "epoch 4786  loss 39.8953  lr 1.000e-03\n",
      "epoch 4787  loss 38.1941  lr 1.000e-03\n",
      "epoch 4788  loss 39.9599  lr 1.000e-03\n",
      "epoch 4789  loss 40.3363  lr 1.000e-03\n",
      "epoch 4790  loss 39.0886  lr 1.000e-03\n",
      "epoch 4791  loss 38.2855  lr 1.000e-03\n",
      "epoch 4792  loss 38.3153  lr 1.000e-03\n",
      "epoch 4793  loss 39.1034  lr 1.000e-03\n",
      "epoch 4794  loss 40.9630  lr 1.000e-03\n",
      "epoch 4795  loss 39.4936  lr 1.000e-03\n",
      "epoch 4796  loss 39.3802  lr 1.000e-03\n",
      "epoch 4797  loss 39.3156  lr 1.000e-03\n",
      "epoch 4798  loss 38.7134  lr 1.000e-03\n",
      "epoch 4799  loss 38.6712  lr 1.000e-03\n",
      "epoch 4800  loss 39.6389  lr 1.000e-03\n",
      "epoch 4801  loss 40.3605  lr 1.000e-03\n",
      "epoch 4802  loss 39.3045  lr 1.000e-03\n",
      "epoch 4803  loss 39.6065  lr 1.000e-03\n",
      "epoch 4804  loss 40.4195  lr 1.000e-03\n",
      "epoch 4805  loss 39.5746  lr 1.000e-03\n",
      "epoch 4806  loss 39.7570  lr 1.000e-03\n",
      "epoch 4807  loss 39.0186  lr 1.000e-03\n",
      "epoch 4808  loss 40.1549  lr 1.000e-03\n",
      "epoch 4809  loss 38.4977  lr 1.000e-03\n",
      "epoch 4810  loss 38.4878  lr 1.000e-03\n",
      "epoch 4811  loss 40.0449  lr 1.000e-03\n",
      "epoch 4812  loss 39.8700  lr 1.000e-03\n",
      "epoch 4813  loss 39.5423  lr 1.000e-03\n",
      "epoch 4814  loss 41.0454  lr 1.000e-03\n",
      "epoch 4815  loss 39.9165  lr 1.000e-03\n",
      "epoch 4816  loss 40.0792  lr 1.000e-03\n",
      "epoch 4817  loss 39.1800  lr 1.000e-03\n",
      "epoch 4818  loss 39.1237  lr 1.000e-03\n",
      "epoch 4819  loss 39.7814  lr 1.000e-03\n",
      "epoch 4820  loss 38.2213  lr 1.000e-03\n",
      "epoch 4821  loss 39.9636  lr 1.000e-03\n",
      "epoch 4822  loss 39.4759  lr 1.000e-03\n",
      "epoch 4823  loss 38.0044  lr 1.000e-03\n",
      "epoch 4824  loss 38.0449  lr 1.000e-03\n",
      "epoch 4825  loss 39.1702  lr 1.000e-03\n",
      "epoch 4826  loss 40.0825  lr 1.000e-03\n",
      "epoch 4827  loss 39.3808  lr 1.000e-03\n",
      "epoch 4828  loss 39.3625  lr 1.000e-03\n",
      "epoch 4829  loss 40.1426  lr 1.000e-03\n",
      "epoch 4830  loss 39.4841  lr 1.000e-03\n",
      "epoch 4831  loss 38.9942  lr 1.000e-03\n",
      "epoch 4832  loss 39.6805  lr 1.000e-03\n",
      "epoch 4833  loss 39.6567  lr 1.000e-03\n",
      "epoch 4834  loss 38.1762  lr 1.000e-03\n",
      "epoch 4835  loss 41.4549  lr 1.000e-03\n",
      "epoch 4836  loss 38.9503  lr 1.000e-03\n",
      "epoch 4837  loss 38.2869  lr 1.000e-03\n",
      "epoch 4838  loss 39.0466  lr 1.000e-03\n",
      "epoch 4839  loss 38.5525  lr 1.000e-03\n",
      "epoch 4840  loss 39.8150  lr 1.000e-03\n",
      "epoch 4841  loss 39.6839  lr 1.000e-03\n",
      "epoch 4842  loss 41.2107  lr 1.000e-03\n",
      "epoch 4843  loss 40.1072  lr 1.000e-03\n",
      "epoch 4844  loss 38.3992  lr 1.000e-03\n",
      "epoch 4845  loss 38.8289  lr 1.000e-03\n",
      "epoch 4846  loss 39.6902  lr 1.000e-03\n",
      "epoch 4847  loss 39.9030  lr 1.000e-03\n",
      "epoch 4848  loss 38.9187  lr 1.000e-03\n",
      "epoch 4849  loss 40.9551  lr 1.000e-03\n",
      "epoch 4850  loss 40.3324  lr 1.000e-03\n",
      "epoch 4851  loss 38.7452  lr 1.000e-03\n",
      "epoch 4852  loss 38.8789  lr 1.000e-03\n",
      "epoch 4853  loss 39.2840  lr 1.000e-03\n",
      "epoch 4854  loss 39.4128  lr 1.000e-03\n",
      "epoch 4855  loss 39.9190  lr 1.000e-03\n",
      "epoch 4856  loss 38.3892  lr 1.000e-03\n",
      "epoch 4857  loss 38.9862  lr 1.000e-03\n",
      "epoch 4858  loss 39.7109  lr 1.000e-03\n",
      "epoch 4859  loss 39.3491  lr 1.000e-03\n",
      "epoch 4860  loss 39.5678  lr 1.000e-03\n",
      "epoch 4861  loss 38.5439  lr 1.000e-03\n",
      "epoch 4862  loss 39.3321  lr 1.000e-03\n",
      "epoch 4863  loss 38.3383  lr 1.000e-03\n",
      "epoch 4864  loss 40.7179  lr 1.000e-03\n",
      "epoch 4865  loss 40.5946  lr 1.000e-03\n",
      "epoch 4866  loss 39.5015  lr 1.000e-03\n",
      "epoch 4867  loss 38.7192  lr 1.000e-03\n",
      "epoch 4868  loss 38.4927  lr 1.000e-03\n",
      "epoch 4869  loss 38.9615  lr 1.000e-03\n",
      "epoch 4870  loss 39.1757  lr 1.000e-03\n",
      "epoch 4871  loss 41.4813  lr 1.000e-03\n",
      "epoch 4872  loss 39.8976  lr 1.000e-03\n",
      "epoch 4873  loss 39.3190  lr 1.000e-03\n",
      "epoch 4874  loss 38.8874  lr 1.000e-03\n",
      "epoch 4875  loss 40.6807  lr 1.000e-03\n",
      "epoch 4876  loss 39.6293  lr 1.000e-03\n",
      "epoch 4877  loss 39.1902  lr 1.000e-03\n",
      "epoch 4878  loss 39.8129  lr 1.000e-03\n",
      "epoch 4879  loss 38.1375  lr 1.000e-03\n",
      "epoch 4880  loss 40.1101  lr 1.000e-03\n",
      "epoch 4881  loss 38.2488  lr 1.000e-03\n",
      "epoch 4882  loss 39.2681  lr 1.000e-03\n",
      "epoch 4883  loss 38.9857  lr 1.000e-03\n",
      "epoch 4884  loss 38.4064  lr 1.000e-03\n",
      "epoch 4885  loss 38.5604  lr 1.000e-03\n",
      "epoch 4886  loss 41.1131  lr 1.000e-03\n",
      "epoch 4887  loss 40.1940  lr 1.000e-03\n",
      "epoch 4888  loss 40.6976  lr 1.000e-03\n",
      "epoch 4889  loss 39.7535  lr 1.000e-03\n",
      "epoch 4890  loss 39.4328  lr 1.000e-03\n",
      "epoch 4891  loss 40.2880  lr 1.000e-03\n",
      "epoch 4892  loss 43.3662  lr 1.000e-03\n",
      "epoch 4893  loss 40.2358  lr 1.000e-03\n",
      "epoch 4894  loss 38.9332  lr 1.000e-03\n",
      "epoch 4895  loss 39.9899  lr 1.000e-03\n",
      "epoch 4896  loss 38.9534  lr 1.000e-03\n",
      "epoch 4897  loss 40.2631  lr 1.000e-03\n",
      "epoch 4898  loss 39.0061  lr 1.000e-03\n",
      "epoch 4899  loss 38.4601  lr 1.000e-03\n",
      "epoch 4900  loss 39.5509  lr 1.000e-03\n",
      "epoch 4901  loss 39.3208  lr 1.000e-03\n",
      "epoch 4902  loss 39.2386  lr 1.000e-03\n",
      "epoch 4903  loss 39.3164  lr 1.000e-03\n",
      "epoch 4904  loss 39.7982  lr 1.000e-03\n",
      "epoch 4905  loss 38.4396  lr 1.000e-03\n",
      "epoch 4906  loss 39.7474  lr 1.000e-03\n",
      "epoch 4907  loss 38.6956  lr 1.000e-03\n",
      "epoch 4908  loss 39.7156  lr 1.000e-03\n",
      "epoch 4909  loss 39.9843  lr 1.000e-03\n",
      "epoch 4910  loss 40.0817  lr 1.000e-03\n",
      "epoch 4911  loss 40.5195  lr 1.000e-03\n",
      "epoch 4912  loss 40.8346  lr 1.000e-03\n",
      "epoch 4913  loss 41.0516  lr 1.000e-03\n",
      "epoch 4914  loss 39.2149  lr 1.000e-03\n",
      "epoch 4915  loss 38.4625  lr 1.000e-03\n",
      "epoch 4916  loss 40.2519  lr 1.000e-03\n",
      "epoch 4917  loss 40.6637  lr 1.000e-03\n",
      "epoch 4918  loss 38.6468  lr 1.000e-03\n",
      "epoch 4919  loss 40.1692  lr 1.000e-03\n",
      "epoch 4920  loss 39.1957  lr 1.000e-03\n",
      "epoch 4921  loss 39.7686  lr 1.000e-03\n",
      "epoch 4922  loss 38.4172  lr 1.000e-03\n",
      "epoch 4923  loss 39.2378  lr 1.000e-03\n",
      "epoch 4924  loss 39.2644  lr 1.000e-03\n",
      "epoch 4925  loss 40.9162  lr 1.000e-03\n",
      "epoch 4926  loss 39.7831  lr 1.000e-03\n",
      "epoch 4927  loss 40.1928  lr 1.000e-03\n",
      "epoch 4928  loss 39.7742  lr 1.000e-03\n",
      "epoch 4929  loss 39.4113  lr 1.000e-03\n",
      "epoch 4930  loss 39.3193  lr 1.000e-03\n",
      "epoch 4931  loss 39.1057  lr 1.000e-03\n",
      "epoch 4932  loss 38.0413  lr 1.000e-03\n",
      "epoch 4933  loss 39.8697  lr 1.000e-03\n",
      "epoch 4934  loss 39.4950  lr 1.000e-03\n",
      "epoch 4935  loss 38.7432  lr 1.000e-03\n",
      "epoch 4936  loss 40.6979  lr 1.000e-03\n",
      "epoch 4937  loss 39.4731  lr 1.000e-03\n",
      "epoch 4938  loss 39.6029  lr 1.000e-03\n",
      "epoch 4939  loss 42.0667  lr 1.000e-03\n",
      "epoch 4940  loss 39.1535  lr 1.000e-03\n",
      "epoch 4941  loss 39.1907  lr 1.000e-03\n",
      "epoch 4942  loss 40.3960  lr 1.000e-03\n",
      "epoch 4943  loss 40.7031  lr 1.000e-03\n",
      "epoch 4944  loss 39.4469  lr 1.000e-03\n",
      "epoch 4945  loss 40.4476  lr 1.000e-03\n",
      "epoch 4946  loss 38.7549  lr 1.000e-03\n",
      "epoch 4947  loss 39.6151  lr 1.000e-03\n",
      "epoch 4948  loss 38.7592  lr 1.000e-03\n",
      "epoch 4949  loss 38.1407  lr 1.000e-03\n",
      "epoch 4950  loss 40.4099  lr 1.000e-03\n",
      "epoch 4951  loss 38.0083  lr 1.000e-03\n",
      "epoch 4952  loss 40.0189  lr 1.000e-03\n",
      "epoch 4953  loss 39.4985  lr 1.000e-03\n",
      "epoch 4954  loss 40.5779  lr 1.000e-03\n",
      "epoch 4955  loss 38.3552  lr 1.000e-03\n",
      "epoch 4956  loss 40.2147  lr 1.000e-03\n",
      "epoch 4957  loss 39.0272  lr 1.000e-03\n",
      "epoch 4958  loss 38.0283  lr 1.000e-03\n",
      "epoch 4959  loss 39.8992  lr 1.000e-03\n",
      "epoch 4960  loss 39.2183  lr 1.000e-03\n",
      "epoch 4961  loss 39.2666  lr 1.000e-03\n",
      "epoch 4962  loss 38.4873  lr 1.000e-03\n",
      "epoch 4963  loss 40.8805  lr 1.000e-03\n",
      "epoch 4964  loss 38.9759  lr 1.000e-03\n",
      "epoch 4965  loss 38.5813  lr 1.000e-03\n",
      "epoch 4966  loss 38.4397  lr 1.000e-03\n",
      "epoch 4967  loss 39.1496  lr 1.000e-03\n",
      "epoch 4968  loss 40.0980  lr 1.000e-03\n",
      "epoch 4969  loss 39.8169  lr 1.000e-03\n",
      "epoch 4970  loss 39.1882  lr 1.000e-03\n",
      "epoch 4971  loss 38.0578  lr 1.000e-03\n",
      "epoch 4972  loss 39.7879  lr 1.000e-03\n",
      "epoch 4973  loss 38.6519  lr 1.000e-03\n",
      "epoch 4974  loss 38.5382  lr 1.000e-03\n",
      "epoch 4975  loss 38.8409  lr 1.000e-03\n",
      "epoch 4976  loss 38.9513  lr 1.000e-03\n",
      "epoch 4977  loss 39.0675  lr 1.000e-03\n",
      "epoch 4978  loss 39.2562  lr 1.000e-03\n",
      "epoch 4979  loss 38.8307  lr 1.000e-03\n",
      "epoch 4980  loss 38.5527  lr 1.000e-03\n",
      "epoch 4981  loss 39.0540  lr 1.000e-03\n",
      "epoch 4982  loss 39.6146  lr 1.000e-03\n",
      "epoch 4983  loss 39.7536  lr 1.000e-03\n",
      "epoch 4984  loss 38.4304  lr 1.000e-03\n",
      "epoch 4985  loss 40.8742  lr 1.000e-03\n",
      "epoch 4986  loss 40.9596  lr 1.000e-03\n",
      "epoch 4987  loss 38.9685  lr 1.000e-03\n",
      "epoch 4988  loss 39.0068  lr 1.000e-03\n",
      "epoch 4989  loss 40.7503  lr 1.000e-03\n",
      "epoch 4990  loss 38.6845  lr 1.000e-03\n",
      "epoch 4991  loss 38.7421  lr 1.000e-03\n",
      "epoch 4992  loss 39.0877  lr 1.000e-03\n",
      "epoch 4993  loss 39.4194  lr 1.000e-03\n",
      "epoch 4994  loss 37.3140  lr 1.000e-03\n",
      "epoch 4995  loss 40.0426  lr 1.000e-03\n",
      "epoch 4996  loss 40.0706  lr 1.000e-03\n",
      "epoch 4997  loss 38.8270  lr 1.000e-03\n",
      "epoch 4998  loss 41.9239  lr 1.000e-03\n",
      "epoch 4999  loss 38.9597  lr 1.000e-03\n",
      "epoch 5000  loss 39.6458  lr 1.000e-03\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model = OddShapeDetector().to(device)\n",
    "criterion = nn.MSELoss()                 # regresja współrzędnych\n",
    "optim     = Adam(model.parameters(), lr=0.001) #bylo 0.001\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optim,\n",
    "    mode='min',         # obniżamy stratę\n",
    "    factor=0.5,         # nowy LR = lr * factor\n",
    "    patience=5,         # ile epok czekać na poprawę\n",
    "    min_lr=1e-6         # najniższy dopuszczalny LR\n",
    ")\n",
    "\n",
    "epochs = 5000\n",
    "for ep in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for img, coord in loader:\n",
    "        img, coord = img.to(device), coord.to(device)\n",
    "\n",
    "        pred = model(img)          # [B,2]\n",
    "        loss = criterion(pred, coord)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        running += loss.item() * img.size(0)\n",
    "\n",
    "    #scheduler.step(loss)\n",
    "    lr_now = scheduler.get_last_lr()[0]\n",
    "\n",
    "    print(f\"epoch {ep:2d}  loss {running/len(loader.dataset):.4f}  lr {lr_now:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ea319f-0b60-43b9-9a4b-748b832f5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = 12\n",
    "kernel = 20\n",
    "stride = 4\n",
    "# centers of 20×20 windows, sampled every 4 px\n",
    "yy, xx = torch.meshgrid(\n",
    "torch.arange(grid), torch.arange(grid), indexing=\"ij\"\n",
    ")                                           # [G, G]\n",
    "centers = torch.stack([yy, xx], -1).float() \\\n",
    "                  * stride + (kernel - 1) / 2       # [G, G, 2]\n",
    "# plain tensor; no need for register_buffer in a quick demo\n",
    "centers = centers.reshape(-1, 2)       # [144, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb9db052-ef57-4788-ba3c-c6fe36dde75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = 12\n",
    "kernel = 20\n",
    "stride = 4\n",
    "# centers of 20×20 windows, sampled every 4 px\n",
    "xx, yy = torch.meshgrid(\n",
    "torch.arange(grid), torch.arange(grid), indexing=\"xy\"\n",
    ")                                           # [G, G]\n",
    "centers = torch.stack([xx, yy], -1).float() \\\n",
    "                  * stride + (kernel - 1) / 2       # [G, G, 2]\n",
    "# plain tensor; no need for register_buffer in a quick demo\n",
    "centers = centers.reshape(-1, 2)       # [144, 2]\n",
    "\n",
    "#centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9c6ac75-d5d9-4886-8f6a-dd82c5db477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "662e0b34-2878-423c-a1d3-3cfa09f88acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OddShapeDetector(\n",
       "  (patch): PatchEmbedCNN(\n",
       "    (conv): Conv2d(1, 16, kernel_size=(20, 20), stride=(4, 4))\n",
       "  )\n",
       "  (pos): PositionalEncoding()\n",
       "  (attn): SelfAttention(\n",
       "    (Q): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (K): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (V): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       "  (cls): TokenClassifier(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (sarg): SoftArgmax()\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = torch.load(\"model.pth\", weights_only=False)\n",
    "model3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "172d3868-1a7a-4c92-83d8-e7ef6b8f3334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[22.7468, 48.9914],\n",
      "        [ 9.8323, 52.9796],\n",
      "        [13.8283, 35.9301],\n",
      "        ...,\n",
      "        [42.7816, 19.7308],\n",
      "        [44.6632, 32.5783],\n",
      "        [27.7093, 34.4717]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[42.4784, 13.0682],\n",
      "        [48.9124, 44.8565],\n",
      "        [35.9243, 27.5881],\n",
      "        ...,\n",
      "        [ 9.6868, 21.4246],\n",
      "        [22.9082, 19.8702],\n",
      "        [30.4907, 31.6169]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[43.5275, 31.7338],\n",
      "        [21.5954, 33.4548],\n",
      "        [29.0341, 53.4950],\n",
      "        ...,\n",
      "        [44.6795, 30.6049],\n",
      "        [24.5939, 30.9656],\n",
      "        [36.4572, 38.5334]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[25.6024, 37.4640],\n",
      "        [25.2638, 11.2583],\n",
      "        [33.5787,  9.6017],\n",
      "        ...,\n",
      "        [51.5627, 41.2283],\n",
      "        [21.5158, 53.4693],\n",
      "        [41.8685,  9.8362]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[52.4797, 13.4165],\n",
      "        [28.0930, 19.3110],\n",
      "        [21.9923, 46.0597],\n",
      "        ...,\n",
      "        [ 9.5915, 52.3704],\n",
      "        [49.4822, 26.7388],\n",
      "        [29.7887, 28.1670]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[28.5518, 23.1413],\n",
      "        [36.2586, 25.8916],\n",
      "        [25.8389, 14.4444],\n",
      "        ...,\n",
      "        [49.2550, 14.8337],\n",
      "        [51.4205, 20.5796],\n",
      "        [37.1139, 42.4645]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[27.7247, 49.8303],\n",
      "        [12.0896, 46.6427],\n",
      "        [17.8858, 41.1191],\n",
      "        ...,\n",
      "        [45.5726, 13.5471],\n",
      "        [30.5858, 13.0426],\n",
      "        [ 9.8146, 17.4437]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[28.3776, 37.1274],\n",
      "        [31.3655, 22.6825],\n",
      "        [17.2547, 10.6724],\n",
      "        ...,\n",
      "        [13.9849, 42.0635],\n",
      "        [14.4857, 14.2581],\n",
      "        [31.4825, 22.7384]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[21.6138, 34.9119],\n",
      "        [21.7793, 37.0233],\n",
      "        [51.1876, 33.4782],\n",
      "        ...,\n",
      "        [26.0815,  9.9319],\n",
      "        [39.2278, 33.0530],\n",
      "        [42.7608, 45.3993]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[36.0567, 52.6976],\n",
      "        [18.0764, 23.7656],\n",
      "        [23.3759, 27.0797],\n",
      "        ...,\n",
      "        [53.4295, 23.1070],\n",
      "        [31.8514, 14.3718],\n",
      "        [13.7906, 14.2277]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[ 9.8611, 13.7116],\n",
      "        [53.3132,  9.8432],\n",
      "        [47.3115, 47.3302],\n",
      "        ...,\n",
      "        [35.3023, 36.2805],\n",
      "        [14.1356, 33.6414],\n",
      "        [16.1490, 51.7332]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[40.0680, 50.7371],\n",
      "        [44.6187, 32.5393],\n",
      "        [46.8022, 40.9617],\n",
      "        ...,\n",
      "        [52.2044, 47.1769],\n",
      "        [51.7978, 27.3709],\n",
      "        [34.0193, 41.4768]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[25.1799, 38.0888],\n",
      "        [22.8373, 49.0274],\n",
      "        [17.8315, 32.9643],\n",
      "        ...,\n",
      "        [23.8493, 43.7845],\n",
      "        [30.1954, 37.4257],\n",
      "        [41.9123, 53.4257]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[ 9.9549, 15.5203],\n",
      "        [47.5951, 15.4500],\n",
      "        [26.5091, 38.8959],\n",
      "        ...,\n",
      "        [47.6126, 21.0727],\n",
      "        [24.6193, 24.2153],\n",
      "        [36.3104, 17.7067]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[32.0843, 11.8062],\n",
      "        [19.0474, 49.4484],\n",
      "        [27.0807, 53.4807],\n",
      "        ...,\n",
      "        [48.2114, 22.5808],\n",
      "        [24.1820, 31.5183],\n",
      "        [48.4683, 51.7897]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[49.2465, 25.6632],\n",
      "        [ 9.6712, 53.2719],\n",
      "        [35.3744, 19.7580],\n",
      "        ...,\n",
      "        [30.5319, 51.3734],\n",
      "        [36.2927, 18.8240],\n",
      "        [22.7421, 52.4828]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[21.1513, 46.9630],\n",
      "        [11.4390, 22.8109],\n",
      "        [17.4059,  9.6888],\n",
      "        ...,\n",
      "        [49.4202, 14.7778],\n",
      "        [38.8569, 16.5176],\n",
      "        [33.4363, 22.1590]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[35.0226, 31.0671],\n",
      "        [20.9673, 33.4157],\n",
      "        [24.6216, 30.9419],\n",
      "        ...,\n",
      "        [46.7407, 48.7242],\n",
      "        [17.7395, 36.9750],\n",
      "        [26.0390, 49.7357]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[17.6660, 52.6045],\n",
      "        [34.0668, 20.5121],\n",
      "        [43.2819, 29.3739],\n",
      "        ...,\n",
      "        [23.6891, 42.9960],\n",
      "        [17.2236, 29.6455],\n",
      "        [27.1666, 27.6692]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[32.5753, 32.4873],\n",
      "        [35.6524, 34.3746],\n",
      "        [41.9502, 49.2793],\n",
      "        ...,\n",
      "        [27.3197, 18.8645],\n",
      "        [10.7170, 45.4229],\n",
      "        [49.5243, 22.3485]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[44.8530, 41.4197],\n",
      "        [52.9208, 47.3342],\n",
      "        [27.9124, 35.8587],\n",
      "        ...,\n",
      "        [21.6987, 33.3505],\n",
      "        [41.5186, 17.8143],\n",
      "        [37.0976, 21.1088]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[25.4830, 11.3034],\n",
      "        [26.1232, 22.1396],\n",
      "        [47.4374, 23.1982],\n",
      "        ...,\n",
      "        [11.8885, 49.0843],\n",
      "        [15.8018, 41.4125],\n",
      "        [24.8228, 15.9203]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[15.6541, 13.7226],\n",
      "        [32.0741, 31.0516],\n",
      "        [36.5838, 22.1484],\n",
      "        ...,\n",
      "        [52.7873, 25.0555],\n",
      "        [26.1323, 38.7786],\n",
      "        [33.8885, 50.0141]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[50.8143, 13.3590],\n",
      "        [28.5872, 26.9198],\n",
      "        [49.4815, 42.1609],\n",
      "        ...,\n",
      "        [21.5139, 32.7121],\n",
      "        [39.2695, 29.9550],\n",
      "        [ 9.5082, 33.4962]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[46.1088, 29.0476],\n",
      "        [26.9295, 23.9787],\n",
      "        [40.5751, 38.7570],\n",
      "        [28.8470, 42.4988],\n",
      "        [41.3203, 49.9273],\n",
      "        [36.6596, 40.2715],\n",
      "        [38.3150, 29.7375],\n",
      "        [53.1427, 20.9547],\n",
      "        [45.3373, 35.1665],\n",
      "        [45.5017, 33.4648],\n",
      "        [13.4633, 21.1430],\n",
      "        [23.3120, 20.2678],\n",
      "        [25.8421, 16.4112],\n",
      "        [16.5205, 33.9613],\n",
      "        [48.3792, 23.5193],\n",
      "        [44.3160, 51.2182],\n",
      "        [36.4452, 17.4760],\n",
      "        [46.9122, 16.6578],\n",
      "        [45.9414, 42.6478],\n",
      "        [47.5062, 49.2456],\n",
      "        [18.3726, 47.7343],\n",
      "        [50.5089, 29.3315],\n",
      "        [12.8000, 31.9797],\n",
      "        [10.4133, 26.6626],\n",
      "        [47.8966, 44.9090],\n",
      "        [35.7454, 20.0480],\n",
      "        [10.0010, 17.7023],\n",
      "        [ 9.5497, 50.1620],\n",
      "        [41.8984, 17.9272],\n",
      "        [49.5819, 16.1064],\n",
      "        [37.3973,  9.5926],\n",
      "        [33.5267, 49.8798],\n",
      "        [32.6074, 32.5963],\n",
      "        [ 9.5724, 53.1001],\n",
      "        [41.0847, 52.6536],\n",
      "        [25.5064, 44.2219],\n",
      "        [26.8661, 33.2496],\n",
      "        [42.9702, 33.1206],\n",
      "        [53.4852,  9.5078],\n",
      "        [17.0739, 39.8857],\n",
      "        [47.6160, 49.6165],\n",
      "        [49.1625, 24.1869],\n",
      "        [39.0985, 47.6550],\n",
      "        [33.6156, 50.6215],\n",
      "        [49.3424, 44.4389],\n",
      "        [48.6132, 52.2683],\n",
      "        [53.4500, 49.3082],\n",
      "        [48.8408, 26.3351],\n",
      "        [47.5894, 40.5924],\n",
      "        [52.4554, 52.6682],\n",
      "        [37.9631, 50.9016],\n",
      "        [22.2890, 29.7216],\n",
      "        [42.7906, 26.3482],\n",
      "        [37.3515, 11.4297],\n",
      "        [10.1932, 45.3373],\n",
      "        [39.3491, 53.4451],\n",
      "        [18.2560, 14.1685],\n",
      "        [21.6870, 48.2145],\n",
      "        [49.6749, 20.1339],\n",
      "        [36.0807, 11.9099],\n",
      "        [19.0470, 11.7088],\n",
      "        [47.3576, 28.6951],\n",
      "        [46.3506, 44.9698],\n",
      "        [19.7563, 41.2953],\n",
      "        [12.0088, 38.2409],\n",
      "        [42.0899, 42.4953],\n",
      "        [10.5022, 44.2974],\n",
      "        [40.5241, 34.5132],\n",
      "        [27.0946, 12.0214],\n",
      "        [50.8052, 11.3729],\n",
      "        [21.3562, 40.1117],\n",
      "        [53.4090, 41.5122],\n",
      "        [17.6650, 21.9483],\n",
      "        [12.0759, 26.9708],\n",
      "        [39.7436, 29.0023],\n",
      "        [28.5398, 31.8423],\n",
      "        [17.9578, 50.9240],\n",
      "        [21.9452, 32.8399],\n",
      "        [40.4256, 18.1479],\n",
      "        [24.2054, 29.5241],\n",
      "        [46.4652, 37.9745],\n",
      "        [23.3941, 40.3770],\n",
      "        [18.0574, 42.3694],\n",
      "        [16.3392, 26.6912],\n",
      "        [35.3565, 52.6465],\n",
      "        [29.5920, 10.3640],\n",
      "        [46.6474, 14.2347],\n",
      "        [36.7802, 24.4055],\n",
      "        [39.7027, 19.3217],\n",
      "        [41.9742, 50.2360],\n",
      "        [21.4867, 25.4636],\n",
      "        [15.2602, 30.0976],\n",
      "        [36.3260, 37.9992],\n",
      "        [22.7570, 40.4360],\n",
      "        [13.0553, 22.6477],\n",
      "        [25.9298, 32.9276],\n",
      "        [17.9468, 36.8951],\n",
      "        [41.9611,  9.5646],\n",
      "        [42.1724, 25.4667],\n",
      "        [32.1326, 41.8370],\n",
      "        [44.4871, 51.9234],\n",
      "        [17.8805, 18.3463],\n",
      "        [46.5408, 44.5314],\n",
      "        [28.5483, 18.4159],\n",
      "        [29.4668,  9.5400],\n",
      "        [53.4611, 29.8231],\n",
      "        [15.0319, 10.4521],\n",
      "        [20.4148, 32.8911],\n",
      "        [45.8157, 33.9207],\n",
      "        [17.5246, 33.5815],\n",
      "        [24.2958, 29.8270],\n",
      "        [32.1568, 23.5679],\n",
      "        [17.3624, 41.5069],\n",
      "        [44.5002, 39.8295],\n",
      "        [38.1839, 16.8023],\n",
      "        [29.9666, 16.0610],\n",
      "        [22.4644, 23.0090],\n",
      "        [26.5924, 29.2336],\n",
      "        [36.8521, 13.2578],\n",
      "        [15.5768, 15.7600],\n",
      "        [16.2185, 41.5450],\n",
      "        [35.8647, 20.3389],\n",
      "        [33.5689, 46.6296],\n",
      "        [28.1067, 37.1593],\n",
      "        [29.8163, 25.7469],\n",
      "        [31.5481, 33.5721],\n",
      "        [16.7190, 51.5333],\n",
      "        [41.2687, 14.0547],\n",
      "        [33.9200,  9.7628],\n",
      "        [52.2171, 10.6931],\n",
      "        [22.9862, 36.0681],\n",
      "        [41.9684, 52.8558],\n",
      "        [29.7492, 44.6589],\n",
      "        [14.6652, 28.3862],\n",
      "        [28.2479, 27.1914],\n",
      "        [23.5436, 15.9686],\n",
      "        [40.1099, 21.3371],\n",
      "        [38.3229, 35.0622],\n",
      "        [26.0435, 53.0379],\n",
      "        [30.1628, 41.6191],\n",
      "        [34.9895, 33.9201],\n",
      "        [29.9142, 51.1077],\n",
      "        [41.7465, 26.1056],\n",
      "        [28.8600, 43.3339],\n",
      "        [44.8140, 42.4034],\n",
      "        [38.5440, 49.1347],\n",
      "        [42.5461, 30.5939],\n",
      "        [23.5377, 49.5914],\n",
      "        [25.9802, 34.6835],\n",
      "        [31.7082, 14.2071],\n",
      "        [10.1790, 46.2806],\n",
      "        [27.0913, 40.8584],\n",
      "        [22.6665, 35.6617],\n",
      "        [41.0204, 20.6121],\n",
      "        [53.2822, 23.3553],\n",
      "        [53.4825, 45.4123],\n",
      "        [25.2497, 49.3679],\n",
      "        [37.5502, 49.4181],\n",
      "        [33.6897, 36.5884],\n",
      "        [44.8678, 26.9291],\n",
      "        [43.4039, 45.0334],\n",
      "        [13.4786, 18.2028],\n",
      "        [41.0993, 24.7760],\n",
      "        [29.4717, 33.2490],\n",
      "        [40.7318, 10.3862],\n",
      "        [14.2221, 30.4008],\n",
      "        [38.2811, 45.8783],\n",
      "        [17.2418, 34.1018],\n",
      "        [33.9108, 36.4098],\n",
      "        [24.2364, 52.4467],\n",
      "        [29.9763, 43.9194],\n",
      "        [11.4744, 48.6664],\n",
      "        [39.1529, 43.7892],\n",
      "        [38.4765, 26.6466],\n",
      "        [11.1531, 36.0511],\n",
      "        [20.9009, 33.5155],\n",
      "        [52.4946, 12.3438],\n",
      "        [13.5256,  9.5416],\n",
      "        [28.3668, 25.2331],\n",
      "        [28.5471, 37.6722],\n",
      "        [49.5562, 13.7365],\n",
      "        [43.9563, 27.6455],\n",
      "        [21.4739, 53.4060],\n",
      "        [21.4765, 47.5872],\n",
      "        [26.1680, 30.3914],\n",
      "        [12.9020, 34.7702],\n",
      "        [25.0123, 45.1743],\n",
      "        [25.2858, 28.5985],\n",
      "        [32.4576, 34.1177],\n",
      "        [29.5941,  9.6495],\n",
      "        [33.4258, 30.1292],\n",
      "        [49.4737, 43.6775],\n",
      "        [14.7465, 44.4430],\n",
      "        [14.0929, 53.1740],\n",
      "        [23.8758, 18.0877],\n",
      "        [36.2675, 36.2240],\n",
      "        [52.2836, 25.7362],\n",
      "        [28.0510, 33.5035],\n",
      "        [12.9321, 33.1809],\n",
      "        [13.8916, 36.4701],\n",
      "        [38.9799, 15.0386],\n",
      "        [13.8927, 34.8846],\n",
      "        [24.6999, 43.8255],\n",
      "        [49.1988, 37.3583],\n",
      "        [21.2455, 33.2672],\n",
      "        [49.7815, 19.2185],\n",
      "        [39.8908, 40.3480],\n",
      "        [27.8946, 25.4917],\n",
      "        [30.2529, 45.0315],\n",
      "        [25.3157, 14.0290],\n",
      "        [45.9308, 18.1919],\n",
      "        [32.0884, 35.6306],\n",
      "        [25.6200, 43.6910],\n",
      "        [50.1551, 42.0274],\n",
      "        [51.0151, 34.1805],\n",
      "        [22.1960, 45.1626],\n",
      "        [29.2114, 22.6693],\n",
      "        [36.4725, 29.0430],\n",
      "        [36.4663, 23.4619],\n",
      "        [25.7033, 26.1271],\n",
      "        [31.2425, 21.3733],\n",
      "        [35.6405, 33.0298],\n",
      "        [34.0882, 47.6039],\n",
      "        [21.1326, 38.5970],\n",
      "        [53.3257, 53.4455],\n",
      "        [24.7134, 39.8501],\n",
      "        [38.1256, 17.6446],\n",
      "        [51.4524, 29.9771],\n",
      "        [30.5693, 37.2841],\n",
      "        [38.3533, 42.5985],\n",
      "        [49.8625, 41.8869],\n",
      "        [10.6091, 14.4142],\n",
      "        [17.9368, 48.9255],\n",
      "        [44.2592, 28.8448],\n",
      "        [25.8428, 33.3924],\n",
      "        [49.5860, 49.4568],\n",
      "        [17.4613, 40.0438],\n",
      "        [37.4620, 13.9772],\n",
      "        [20.7066, 11.5115],\n",
      "        [25.8942, 52.8206],\n",
      "        [15.2539, 10.5242],\n",
      "        [18.0345, 14.4494],\n",
      "        [40.4447, 18.1835],\n",
      "        [49.0329, 40.6436],\n",
      "        [16.8500, 19.5607],\n",
      "        [44.0998, 46.2671],\n",
      "        [44.8760, 31.0139],\n",
      "        [40.1575, 21.1881],\n",
      "        [27.9211, 12.7346],\n",
      "        [29.9188, 37.4626],\n",
      "        [11.5818, 44.9830],\n",
      "        [21.5997, 13.5804],\n",
      "        [45.5610, 13.7439],\n",
      "        [16.6508, 22.2374],\n",
      "        [21.8973, 21.5432],\n",
      "        [21.3712, 45.4916],\n",
      "        [15.5880, 44.5976],\n",
      "        [11.0709, 35.7108],\n",
      "        [41.5258, 35.9483],\n",
      "        [42.6956, 47.6231],\n",
      "        [31.5127, 38.8530],\n",
      "        [53.1154, 21.6301],\n",
      "        [33.6192, 52.7591],\n",
      "        [47.7863, 37.3280],\n",
      "        [25.3563, 16.7288],\n",
      "        [42.7802, 45.2683],\n",
      "        [22.8240, 28.8915],\n",
      "        [19.5734, 45.2660],\n",
      "        [36.7610, 18.6465],\n",
      "        [25.5407, 47.5286],\n",
      "        [44.9645, 32.4483],\n",
      "        [25.9117, 23.0363],\n",
      "        [14.0268, 49.3265],\n",
      "        [39.0108, 19.8931],\n",
      "        [10.9421, 43.6653],\n",
      "        [36.5973, 41.9306],\n",
      "        [40.2146, 32.2109],\n",
      "        [53.1459, 40.3901],\n",
      "        [11.5388, 29.2597],\n",
      "        [46.9898, 42.2208],\n",
      "        [31.0691, 26.6454],\n",
      "        [28.8739, 18.1248],\n",
      "        [30.0236, 21.0732],\n",
      "        [17.7268,  9.7052],\n",
      "        [35.7299, 32.8986],\n",
      "        [17.6018, 10.7764],\n",
      "        [38.1726, 24.8939],\n",
      "        [35.5730, 31.2696],\n",
      "        [34.3413, 26.2601],\n",
      "        [14.1776,  9.5177],\n",
      "        [13.4266, 46.2521],\n",
      "        [22.0791, 17.7215],\n",
      "        [ 9.5166, 41.5236],\n",
      "        [ 9.9542, 13.3526],\n",
      "        [34.1975, 33.3709],\n",
      "        [34.9433, 42.6518],\n",
      "        [27.8228, 39.3889],\n",
      "        [40.7204, 34.2873],\n",
      "        [13.4048, 19.4449],\n",
      "        [29.4444, 21.5561],\n",
      "        [30.2652, 39.6253],\n",
      "        [10.9421, 31.9064],\n",
      "        [35.2417, 18.9297],\n",
      "        [22.6457, 24.9565],\n",
      "        [42.4617, 50.2872],\n",
      "        [48.6838, 25.4538],\n",
      "        [46.3083, 17.1215],\n",
      "        [50.4980, 45.6071],\n",
      "        [ 9.7867, 14.0037],\n",
      "        [45.3984, 25.8619],\n",
      "        [22.0473, 23.3281],\n",
      "        [49.5310, 49.9112],\n",
      "        [25.5800, 34.9660],\n",
      "        [33.0578, 44.9353],\n",
      "        [25.3070, 48.2923],\n",
      "        [21.9174, 24.4317],\n",
      "        [51.8476, 11.0403],\n",
      "        [53.1932, 17.4499],\n",
      "        [30.0878, 51.3412],\n",
      "        [11.8275, 27.2183],\n",
      "        [29.2453, 14.2110],\n",
      "        [17.5408, 52.5712],\n",
      "        [18.6228, 19.1342],\n",
      "        [52.5783, 31.5815],\n",
      "        [13.8912, 29.9106],\n",
      "        [16.2205, 32.3512],\n",
      "        [46.8367, 31.5240],\n",
      "        [38.0276, 21.4243],\n",
      "        [42.5879, 23.2817],\n",
      "        [10.8434, 26.8354],\n",
      "        [40.8837, 19.2474],\n",
      "        [43.6153, 20.2841],\n",
      "        [45.4849, 48.9105],\n",
      "        [ 9.5887, 25.4954],\n",
      "        [13.8181, 29.7370],\n",
      "        [48.9652, 17.9536],\n",
      "        [53.2032, 39.8052],\n",
      "        [32.3311, 38.9568],\n",
      "        [34.1480, 32.5517],\n",
      "        [33.9895, 26.2254],\n",
      "        [50.0141, 16.2294],\n",
      "        [27.2702, 23.9915],\n",
      "        [13.8171, 33.2332],\n",
      "        [31.8266, 31.6889],\n",
      "        [29.8710, 10.7890],\n",
      "        [23.9346, 36.5718],\n",
      "        [49.6800, 30.1701],\n",
      "        [37.1974, 47.1355],\n",
      "        [38.8497, 32.4753],\n",
      "        [29.3854, 41.7615],\n",
      "        [28.2087, 25.5414],\n",
      "        [34.7110, 39.9702],\n",
      "        [48.6056, 30.1909],\n",
      "        [46.7320, 28.6029],\n",
      "        [44.8551,  9.6830],\n",
      "        [50.2679, 42.5950],\n",
      "        [29.5943, 33.5078],\n",
      "        [24.6166, 10.9537],\n",
      "        [45.9165, 12.1056],\n",
      "        [35.9853, 32.2125],\n",
      "        [39.6757, 16.0772],\n",
      "        [28.1297, 30.2823],\n",
      "        [20.5880, 46.8787],\n",
      "        [33.4987, 14.9851],\n",
      "        [19.8958, 17.9580],\n",
      "        [33.4480, 25.6707],\n",
      "        [48.6103, 32.8680],\n",
      "        [15.6709, 34.7996],\n",
      "        [13.0492, 15.4304],\n",
      "        [44.9340, 49.2017],\n",
      "        [41.0143, 49.1349],\n",
      "        [15.5206, 11.7298],\n",
      "        [47.3949, 29.5689],\n",
      "        [29.4544, 41.8284],\n",
      "        [19.1074, 49.3766],\n",
      "        [15.7263, 49.5615],\n",
      "        [34.3417, 30.5723],\n",
      "        [30.8142, 51.8105],\n",
      "        [41.4402, 20.6733],\n",
      "        [37.2198, 18.6463],\n",
      "        [22.3772, 28.2117],\n",
      "        [41.5468, 41.6651],\n",
      "        [17.5162, 48.3378],\n",
      "        [53.3278, 45.4877],\n",
      "        [53.3279, 16.4087],\n",
      "        [14.8320, 13.8945],\n",
      "        [32.0374, 29.5199],\n",
      "        [35.2458, 31.4260],\n",
      "        [18.1522, 30.2725],\n",
      "        [33.7998, 28.6887],\n",
      "        [24.1564, 37.0512],\n",
      "        [ 9.9014,  9.9094],\n",
      "        [17.2842, 10.1703],\n",
      "        [11.2100, 32.3140],\n",
      "        [28.1179, 35.6268],\n",
      "        [20.2463, 50.5302],\n",
      "        [21.1077, 36.6981],\n",
      "        [26.1279, 17.0780],\n",
      "        [13.3456, 21.3795],\n",
      "        [33.6103, 49.3276],\n",
      "        [37.2652, 43.0420],\n",
      "        [37.5533, 47.7601],\n",
      "        [27.0235, 49.4297],\n",
      "        [15.0672, 17.4720],\n",
      "        [40.0871,  9.5230],\n",
      "        [20.8011, 52.6884],\n",
      "        [14.6385, 52.1036],\n",
      "        [31.1808, 38.3471],\n",
      "        [41.7240, 40.4880],\n",
      "        [25.2597, 25.5553],\n",
      "        [28.7725, 10.4210],\n",
      "        [38.4397, 24.8797],\n",
      "        [17.8447, 44.5284],\n",
      "        [37.0968, 29.0744],\n",
      "        [27.1215, 32.4383],\n",
      "        [36.7648, 26.7331],\n",
      "        [41.4715, 13.6775],\n",
      "        [53.0997, 41.2786],\n",
      "        [24.5891, 44.2788],\n",
      "        [35.0967, 51.5431],\n",
      "        [42.2199, 46.6066],\n",
      "        [38.5226, 46.6391],\n",
      "        [10.0991, 53.1197],\n",
      "        [30.4930, 45.0599]], device='cuda:0', grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for x, y in loader:\n",
    "    print(model3(x.to(device)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
