{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80da538b-e426-4e91-9937-4dfd5e9de384",
   "metadata": {},
   "source": [
    "# **Homework Assignment: Understanding Deconvolution in Autoencoders**\n",
    "---------------\n",
    "\n",
    "In class, we worked with autoencoders built from multilayer perceptrons (MLPs). However, encoders are often constructed using convolutional architectures to better capture spatial patterns. In this assignment, you'll explore how the decoder can use deconvolutional (transposed convolution) layers to reverse and mirror the operations performed by the convolutional encoder.\n",
    "\n",
    "While convolutional encoders are relatively well understood, **decoding (or upsampling) the compressed representation** using **deconvolutional layers** (also known as **transposed convolutions**) often raises questions.\n",
    "\n",
    "This assignment is particularly relevant because deconvolution is a core component of the U-Net architecture, a prominent neural network used extensively in image segmentation tasks.\n",
    "\n",
    "Your main objective is to deeply understand **how transposed convolution layers work**, and explain them in both words and visuals.\n",
    "\n",
    "\n",
    "## **The Objective**\n",
    "\n",
    "Understand and clearly explain how **transposed convolutions** work. Use 2D transposed convolutions and a small grid of 2D points as a working example.\n",
    "\n",
    "You may need to do some additional reading to complete this assignment.\n",
    "\n",
    "## **Tasks & Deliverables**\n",
    "\n",
    "### 1. **Theory Exploration**\n",
    "\n",
    "Using markdown cells in your Colab notebook, answer the following:\n",
    "\n",
    "- What is a **transposed convolution**?\n",
    "- How does it differ from a regular convolution?\n",
    "- How does it upsample feature maps?\n",
    "- What are **stride**, **padding**, and **kernel size**, and how do they influence the result in a transposed convolution?\n",
    "- To earn full two points, your explanation must be detailed enough for a reader to reproduce the upsampling process step by step.\n",
    "\n",
    "\n",
    "### 2. **Manual Diagram (by your hand, not a generated image)**\n",
    "\n",
    "Carefully plan and draw **by hand** a diagram or a set of diagrams that:\n",
    "\n",
    "- Explain the process of using **transposed convolution**.\n",
    "- Use an example of a **small input grid of 2D points** which gets expanded into a larger output grid.\n",
    "- Explain how stride, padding, and the kernel shape affect the result.\n",
    "- Show intermediate steps of the operation, not just input and output.\n",
    "\n",
    "**Scan or photograph your diagram(s)**, and upload it to your **GitHub repository** for this course.\n",
    "\n",
    "Then embed it in your Colab notebook using markdown (you can find examples on *how to do it* in previous notebooks related to this class, e.g. the one on linear regression or the one on the MLP network).\n",
    "\n",
    "\n",
    "### 3. **Publish on GitHub**  \n",
    "   - Place the Colab notebook in your **GitHub repository** for this course.\n",
    "   - In your repository’s **README**, add a **link** to the notebook and also include an **“Open in Colab”** badge at the top of the notebook so it can be launched directly from GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd21f38-6197-43ba-8bbc-d7acd228cd01",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7056d19-211e-4a04-941b-8dfdb34cd30c",
   "metadata": {},
   "source": [
    "**What is transposed convolution?**\n",
    "\n",
    "Transposed convolution is a method of upsampling input. Despite the name, it's not a simple inverse of convolution, but rather a way to project a smaller input (e.g., a compressed representation) back into a larger spatial output by reversing the spatial reduction caused by a standard convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5eafbe-b8d4-4260-a116-8311ad0ed247",
   "metadata": {},
   "source": [
    "**How does it differ from a regular convolution?**\n",
    "\n",
    "A regular convolution takes a large input (like an image) and uses a filter (or kernel) to slide over it, computing dot products at each position to produce a smaller output. This operation typically reduces spatial dimensions. Transposed convolution works in opposite direction. It spreads values of input matrix over multiple outputs. To better understand that (and know why it is called *transposed*) it is worth to understand how we can write convolution as matrix multiplication. Let's do that step by step (for 2d matrices).\n",
    "1. We have input matrix $X$ (d x d) and kernel $K$ (k x k).\n",
    "2. Add padding.\n",
    "3. Flatten the input matrix (still $X$) and create sparse matrix from kernel (still $K$) (which depends on stride).\n",
    "4. Multiplicate $KX$ (let's call it $Y$).\n",
    "5. Reshape $Y$.\n",
    "\n",
    "And here we can see the difference: in transposed convolution we are doing that in reversed order.\n",
    "1. We have input matrix $Y$ (n x n) and kernel $K$ (k x k).\n",
    "2. Flatten the input matrix and create sparse matrix from kernel (which depends on stride).\n",
    "3. Multiplicate $K^tY$ (let's call it $X'$).\n",
    "4. Reshape $X'$.\n",
    "5. Apply cropping.\n",
    "\n",
    "Now, it is important to understand creating sparse matrix. We are going to proceed as it follows:\n",
    "1. We have input matrix $X$ (d x d) and kernel $K$ (k x k).\n",
    "2. Initialize matrix of zeros $K'$.\n",
    "3. Each row of $K'$ represents the kernel applied at a specific position on the input. The non-zero entries in a row are the flattened values of the kernel, placed in positions corresponding to where the kernel overlaps with the input at that step.\n",
    "4. If the stride \\( s > 1 \\), each row is spaced further apart in terms of index shifts — simulating the effect of the kernel skipping positions.\n",
    "\n",
    "It is going to be more understandable if we look at the example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc4f58-7829-4808-a9ba-bec5737fd0c2",
   "metadata": {},
   "source": [
    "**How does it upsample feature maps?**\n",
    "\n",
    "We can see that from previous answer. We are taking transpose of convolution matrix which is going to result in upsampled matrix. We can think about it as spreading the values of input matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f4cad-66f9-4404-9746-20237386c2b7",
   "metadata": {},
   "source": [
    "**What are **stride**, **padding**, and **kernel size**, and how do they influence the result in a transposed convolution?**\n",
    "\n",
    "**Stride**: number which indicates the size of step. It says how we move the kernel across the input matrix during the convolution operation. In terms of convolution matrix: it says how we move previous row.\n",
    "\n",
    "**Kernel size**: number which indicates the spread of values. \n",
    "\n",
    "**Padding**: in transposed convolution, it affects the final cropping of the output. The convolution matrix produces an output potentially larger than needed, so padding corresponds to removing extra values from the boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7921cfb8-6f28-4a06-959e-a8139be6c7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
